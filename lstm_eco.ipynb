{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import tpqoa\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "day_ahead = 1\n",
    "epochs = 200\n",
    "lstm_units = 150\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/EUR_USD_D_2006_2024_M.csv', parse_dates = ['time'], usecols = ['time', 'c', 'h', 'l'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge macroeco data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eco = data.copy()\n",
    "data_eco.drop(['h', 'l'], axis=1, inplace=True)\n",
    "data_eu_interest = pd.read_csv('./data/Interest_rate_EUR.csv')\n",
    "data_ge_interest = pd.read_csv('./data/Interest_rate_Germany.csv')\n",
    "data_sp500 = pd.read_csv('./data/SP500_Historical_Data.csv', parse_dates = ['Date'])\n",
    "data_cpi = pd.read_csv('./data/CPI-U_Inflation_US.csv')\n",
    "data_dff = pd.read_csv('./data/DFF.csv')\n",
    "data_gdaxi = pd.read_csv('./data/GDAXI.csv')\n",
    "data_hcip = pd.read_csv('./data/HCIP_Inflation_EUR.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eco['year_month'] = data_eco['time'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_eu_interest\n",
    "data_eu_interest['DATE'] = pd.to_datetime(data_eu_interest['DATE'], format=\"%Y-%m-%d\").dt.strftime(\"%Y-%m\")\n",
    "data_eco = pd.merge(data_eco, data_eu_interest, left_on='year_month', right_on='DATE', how='left')\n",
    "data_eco.drop(['DATE', 'TIME PERIOD'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_ge_interest\n",
    "data_ge_interest['DATE'] = pd.to_datetime(data_ge_interest['DATE'], format=\"%Y-%m-%d\").dt.strftime(\"%Y-%m\")\n",
    "data_eco = pd.merge(data_eco, data_ge_interest, left_on='year_month', right_on='DATE', how='left')\n",
    "data_eco.drop(['DATE', 'TIME PERIOD'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_sp500\n",
    "data_eco = pd.merge(data_eco, data_sp500[['Date', 'Adj Close']], left_on='time', right_on='Date', how='left')\n",
    "data_eco.drop(['Date'], axis=1, inplace=True)\n",
    "data_eco['Adj Close'].interpolate(method='linear', inplace=True)\n",
    "data_eco['Adj Close'].bfill(inplace=True)\n",
    "data_eco.rename(columns= {'Adj Close' : 'sp500'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_cpi\n",
    "data_cpi = data_cpi[~data_cpi['Period'].isin(['S01', 'S02'])]\n",
    "data_cpi['year_month'] = data_cpi['Year'].astype(str) + '-' + pd.to_datetime(data_cpi['Period'], format=\"M%m\").dt.strftime('%m')\n",
    "data_eco = pd.merge(data_eco, data_cpi[['year_month', 'Value']], left_on='year_month', right_on='year_month', how='left')\n",
    "data_eco.rename(columns= {'Value' : 'cpi-u'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_dff\n",
    "data_dff['DATE'] = pd.to_datetime(data_dff['DATE'], format='%Y-%m-%d')\n",
    "data_eco = pd.merge(data_eco, data_dff[['DATE', 'DFF']], left_on='time', right_on='DATE', how='left')\n",
    "data_eco.rename(columns= {'Value' : 'cpi-u'}, inplace=True)\n",
    "data_eco.drop(['DATE'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_gdaxi\n",
    "data_gdaxi['Date'] = pd.to_datetime(data_gdaxi['Date'], format='%Y-%m-%d')\n",
    "data_eco = pd.merge(data_eco, data_gdaxi[['Date', 'Adj Close']], left_on='time', right_on='Date', how='left')\n",
    "data_eco.rename(columns= {'Adj Close' : 'gdaxi'}, inplace=True)\n",
    "data_eco.drop(['Date'], axis=1, inplace=True)\n",
    "data_eco['gdaxi'].interpolate(method='linear', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>c</th>\n",
       "      <th>year_month</th>\n",
       "      <th>interest_rate_eu</th>\n",
       "      <th>interest_rate_ge</th>\n",
       "      <th>sp500</th>\n",
       "      <th>cpi-u</th>\n",
       "      <th>DFF</th>\n",
       "      <th>gdaxi</th>\n",
       "      <th>hcip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-02</td>\n",
       "      <td>1.18380</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1268.800049</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.09</td>\n",
       "      <td>5449.979980</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>1.18420</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1268.800049</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.34</td>\n",
       "      <td>5460.680176</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>1.20310</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1273.459961</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.22</td>\n",
       "      <td>5523.620117</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-05</td>\n",
       "      <td>1.21140</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1273.479980</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.24</td>\n",
       "      <td>5516.529785</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-06</td>\n",
       "      <td>1.21140</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1285.449951</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.22</td>\n",
       "      <td>5536.319824</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>2024-03-25</td>\n",
       "      <td>1.08030</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>5218.189941</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18261.310547</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>2024-03-26</td>\n",
       "      <td>1.08385</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>5203.580078</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18384.349609</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>1.08302</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>5248.490234</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18477.089844</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>1.08138</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>5254.350098</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18492.490234</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>1.07866</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>5254.350098</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18492.490234</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4738 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time        c year_month  interest_rate_eu  interest_rate_ge  \\\n",
       "0    2006-01-02  1.18380    2006-01              3.38              3.32   \n",
       "1    2006-01-03  1.18420    2006-01              3.38              3.32   \n",
       "2    2006-01-04  1.20310    2006-01              3.38              3.32   \n",
       "3    2006-01-05  1.21140    2006-01              3.38              3.32   \n",
       "4    2006-01-06  1.21140    2006-01              3.38              3.32   \n",
       "...         ...      ...        ...               ...               ...   \n",
       "4733 2024-03-25  1.08030    2024-03              2.90              2.35   \n",
       "4734 2024-03-26  1.08385    2024-03              2.90              2.35   \n",
       "4735 2024-03-27  1.08302    2024-03              2.90              2.35   \n",
       "4736 2024-03-28  1.08138    2024-03              2.90              2.35   \n",
       "4737 2024-03-29  1.07866    2024-03              2.90              2.35   \n",
       "\n",
       "            sp500  cpi-u   DFF         gdaxi  hcip  \n",
       "0     1268.800049    2.1  4.09   5449.979980   2.4  \n",
       "1     1268.800049    2.1  4.34   5460.680176   2.4  \n",
       "2     1273.459961    2.1  4.22   5523.620117   2.4  \n",
       "3     1273.479980    2.1  4.24   5516.529785   2.4  \n",
       "4     1285.449951    2.1  4.22   5536.319824   2.4  \n",
       "...           ...    ...   ...           ...   ...  \n",
       "4733  5218.189941    3.8  5.33  18261.310547   2.4  \n",
       "4734  5203.580078    3.8  5.33  18384.349609   2.4  \n",
       "4735  5248.490234    3.8  5.33  18477.089844   2.4  \n",
       "4736  5254.350098    3.8  5.33  18492.490234   2.4  \n",
       "4737  5254.350098    3.8  5.33  18492.490234   2.4  \n",
       "\n",
       "[4738 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with data_hcip\n",
    "data_hcip['DATE'] = pd.to_datetime(data_hcip['DATE'], format=\"%Y-%m-%d\").dt.strftime(\"%Y-%m\")\n",
    "data_eco = pd.merge(data_eco, data_hcip, left_on='year_month', right_on='DATE', how='left')\n",
    "data_eco.drop(['DATE', 'TIME PERIOD'], axis=1, inplace=True)\n",
    "data_eco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4712, 10)\n",
      "           time        c year_month  interest_rate_eu  interest_rate_ge  \\\n",
      "26   2006-02-07  1.19646    2006-02              3.53              3.47   \n",
      "27   2006-02-08  1.19816    2006-02              3.53              3.47   \n",
      "28   2006-02-09  1.19626    2006-02              3.53              3.47   \n",
      "29   2006-02-10  1.19840    2006-02              3.53              3.47   \n",
      "30   2006-02-13  1.18960    2006-02              3.53              3.47   \n",
      "...         ...      ...        ...               ...               ...   \n",
      "4733 2024-03-25  1.08030    2024-03              2.90              2.35   \n",
      "4734 2024-03-26  1.08385    2024-03              2.90              2.35   \n",
      "4735 2024-03-27  1.08302    2024-03              2.90              2.35   \n",
      "4736 2024-03-28  1.08138    2024-03              2.90              2.35   \n",
      "4737 2024-03-29  1.07866    2024-03              2.90              2.35   \n",
      "\n",
      "            sp500  cpi-u   DFF         gdaxi  hcip  \n",
      "26    1254.780029    2.1  4.47   5672.919922   2.4  \n",
      "27    1265.650024    2.1  4.48   5666.410156   2.4  \n",
      "28    1263.780029    2.1  4.52   5743.680176   2.4  \n",
      "29    1266.989990    2.1  4.51   5701.470215   2.4  \n",
      "30    1262.859985    2.1  4.44   5756.330078   2.4  \n",
      "...           ...    ...   ...           ...   ...  \n",
      "4733  5218.189941    3.8  5.33  18261.310547   2.4  \n",
      "4734  5203.580078    3.8  5.33  18384.349609   2.4  \n",
      "4735  5248.490234    3.8  5.33  18477.089844   2.4  \n",
      "4736  5254.350098    3.8  5.33  18492.490234   2.4  \n",
      "4737  5254.350098    3.8  5.33  18492.490234   2.4  \n",
      "\n",
      "[4712 rows x 10 columns]\n",
      "time                0\n",
      "c                   0\n",
      "year_month          0\n",
      "interest_rate_eu    0\n",
      "interest_rate_ge    0\n",
      "sp500               0\n",
      "cpi-u               0\n",
      "DFF                 0\n",
      "gdaxi               0\n",
      "hcip                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop the first 26 rows to match with data_tech\n",
    "data_eco = data_eco.iloc[26:]\n",
    "print(data_eco.shape)\n",
    "print(data_eco)\n",
    "print(data_eco.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate price changes\n",
    "price_changes = np.diff(data_eco['c'])\n",
    "\n",
    "# Perform histogram analysis\n",
    "histogram, bins = np.histogram(price_changes, bins=10)\n",
    "\n",
    "# Plot histogram\n",
    "plt.bar(bins[:-1], histogram, width=np.diff(bins), align='edge')\n",
    "plt.xlabel('Price Change')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Price Changes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0017 , -0.0019 ,  0.00214, ..., -0.00083, -0.00164, -0.00272])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper bound of the threshold value: 0.04116999999999993\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Determine number of bins\n",
    "number_of_bins = 10\n",
    "\n",
    "# Calculate histogram\n",
    "histogram, bins = np.histogram(price_changes, bins=number_of_bins, range=(0, price_changes.max()))\n",
    "\n",
    "# Sort histogram counts in descending order\n",
    "sorted_histogram = np.sort(histogram)[::-1]\n",
    "\n",
    "# Calculate cumulative sum of sorted histogram counts\n",
    "cumulative_sum = np.cumsum(sorted_histogram)\n",
    "\n",
    "# Find the index where cumulative sum exceeds 85% of the whole count\n",
    "index_85_percent = np.argmax(cumulative_sum >= len(price_changes) * 0.85)\n",
    "\n",
    "# Calculate the upper bound of the threshold value\n",
    "if index_85_percent == 0:\n",
    "    threshold_upper_bound = bins[-1]\n",
    "else:\n",
    "    threshold_upper_bound = bins[index_85_percent]\n",
    "\n",
    "print(\"Upper bound of the threshold value:\", threshold_upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  17   49  213 1022 2249  939  177   28   14    3]\n",
      "[-0.03304  -0.025619 -0.018198 -0.010777 -0.003356  0.004065  0.011486\n",
      "  0.018907  0.026328  0.033749  0.04117 ]\n",
      "[-0.029329500000000175, -0.021908500000000164, -0.014487500000000153, -0.007066500000000142, 0.0003544999999998688, 0.00777549999999988, 0.01519649999999989, 0.0226174999999999, 0.030038499999999912, 0.03745949999999992]\n"
     ]
    }
   ],
   "source": [
    "bin_counts, bin_edges = np.histogram(price_changes, bins=number_of_bins)\n",
    "print(bin_counts)\n",
    "print(bin_edges)\n",
    "bin_max_diff = [(bin_edges[i] + bin_edges[i+1]) / 2 for i in range(len(bin_counts))]\n",
    "print(bin_max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold upper bound: 0.00777549999999988\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def histogram_analysis(close_diff, number_of_bins):\n",
    "    # Perform histogram analysis\n",
    "    bin_counts, bin_edges = np.histogram(close_diff, bins=number_of_bins)\n",
    "    bin_max_diff = [(bin_edges[i] + bin_edges[i+1]) / 2 for i in range(len(bin_counts))]\n",
    "\n",
    "    # Sort bin_counts and bin_max_diff in descending order\n",
    "    sorted_indices = np.argsort(bin_counts)[::-1]\n",
    "    bin_counts = bin_counts[sorted_indices]\n",
    "    bin_max_diff = [bin_max_diff[i] for i in sorted_indices]\n",
    "\n",
    "    # Calculate sum of bin_counts\n",
    "    sum_bin_counts = np.sum(bin_counts)\n",
    "\n",
    "    # Find the threshold upper bound\n",
    "    temp_sum = 0\n",
    "    for i in range(number_of_bins):\n",
    "        temp_sum += bin_counts[i]\n",
    "        if temp_sum / sum_bin_counts > 0.85:\n",
    "            break\n",
    "\n",
    "    threshold_upper_bound = bin_max_diff[i]\n",
    "\n",
    "    return threshold_upper_bound\n",
    "\n",
    "# Example usage\n",
    "# close_diff = np.random.uniform(low=-0.01, high=0.01, size=1000)  # Example differences data\n",
    "number_of_bins = 10  # Example number of bins\n",
    "threshold_upper_bound = histogram_analysis(price_changes, number_of_bins)\n",
    "print(\"Threshold upper bound:\", threshold_upper_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final threshold: 0.0024400000000000055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_threshold(close_diff):\n",
    "    # Get the upper bound of the threshold value from histogram analysis\n",
    "    threshold_upper_bound = histogram_analysis(close_diff, number_of_bins)\n",
    "    \n",
    "    temp_threshold = 0\n",
    "    best_entropy = -float('inf')\n",
    "    threshold = None\n",
    "    \n",
    "    while temp_threshold < threshold_upper_bound:\n",
    "        labels = np.zeros(len(close_diff))  # Initialize labels with zeros\n",
    "        \n",
    "        # Assign labels based on threshold\n",
    "        indexes_incr = np.where(close_diff > temp_threshold)[0]\n",
    "        indexes_decr = np.where(-close_diff > temp_threshold)[0]\n",
    "        labels[indexes_incr] = 2\n",
    "        labels[indexes_decr] = 1\n",
    "        \n",
    "        # Calculate entropy\n",
    "        entropy = calculate_entropy(labels)\n",
    "        \n",
    "        # Update best_entropy and threshold if current entropy is better\n",
    "        if entropy > best_entropy:\n",
    "            best_entropy = entropy\n",
    "            threshold = temp_threshold\n",
    "        \n",
    "        # Increase temp_threshold for next iteration\n",
    "        temp_threshold += 0.00001\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(labels):\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = label_counts / len(labels)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "# Example usage\n",
    "threshold = calculate_threshold(price_changes)\n",
    "print(\"Final threshold:\", threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>MA_10</th>\n",
       "      <th>MACD_12_26</th>\n",
       "      <th>ROC_2</th>\n",
       "      <th>Momentum_4</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>BBL_20_2.0</th>\n",
       "      <th>BBM_20_2.0</th>\n",
       "      <th>BBU_20_2.0</th>\n",
       "      <th>BBB_20_2.0</th>\n",
       "      <th>BBP_20_2.0</th>\n",
       "      <th>CCI_20</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-02-07</th>\n",
       "      <td>1.19646</td>\n",
       "      <td>1.212396</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-1.045406</td>\n",
       "      <td>-0.01834</td>\n",
       "      <td>36.217972</td>\n",
       "      <td>1.196244</td>\n",
       "      <td>1.212436</td>\n",
       "      <td>1.228628</td>\n",
       "      <td>2.671004</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>-165.533230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-08</th>\n",
       "      <td>1.19816</td>\n",
       "      <td>1.209542</td>\n",
       "      <td>-0.000946</td>\n",
       "      <td>-0.485050</td>\n",
       "      <td>-0.00964</td>\n",
       "      <td>38.532998</td>\n",
       "      <td>1.194933</td>\n",
       "      <td>1.212059</td>\n",
       "      <td>1.229185</td>\n",
       "      <td>2.825944</td>\n",
       "      <td>0.094215</td>\n",
       "      <td>-133.416803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-09</th>\n",
       "      <td>1.19626</td>\n",
       "      <td>1.206658</td>\n",
       "      <td>-0.001769</td>\n",
       "      <td>-0.016716</td>\n",
       "      <td>-0.01284</td>\n",
       "      <td>36.871095</td>\n",
       "      <td>1.192758</td>\n",
       "      <td>1.211187</td>\n",
       "      <td>1.229616</td>\n",
       "      <td>3.043199</td>\n",
       "      <td>0.095022</td>\n",
       "      <td>-137.805786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-10</th>\n",
       "      <td>1.19840</td>\n",
       "      <td>1.204328</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>-0.00560</td>\n",
       "      <td>40.103967</td>\n",
       "      <td>1.191852</td>\n",
       "      <td>1.210892</td>\n",
       "      <td>1.229932</td>\n",
       "      <td>3.144742</td>\n",
       "      <td>0.171949</td>\n",
       "      <td>-105.776085</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-13</th>\n",
       "      <td>1.18960</td>\n",
       "      <td>1.202308</td>\n",
       "      <td>-0.003255</td>\n",
       "      <td>-0.556735</td>\n",
       "      <td>-0.00686</td>\n",
       "      <td>32.499577</td>\n",
       "      <td>1.188575</td>\n",
       "      <td>1.209562</td>\n",
       "      <td>1.230549</td>\n",
       "      <td>3.470244</td>\n",
       "      <td>0.024428</td>\n",
       "      <td>-167.999552</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-25</th>\n",
       "      <td>1.08030</td>\n",
       "      <td>1.089076</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>-1.178214</td>\n",
       "      <td>-0.00694</td>\n",
       "      <td>38.811259</td>\n",
       "      <td>1.078868</td>\n",
       "      <td>1.087952</td>\n",
       "      <td>1.097036</td>\n",
       "      <td>1.669874</td>\n",
       "      <td>0.078807</td>\n",
       "      <td>-128.014550</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-26</th>\n",
       "      <td>1.08385</td>\n",
       "      <td>1.088139</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>-0.253083</td>\n",
       "      <td>-0.00212</td>\n",
       "      <td>45.143745</td>\n",
       "      <td>1.078728</td>\n",
       "      <td>1.087897</td>\n",
       "      <td>1.097066</td>\n",
       "      <td>1.685578</td>\n",
       "      <td>0.279303</td>\n",
       "      <td>-70.215176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-27</th>\n",
       "      <td>1.08302</td>\n",
       "      <td>1.087145</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.251782</td>\n",
       "      <td>-0.01016</td>\n",
       "      <td>43.961831</td>\n",
       "      <td>1.078553</td>\n",
       "      <td>1.087835</td>\n",
       "      <td>1.097117</td>\n",
       "      <td>1.706560</td>\n",
       "      <td>0.240635</td>\n",
       "      <td>-80.347630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>1.08138</td>\n",
       "      <td>1.085791</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>-0.227891</td>\n",
       "      <td>-0.00522</td>\n",
       "      <td>41.572286</td>\n",
       "      <td>1.078171</td>\n",
       "      <td>1.087716</td>\n",
       "      <td>1.097261</td>\n",
       "      <td>1.755144</td>\n",
       "      <td>0.168116</td>\n",
       "      <td>-105.605063</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-29</th>\n",
       "      <td>1.07866</td>\n",
       "      <td>1.084887</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>-0.402578</td>\n",
       "      <td>-0.00164</td>\n",
       "      <td>37.787271</td>\n",
       "      <td>1.077720</td>\n",
       "      <td>1.087610</td>\n",
       "      <td>1.097501</td>\n",
       "      <td>1.818783</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>-140.927230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4712 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  c     MA_10  MACD_12_26     ROC_2  Momentum_4     RSI_10  \\\n",
       "time                                                                         \n",
       "2006-02-07  1.19646  1.212396   -0.000074 -1.045406    -0.01834  36.217972   \n",
       "2006-02-08  1.19816  1.209542   -0.000946 -0.485050    -0.00964  38.532998   \n",
       "2006-02-09  1.19626  1.206658   -0.001769 -0.016716    -0.01284  36.871095   \n",
       "2006-02-10  1.19840  1.204328   -0.002223  0.020031    -0.00560  40.103967   \n",
       "2006-02-13  1.18960  1.202308   -0.003255 -0.556735    -0.00686  32.499577   \n",
       "...             ...       ...         ...       ...         ...        ...   \n",
       "2024-03-25  1.08030  1.089076    0.000777 -1.178214    -0.00694  38.811259   \n",
       "2024-03-26  1.08385  1.088139    0.000427 -0.253083    -0.00212  45.143745   \n",
       "2024-03-27  1.08302  1.087145    0.000082  0.251782    -0.01016  43.961831   \n",
       "2024-03-28  1.08138  1.085791   -0.000320 -0.227891    -0.00522  41.572286   \n",
       "2024-03-29  1.07866  1.084887   -0.000848 -0.402578    -0.00164  37.787271   \n",
       "\n",
       "            BBL_20_2.0  BBM_20_2.0  BBU_20_2.0  BBB_20_2.0  BBP_20_2.0  \\\n",
       "time                                                                     \n",
       "2006-02-07    1.196244    1.212436    1.228628    2.671004    0.006673   \n",
       "2006-02-08    1.194933    1.212059    1.229185    2.825944    0.094215   \n",
       "2006-02-09    1.192758    1.211187    1.229616    3.043199    0.095022   \n",
       "2006-02-10    1.191852    1.210892    1.229932    3.144742    0.171949   \n",
       "2006-02-13    1.188575    1.209562    1.230549    3.470244    0.024428   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-03-25    1.078868    1.087952    1.097036    1.669874    0.078807   \n",
       "2024-03-26    1.078728    1.087897    1.097066    1.685578    0.279303   \n",
       "2024-03-27    1.078553    1.087835    1.097117    1.706560    0.240635   \n",
       "2024-03-28    1.078171    1.087716    1.097261    1.755144    0.168116   \n",
       "2024-03-29    1.077720    1.087610    1.097501    1.818783    0.047527   \n",
       "\n",
       "                CCI_20  target  \n",
       "time                            \n",
       "2006-02-07 -165.533230     0.0  \n",
       "2006-02-08 -133.416803     0.0  \n",
       "2006-02-09 -137.805786     0.0  \n",
       "2006-02-10 -105.776085     1.0  \n",
       "2006-02-13 -167.999552     0.0  \n",
       "...                ...     ...  \n",
       "2024-03-25 -128.014550     2.0  \n",
       "2024-03-26  -70.215176     0.0  \n",
       "2024-03-27  -80.347630     0.0  \n",
       "2024-03-28 -105.605063     1.0  \n",
       "2024-03-29 -140.927230     0.0  \n",
       "\n",
       "[4712 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tech = data.copy()\n",
    "data_tech['MA_10'] = ta.sma(data_tech['c'], length=10)\n",
    "data_tech['MACD_12_26'] = ta.macd(data_tech['c'], fast=12, slow=26).iloc[:, 0]\n",
    "data_tech['ROC_2'] = ta.roc(data_tech['c'], length=2)\n",
    "data_tech['Momentum_4'] = ta.mom(data_tech['c'], length=4)\n",
    "data_tech['RSI_10'] = ta.rsi(data_tech['c'], length=10)\n",
    "bb_data = ta.bbands(data_tech['c'], length=20)\n",
    "data_tech = pd.concat([data_tech, bb_data], axis=1)\n",
    "data_tech['CCI_20'] = ta.cci(data_tech['h'], data_tech['l'], data_tech['c'], length=20)\n",
    "data_tech = data_tech.iloc[26:]\n",
    "data_tech['price_diff'] = data_tech['c'].diff()\n",
    "data_tech['price_diff'] = data_tech['price_diff'].bfill()\n",
    "data_tech['target'] = 0\n",
    "data_tech.loc[data_tech['price_diff'] > threshold, 'target'] = 2\n",
    "data_tech.loc[data_tech['price_diff'] < -threshold, 'target'] = 1\n",
    "data_tech['target'] = data_tech['target'].shift(-day_ahead)\n",
    "data_tech['target'].fillna(0, inplace=True)\n",
    "data_tech.set_index('time', inplace=True)\n",
    "data_tech.drop(['h', 'l', 'price_diff'], axis=1, inplace=True)\n",
    "# print(data_tech.isna().sum())\n",
    "data_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_533055/2160447692.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['price_diff'] = data_eco['c'].diff()\n",
      "/tmp/ipykernel_533055/2160447692.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['price_diff'] = data_eco['price_diff'].bfill()\n",
      "/tmp/ipykernel_533055/2160447692.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['target'] = 0\n",
      "/tmp/ipykernel_533055/2160447692.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['target'] = data_eco['target'].shift(-day_ahead)\n",
      "/tmp/ipykernel_533055/2160447692.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['target'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_533055/2160447692.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco.drop(['year_month', 'price_diff'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_eco['price_diff'] = data_eco['c'].diff()\n",
    "data_eco['price_diff'] = data_eco['price_diff'].bfill()\n",
    "data_eco['target'] = 0\n",
    "data_eco.loc[data_eco['price_diff'] > threshold, 'target'] = 2\n",
    "data_eco.loc[data_eco['price_diff'] < -threshold, 'target'] = 1\n",
    "data_eco['target'] = data_eco['target'].shift(-day_ahead)\n",
    "data_eco['target'].fillna(0, inplace=True)\n",
    "data_eco.set_index('time', inplace=True)\n",
    "data_eco.drop(['year_month', 'price_diff'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_normalized(X, y, test_size=0.2):\n",
    "    # Split the dataset into training and testing sets with no shuffling\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the scaler to the training data and transform it\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Transform the testing data using the scaler fitted on the training data\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_normalized, X_test_normalized, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 03:12:00.367247: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 03:12:00.391571: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-26 03:12:00.684836: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-26 03:12:00.684973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-26 03:12:00.720938: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 03:12:00.824350: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-26 03:12:00.827446: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 03:12:02.279908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import Metric\n",
    "import keras.backend as K\n",
    "\n",
    "class ProfitAccuracy(Metric):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ProfitAccuracy, self).__init__(**kwargs)\n",
    "        self.true_dec = self.add_weight(name='true_dec', initializer='zeros')\n",
    "        self.true_inc = self.add_weight(name='true_inc', initializer='zeros')\n",
    "        self.false_dec_noact = self.add_weight(name='false_dec_noact', initializer='zeros')\n",
    "        self.false_inc_noact = self.add_weight(name='false_inc_noact', initializer='zeros')\n",
    "        self.false_inc_dec = self.add_weight(name='false_inc_dec', initializer='zeros')\n",
    "        self.false_dec_inc = self.add_weight(name='false_dec_inc', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert y_true and y_pred to boolean arrays\n",
    "        y_true = K.argmax(y_true, axis=-1)\n",
    "        y_pred = K.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        true_dec = K.sum(K.cast(K.equal(y_true, 1) & K.equal(y_pred, 1), 'float32'))\n",
    "        true_inc = K.sum(K.cast(K.equal(y_true, 2) & K.equal(y_pred, 2), 'float32'))\n",
    "        false_dec_noact = K.sum(K.cast(K.equal(y_true, 0) & K.equal(y_pred, 1), 'float32'))\n",
    "        false_inc_noact = K.sum(K.cast(K.equal(y_true, 0) & K.equal(y_pred, 2), 'float32'))\n",
    "        false_inc_dec = K.sum(K.cast(K.equal(y_true, 1) & K.equal(y_pred, 2), 'float32'))\n",
    "        false_dec_inc = K.sum(K.cast(K.equal(y_true, 2) & K.equal(y_pred, 1), 'float32'))\n",
    "\n",
    "\n",
    "        self.true_dec.assign_add(true_dec)\n",
    "        self.true_inc.assign_add(true_inc)\n",
    "        self.false_dec_noact.assign_add(false_dec_noact)\n",
    "        self.false_inc_noact.assign_add(false_inc_noact)\n",
    "        self.false_inc_dec.assign_add(false_inc_dec)\n",
    "        self.false_dec_inc.assign_add(false_dec_inc)\n",
    "\n",
    "    def result(self):\n",
    "        numerator = self.true_dec + self.true_inc\n",
    "        denominator = (\n",
    "            self.false_dec_noact + self.false_inc_noact +\n",
    "            self.true_dec + self.false_inc_dec +\n",
    "            self.false_dec_inc + self.true_inc\n",
    "        )\n",
    "\n",
    "        # Check for division by zero\n",
    "        if denominator == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return numerator / denominator\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_dec.assign(0)\n",
    "        self.true_inc.assign(0)\n",
    "        self.false_dec_noact.assign(0)\n",
    "        self.false_inc_noact.assign(0)\n",
    "        self.false_inc_dec.assign(0)\n",
    "        self.false_dec_inc.assign(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2006-02-07    0.0\n",
       "2006-02-08    0.0\n",
       "2006-02-09    0.0\n",
       "2006-02-10    1.0\n",
       "2006-02-13    0.0\n",
       "             ... \n",
       "2020-08-05    2.0\n",
       "2020-08-06    0.0\n",
       "2020-08-07    1.0\n",
       "2020-08-10    1.0\n",
       "2020-08-11    0.0\n",
       "Name: target, Length: 3769, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eco = data_eco.drop(columns=['target'])\n",
    "y_eco = data_eco['target']\n",
    "\n",
    "X_train_normalized_eco, X_test_normalized_eco, y_train, y_test = data_normalized(X_eco, y_eco)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "# from keras.layers import Dropout\n",
    "\n",
    "def train_lstm_model(X_train, X_test, y_train, y_test, lstm_units=lstm_units, epochs=epochs, batch_size=batch_size):\n",
    "    # Convert features to float32\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y_train)\n",
    "    encoded_y_train = encoder.transform(y_train)\n",
    "    encoded_y_test = encoder.transform(y_test)\n",
    "    y_train_onehot = to_categorical(encoded_y_train)\n",
    "    y_test_onehot = to_categorical(encoded_y_test)\n",
    "\n",
    "    # Reshape input data for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[ProfitAccuracy()])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train_onehot, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test_onehot))\n",
    "    \n",
    "    # Evaluate the model on the test set using custom metric\n",
    "    y_pred = model.predict(X_test)\n",
    "    profit_accuracy = ProfitAccuracy()(y_test_onehot, y_pred)\n",
    "    print(f\"Profit_accuracy = {profit_accuracy}\")\n",
    "\n",
    "    return y_pred, profit_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "59/59 [==============================] - 3s 17ms/step - loss: 1.0922 - profit_accuracy: 0.3560 - val_loss: 1.0843 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0832 - profit_accuracy: 0.3716 - val_loss: 1.0850 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0802 - profit_accuracy: 0.3734 - val_loss: 1.1081 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0788 - profit_accuracy: 0.3722 - val_loss: 1.1051 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0784 - profit_accuracy: 0.3851 - val_loss: 1.1377 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0782 - profit_accuracy: 0.3835 - val_loss: 1.1234 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0783 - profit_accuracy: 0.3749 - val_loss: 1.1112 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0769 - profit_accuracy: 0.3873 - val_loss: 1.1120 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy: 0.3950 - val_loss: 1.1124 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy: 0.3940 - val_loss: 1.1205 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0765 - profit_accuracy: 0.3915 - val_loss: 1.1030 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy: 0.3698 - val_loss: 1.1078 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy: 0.3926 - val_loss: 1.1305 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy: 0.3883 - val_loss: 1.1449 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0749 - profit_accuracy: 0.4115 - val_loss: 1.1388 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy: 0.3768 - val_loss: 1.1173 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0750 - profit_accuracy: 0.3925 - val_loss: 1.1236 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0748 - profit_accuracy: 0.3977 - val_loss: 1.1312 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy: 0.3957 - val_loss: 1.1151 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy: 0.3921 - val_loss: 1.1551 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0739 - profit_accuracy: 0.3888 - val_loss: 1.1358 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy: 0.3886 - val_loss: 1.1248 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0738 - profit_accuracy: 0.3928 - val_loss: 1.1329 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0733 - profit_accuracy: 0.3857 - val_loss: 1.1293 - val_profit_accuracy: 0.3158\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0728 - profit_accuracy: 0.3911 - val_loss: 1.1784 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0728 - profit_accuracy: 0.3911 - val_loss: 1.1853 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0721 - profit_accuracy: 0.3981 - val_loss: 1.1291 - val_profit_accuracy: 0.3000\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy: 0.3838 - val_loss: 1.1873 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0724 - profit_accuracy: 0.4000 - val_loss: 1.1435 - val_profit_accuracy: 0.3158\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy: 0.3852 - val_loss: 1.1138 - val_profit_accuracy: 0.3611\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0728 - profit_accuracy: 0.3981 - val_loss: 1.1167 - val_profit_accuracy: 0.3600\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy: 0.3892 - val_loss: 1.1033 - val_profit_accuracy: 0.3786\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0740 - profit_accuracy: 0.3831 - val_loss: 1.1249 - val_profit_accuracy: 0.3000\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy: 0.3909 - val_loss: 1.1312 - val_profit_accuracy: 0.3793\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0717 - profit_accuracy: 0.3918 - val_loss: 1.1364 - val_profit_accuracy: 0.3704\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0720 - profit_accuracy: 0.3919 - val_loss: 1.1273 - val_profit_accuracy: 0.3333\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0717 - profit_accuracy: 0.3919 - val_loss: 1.1858 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0717 - profit_accuracy: 0.3908 - val_loss: 1.1477 - val_profit_accuracy: 0.2857\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0719 - profit_accuracy: 0.3964 - val_loss: 1.1616 - val_profit_accuracy: 0.3600\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0713 - profit_accuracy: 0.3939 - val_loss: 1.1612 - val_profit_accuracy: 0.3600\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0714 - profit_accuracy: 0.3931 - val_loss: 1.1462 - val_profit_accuracy: 0.3600\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0714 - profit_accuracy: 0.3910 - val_loss: 1.1699 - val_profit_accuracy: 0.2222\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0712 - profit_accuracy: 0.3876 - val_loss: 1.1575 - val_profit_accuracy: 0.4138\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy: 0.3951 - val_loss: 1.1871 - val_profit_accuracy: 0.3000\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0708 - profit_accuracy: 0.3908 - val_loss: 1.2074 - val_profit_accuracy: 0.2222\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0709 - profit_accuracy: 0.3914 - val_loss: 1.1375 - val_profit_accuracy: 0.3924\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0718 - profit_accuracy: 0.3870 - val_loss: 1.1462 - val_profit_accuracy: 0.3529\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy: 0.3887 - val_loss: 1.1807 - val_profit_accuracy: 0.3333\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0715 - profit_accuracy: 0.3963 - val_loss: 1.1632 - val_profit_accuracy: 0.3500\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0710 - profit_accuracy: 0.3920 - val_loss: 1.1839 - val_profit_accuracy: 0.3478\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0716 - profit_accuracy: 0.4013 - val_loss: 1.2440 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0723 - profit_accuracy: 0.3980 - val_loss: 1.1320 - val_profit_accuracy: 0.3875\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0711 - profit_accuracy: 0.3909 - val_loss: 1.1855 - val_profit_accuracy: 0.3158\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0711 - profit_accuracy: 0.3954 - val_loss: 1.2140 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0709 - profit_accuracy: 0.3985 - val_loss: 1.1779 - val_profit_accuracy: 0.3077\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy: 0.3965 - val_loss: 1.1904 - val_profit_accuracy: 0.2857\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0711 - profit_accuracy: 0.3970 - val_loss: 1.1979 - val_profit_accuracy: 0.3333\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0703 - profit_accuracy: 0.4005 - val_loss: 1.1552 - val_profit_accuracy: 0.3750\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0708 - profit_accuracy: 0.3913 - val_loss: 1.1654 - val_profit_accuracy: 0.3571\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0702 - profit_accuracy: 0.3956 - val_loss: 1.2352 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0707 - profit_accuracy: 0.3995 - val_loss: 1.1790 - val_profit_accuracy: 0.3636\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0705 - profit_accuracy: 0.3886 - val_loss: 1.1686 - val_profit_accuracy: 0.4000\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0708 - profit_accuracy: 0.3864 - val_loss: 1.1869 - val_profit_accuracy: 0.3125\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0701 - profit_accuracy: 0.4007 - val_loss: 1.1980 - val_profit_accuracy: 0.3077\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0704 - profit_accuracy: 0.3893 - val_loss: 1.1628 - val_profit_accuracy: 0.3750\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0710 - profit_accuracy: 0.3880 - val_loss: 1.1894 - val_profit_accuracy: 0.3125\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0702 - profit_accuracy: 0.3834 - val_loss: 1.2238 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0708 - profit_accuracy: 0.3962 - val_loss: 1.2085 - val_profit_accuracy: 0.2857\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0702 - profit_accuracy: 0.4000 - val_loss: 1.1850 - val_profit_accuracy: 0.3333\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy: 0.3906 - val_loss: 1.2225 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy: 0.3977 - val_loss: 1.1945 - val_profit_accuracy: 0.3077\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0703 - profit_accuracy: 0.3983 - val_loss: 1.1848 - val_profit_accuracy: 0.2727\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy: 0.3968 - val_loss: 1.1865 - val_profit_accuracy: 0.3636\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3986 - val_loss: 1.1239 - val_profit_accuracy: 0.3462\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0707 - profit_accuracy: 0.3925 - val_loss: 1.1575 - val_profit_accuracy: 0.3684\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy: 0.3958 - val_loss: 1.1696 - val_profit_accuracy: 0.3636\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy: 0.3974 - val_loss: 1.2057 - val_profit_accuracy: 0.3125\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0695 - profit_accuracy: 0.3954 - val_loss: 1.1965 - val_profit_accuracy: 0.3125\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0704 - profit_accuracy: 0.3943 - val_loss: 1.1766 - val_profit_accuracy: 0.3478\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy: 0.3941 - val_loss: 1.2039 - val_profit_accuracy: 0.3158\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy: 0.3981 - val_loss: 1.2733 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0699 - profit_accuracy: 0.3995 - val_loss: 1.2065 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0702 - profit_accuracy: 0.3943 - val_loss: 1.1777 - val_profit_accuracy: 0.3333\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy: 0.3978 - val_loss: 1.2209 - val_profit_accuracy: 0.2222\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0701 - profit_accuracy: 0.3908 - val_loss: 1.1834 - val_profit_accuracy: 0.3158\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0699 - profit_accuracy: 0.3949 - val_loss: 1.1959 - val_profit_accuracy: 0.3636\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0691 - profit_accuracy: 0.4020 - val_loss: 1.1826 - val_profit_accuracy: 0.3793\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy: 0.3960 - val_loss: 1.1584 - val_profit_accuracy: 0.3667\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy: 0.3986 - val_loss: 1.1863 - val_profit_accuracy: 0.3333\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy: 0.3984 - val_loss: 1.2142 - val_profit_accuracy: 0.2857\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0690 - profit_accuracy: 0.3967 - val_loss: 1.1886 - val_profit_accuracy: 0.3600\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0697 - profit_accuracy: 0.3958 - val_loss: 1.1979 - val_profit_accuracy: 0.2727\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0687 - profit_accuracy: 0.4057 - val_loss: 1.2348 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy: 0.4002 - val_loss: 1.1651 - val_profit_accuracy: 0.3256\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3950 - val_loss: 1.1988 - val_profit_accuracy: 0.2941\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0695 - profit_accuracy: 0.4001 - val_loss: 1.2280 - val_profit_accuracy: 0.2222\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.3970 - val_loss: 1.2502 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3978 - val_loss: 1.2192 - val_profit_accuracy: 0.2222\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3950 - val_loss: 1.2675 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0689 - profit_accuracy: 0.4024 - val_loss: 1.1819 - val_profit_accuracy: 0.2903\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0701 - profit_accuracy: 0.4029 - val_loss: 1.1492 - val_profit_accuracy: 0.3333\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0688 - profit_accuracy: 0.4016 - val_loss: 1.1476 - val_profit_accuracy: 0.3380\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy: 0.4072 - val_loss: 1.1976 - val_profit_accuracy: 0.3125\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0694 - profit_accuracy: 0.3970 - val_loss: 1.2256 - val_profit_accuracy: 0.2857\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.3936 - val_loss: 1.1940 - val_profit_accuracy: 0.3333\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0691 - profit_accuracy: 0.4037 - val_loss: 1.1806 - val_profit_accuracy: 0.3750\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0687 - profit_accuracy: 0.4050 - val_loss: 1.2395 - val_profit_accuracy: 0.2500\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy: 0.4007 - val_loss: 1.2011 - val_profit_accuracy: 0.3125\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.4037 - val_loss: 1.1791 - val_profit_accuracy: 0.3793\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0689 - profit_accuracy: 0.3973 - val_loss: 1.2009 - val_profit_accuracy: 0.3125\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0685 - profit_accuracy: 0.3976 - val_loss: 1.1958 - val_profit_accuracy: 0.3500\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3960 - val_loss: 1.2211 - val_profit_accuracy: 0.3636\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.4060 - val_loss: 1.1559 - val_profit_accuracy: 0.2969\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.3941 - val_loss: 1.2292 - val_profit_accuracy: 0.2857\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy: 0.4022 - val_loss: 1.1794 - val_profit_accuracy: 0.3226\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0685 - profit_accuracy: 0.4024 - val_loss: 1.2054 - val_profit_accuracy: 0.3125\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0691 - profit_accuracy: 0.3945 - val_loss: 1.2064 - val_profit_accuracy: 0.2941\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy: 0.4093 - val_loss: 1.2198 - val_profit_accuracy: 0.3636\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3938 - val_loss: 1.1618 - val_profit_accuracy: 0.2931\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.3988 - val_loss: 1.2281 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0688 - profit_accuracy: 0.4027 - val_loss: 1.2207 - val_profit_accuracy: 0.3125\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0689 - profit_accuracy: 0.4055 - val_loss: 1.1962 - val_profit_accuracy: 0.3158\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0687 - profit_accuracy: 0.3994 - val_loss: 1.2302 - val_profit_accuracy: 0.4000\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy: 0.4056 - val_loss: 1.2168 - val_profit_accuracy: 0.2500\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0692 - profit_accuracy: 0.4020 - val_loss: 1.2291 - val_profit_accuracy: 0.3636\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0689 - profit_accuracy: 0.4011 - val_loss: 1.2310 - val_profit_accuracy: 0.3333\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy: 0.3954 - val_loss: 1.1888 - val_profit_accuracy: 0.3333\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0696 - profit_accuracy: 0.4062 - val_loss: 1.2172 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0682 - profit_accuracy: 0.3999 - val_loss: 1.2152 - val_profit_accuracy: 0.3333\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0691 - profit_accuracy: 0.4017 - val_loss: 1.1825 - val_profit_accuracy: 0.3333\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy: 0.4035 - val_loss: 1.1809 - val_profit_accuracy: 0.3333\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0683 - profit_accuracy: 0.4024 - val_loss: 1.2222 - val_profit_accuracy: 0.2857\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0684 - profit_accuracy: 0.4083 - val_loss: 1.2040 - val_profit_accuracy: 0.3125\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0689 - profit_accuracy: 0.4048 - val_loss: 1.1815 - val_profit_accuracy: 0.3913\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0682 - profit_accuracy: 0.4016 - val_loss: 1.2310 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0683 - profit_accuracy: 0.3973 - val_loss: 1.1908 - val_profit_accuracy: 0.3158\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0680 - profit_accuracy: 0.4079 - val_loss: 1.2131 - val_profit_accuracy: 0.2857\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0679 - profit_accuracy: 0.4026 - val_loss: 1.2315 - val_profit_accuracy: 0.4000\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0685 - profit_accuracy: 0.4050 - val_loss: 1.1982 - val_profit_accuracy: 0.4167\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.0682 - profit_accuracy: 0.4055 - val_loss: 1.2362 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0683 - profit_accuracy: 0.4044 - val_loss: 1.2515 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0683 - profit_accuracy: 0.4073 - val_loss: 1.1981 - val_profit_accuracy: 0.4286\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0688 - profit_accuracy: 0.4046 - val_loss: 1.2006 - val_profit_accuracy: 0.3333\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0686 - profit_accuracy: 0.3977 - val_loss: 1.2372 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0688 - profit_accuracy: 0.3972 - val_loss: 1.2316 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0677 - profit_accuracy: 0.3995 - val_loss: 1.1863 - val_profit_accuracy: 0.3333\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0684 - profit_accuracy: 0.4024 - val_loss: 1.2307 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0686 - profit_accuracy: 0.4068 - val_loss: 1.1979 - val_profit_accuracy: 0.3333\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0684 - profit_accuracy: 0.4012 - val_loss: 1.1933 - val_profit_accuracy: 0.2222\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy: 0.4063 - val_loss: 1.2178 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0673 - profit_accuracy: 0.4044 - val_loss: 1.2623 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0682 - profit_accuracy: 0.4043 - val_loss: 1.2315 - val_profit_accuracy: 0.2857\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0683 - profit_accuracy: 0.4041 - val_loss: 1.2000 - val_profit_accuracy: 0.3636\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0688 - profit_accuracy: 0.4023 - val_loss: 1.1901 - val_profit_accuracy: 0.3125\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0682 - profit_accuracy: 0.4022 - val_loss: 1.1522 - val_profit_accuracy: 0.3651\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0680 - profit_accuracy: 0.4089 - val_loss: 1.1926 - val_profit_accuracy: 0.3333\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0685 - profit_accuracy: 0.4074 - val_loss: 1.1718 - val_profit_accuracy: 0.3056\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0668 - profit_accuracy: 0.4027 - val_loss: 1.2615 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy: 0.4042 - val_loss: 1.1661 - val_profit_accuracy: 0.3455\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0680 - profit_accuracy: 0.4030 - val_loss: 1.1884 - val_profit_accuracy: 0.3125\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0676 - profit_accuracy: 0.4138 - val_loss: 1.1542 - val_profit_accuracy: 0.3333\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy: 0.3996 - val_loss: 1.2098 - val_profit_accuracy: 0.4000\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0676 - profit_accuracy: 0.4085 - val_loss: 1.1833 - val_profit_accuracy: 0.4000\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0676 - profit_accuracy: 0.4046 - val_loss: 1.2048 - val_profit_accuracy: 0.4000\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy: 0.4020 - val_loss: 1.1834 - val_profit_accuracy: 0.3529\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy: 0.4067 - val_loss: 1.1788 - val_profit_accuracy: 0.3600\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0671 - profit_accuracy: 0.4068 - val_loss: 1.2247 - val_profit_accuracy: 0.2500\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy: 0.4012 - val_loss: 1.2270 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0674 - profit_accuracy: 0.4062 - val_loss: 1.1837 - val_profit_accuracy: 0.3125\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0670 - profit_accuracy: 0.4002 - val_loss: 1.1889 - val_profit_accuracy: 0.4211\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0676 - profit_accuracy: 0.4111 - val_loss: 1.1835 - val_profit_accuracy: 0.5909\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0678 - profit_accuracy: 0.4053 - val_loss: 1.2277 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0664 - profit_accuracy: 0.4051 - val_loss: 1.1740 - val_profit_accuracy: 0.2963\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy: 0.4070 - val_loss: 1.1555 - val_profit_accuracy: 0.3729\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0679 - profit_accuracy: 0.4002 - val_loss: 1.2102 - val_profit_accuracy: 0.3333\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0678 - profit_accuracy: 0.4042 - val_loss: 1.2110 - val_profit_accuracy: 0.4000\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy: 0.4024 - val_loss: 1.1772 - val_profit_accuracy: 0.6111\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0671 - profit_accuracy: 0.4026 - val_loss: 1.1993 - val_profit_accuracy: 0.4000\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy: 0.4064 - val_loss: 1.1633 - val_profit_accuracy: 0.3333\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0668 - profit_accuracy: 0.4109 - val_loss: 1.2095 - val_profit_accuracy: 0.2857\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0681 - profit_accuracy: 0.3997 - val_loss: 1.1978 - val_profit_accuracy: 0.3636\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0667 - profit_accuracy: 0.4074 - val_loss: 1.2301 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0667 - profit_accuracy: 0.4146 - val_loss: 1.1977 - val_profit_accuracy: 0.3571\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0666 - profit_accuracy: 0.4053 - val_loss: 1.1808 - val_profit_accuracy: 0.3929\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0665 - profit_accuracy: 0.4013 - val_loss: 1.2122 - val_profit_accuracy: 0.2857\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0669 - profit_accuracy: 0.3957 - val_loss: 1.2183 - val_profit_accuracy: 0.3333\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0674 - profit_accuracy: 0.4004 - val_loss: 1.2122 - val_profit_accuracy: 0.3571\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0676 - profit_accuracy: 0.4107 - val_loss: 1.1913 - val_profit_accuracy: 0.3600\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0664 - profit_accuracy: 0.4047 - val_loss: 1.2102 - val_profit_accuracy: 0.3333\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy: 0.4140 - val_loss: 1.2212 - val_profit_accuracy: 0.2857\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0663 - profit_accuracy: 0.4050 - val_loss: 1.2253 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0667 - profit_accuracy: 0.4136 - val_loss: 1.1726 - val_profit_accuracy: 0.4333\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.0664 - profit_accuracy: 0.4201 - val_loss: 1.1640 - val_profit_accuracy: 0.4000\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0672 - profit_accuracy: 0.4048 - val_loss: 1.1782 - val_profit_accuracy: 0.4074\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0664 - profit_accuracy: 0.4042 - val_loss: 1.1863 - val_profit_accuracy: 0.3600\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0658 - profit_accuracy: 0.4175 - val_loss: 1.2201 - val_profit_accuracy: 0.4286\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0665 - profit_accuracy: 0.4132 - val_loss: 1.1730 - val_profit_accuracy: 0.4138\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.0664 - profit_accuracy: 0.4006 - val_loss: 1.2211 - val_profit_accuracy: 0.2857\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0663 - profit_accuracy: 0.4124 - val_loss: 1.1966 - val_profit_accuracy: 0.3600\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0655 - profit_accuracy: 0.4026 - val_loss: 1.2014 - val_profit_accuracy: 0.3333\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Profit_accuracy = 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "y_eco = data_eco['target']\n",
    "X_eco = data_eco.drop(columns=['target'])\n",
    "\n",
    "X_train_normalized_eco, X_test_normalized_eco, y_train, y_test = data_normalized(X_eco, y_eco)\n",
    "y_pred, profit_accuracy = train_lstm_model(X_train_normalized_eco, X_test_normalized_eco, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "59/59 [==============================] - 2s 13ms/step - loss: 1.0960 - profit_accuracy_2: 0.3407 - val_loss: 1.0967 - val_profit_accuracy_2: 0.2848\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0919 - profit_accuracy_2: 0.3541 - val_loss: 1.0981 - val_profit_accuracy_2: 0.2803\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0888 - profit_accuracy_2: 0.3575 - val_loss: 1.0901 - val_profit_accuracy_2: 1.0000\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0860 - profit_accuracy_2: 0.3681 - val_loss: 1.0910 - val_profit_accuracy_2: 0.3571\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0844 - profit_accuracy_2: 0.3635 - val_loss: 1.0897 - val_profit_accuracy_2: 0.2759\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0825 - profit_accuracy_2: 0.3704 - val_loss: 1.0938 - val_profit_accuracy_2: 0.3158\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0822 - profit_accuracy_2: 0.3774 - val_loss: 1.0919 - val_profit_accuracy_2: 0.3058\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0795 - profit_accuracy_2: 0.3869 - val_loss: 1.0871 - val_profit_accuracy_2: 0.4194\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0795 - profit_accuracy_2: 0.3904 - val_loss: 1.0911 - val_profit_accuracy_2: 0.3232\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0787 - profit_accuracy_2: 0.3935 - val_loss: 1.0868 - val_profit_accuracy_2: 0.3137\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0802 - profit_accuracy_2: 0.3769 - val_loss: 1.0904 - val_profit_accuracy_2: 0.3164\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0792 - profit_accuracy_2: 0.3918 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3077\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0789 - profit_accuracy_2: 0.3764 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3367\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0791 - profit_accuracy_2: 0.3902 - val_loss: 1.0866 - val_profit_accuracy_2: 0.3103\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0795 - profit_accuracy_2: 0.3808 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3256\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0788 - profit_accuracy_2: 0.4001 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3364\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0789 - profit_accuracy_2: 0.3855 - val_loss: 1.0890 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0787 - profit_accuracy_2: 0.3969 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3399\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0785 - profit_accuracy_2: 0.3905 - val_loss: 1.0878 - val_profit_accuracy_2: 0.3507\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_2: 0.3866 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3356\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_2: 0.3960 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3438\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0786 - profit_accuracy_2: 0.3914 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3562\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0792 - profit_accuracy_2: 0.3908 - val_loss: 1.0874 - val_profit_accuracy_2: 0.3259\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0779 - profit_accuracy_2: 0.3911 - val_loss: 1.0866 - val_profit_accuracy_2: 0.3393\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_2: 0.3923 - val_loss: 1.0873 - val_profit_accuracy_2: 0.3588\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0782 - profit_accuracy_2: 0.3937 - val_loss: 1.0940 - val_profit_accuracy_2: 0.3285\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0783 - profit_accuracy_2: 0.4040 - val_loss: 1.0870 - val_profit_accuracy_2: 0.3525\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0781 - profit_accuracy_2: 0.3984 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3630\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0783 - profit_accuracy_2: 0.3797 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0778 - profit_accuracy_2: 0.3958 - val_loss: 1.0926 - val_profit_accuracy_2: 0.3245\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0789 - profit_accuracy_2: 0.4025 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3448\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0786 - profit_accuracy_2: 0.3776 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3450\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0775 - profit_accuracy_2: 0.3917 - val_loss: 1.0869 - val_profit_accuracy_2: 0.3826\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_2: 0.3920 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3608\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0784 - profit_accuracy_2: 0.3925 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3901\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0777 - profit_accuracy_2: 0.3975 - val_loss: 1.0861 - val_profit_accuracy_2: 0.3878\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0774 - profit_accuracy_2: 0.3985 - val_loss: 1.0865 - val_profit_accuracy_2: 0.4028\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0776 - profit_accuracy_2: 0.3944 - val_loss: 1.0866 - val_profit_accuracy_2: 0.4123\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0779 - profit_accuracy_2: 0.3839 - val_loss: 1.0866 - val_profit_accuracy_2: 0.4242\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0784 - profit_accuracy_2: 0.3813 - val_loss: 1.0880 - val_profit_accuracy_2: 0.3403\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0778 - profit_accuracy_2: 0.3858 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3189\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0775 - profit_accuracy_2: 0.3925 - val_loss: 1.0870 - val_profit_accuracy_2: 0.3621\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_2: 0.3910 - val_loss: 1.0870 - val_profit_accuracy_2: 0.3596\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0770 - profit_accuracy_2: 0.3973 - val_loss: 1.0865 - val_profit_accuracy_2: 0.3618\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_2: 0.3959 - val_loss: 1.0871 - val_profit_accuracy_2: 0.3584\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0771 - profit_accuracy_2: 0.3914 - val_loss: 1.0868 - val_profit_accuracy_2: 0.3731\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0769 - profit_accuracy_2: 0.3931 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3480\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0777 - profit_accuracy_2: 0.3895 - val_loss: 1.0868 - val_profit_accuracy_2: 0.3742\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0765 - profit_accuracy_2: 0.3850 - val_loss: 1.0913 - val_profit_accuracy_2: 0.3266\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0778 - profit_accuracy_2: 0.3816 - val_loss: 1.0921 - val_profit_accuracy_2: 0.3283\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0774 - profit_accuracy_2: 0.3868 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3363\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0766 - profit_accuracy_2: 0.4005 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3651\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0768 - profit_accuracy_2: 0.3913 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3349\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_2: 0.4006 - val_loss: 1.0912 - val_profit_accuracy_2: 0.3140\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0777 - profit_accuracy_2: 0.3826 - val_loss: 1.0866 - val_profit_accuracy_2: 0.4375\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0772 - profit_accuracy_2: 0.3963 - val_loss: 1.0871 - val_profit_accuracy_2: 0.3925\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0766 - profit_accuracy_2: 0.3925 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3492\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3891 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3460\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0764 - profit_accuracy_2: 0.3866 - val_loss: 1.0890 - val_profit_accuracy_2: 0.3454\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0771 - profit_accuracy_2: 0.3885 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3349\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0769 - profit_accuracy_2: 0.3798 - val_loss: 1.0863 - val_profit_accuracy_2: 0.3720\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0764 - profit_accuracy_2: 0.3974 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3429\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3935 - val_loss: 1.0874 - val_profit_accuracy_2: 0.3448\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_2: 0.3923 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3468\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_2: 0.3879 - val_loss: 1.0873 - val_profit_accuracy_2: 0.3851\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0771 - profit_accuracy_2: 0.3798 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3521\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_2: 0.3964 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3535\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3929 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3468\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0764 - profit_accuracy_2: 0.3839 - val_loss: 1.0887 - val_profit_accuracy_2: 0.3362\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0769 - profit_accuracy_2: 0.3937 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3620\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_2: 0.3938 - val_loss: 1.0865 - val_profit_accuracy_2: 0.3812\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy_2: 0.3827 - val_loss: 1.0868 - val_profit_accuracy_2: 0.3855\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_2: 0.3767 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3598\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0770 - profit_accuracy_2: 0.3911 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3188\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0764 - profit_accuracy_2: 0.3764 - val_loss: 1.0874 - val_profit_accuracy_2: 0.4000\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_2: 0.3902 - val_loss: 1.0876 - val_profit_accuracy_2: 0.3581\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0770 - profit_accuracy_2: 0.3803 - val_loss: 1.0909 - val_profit_accuracy_2: 0.3171\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_2: 0.3936 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3613\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy_2: 0.3956 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3659\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0759 - profit_accuracy_2: 0.3895 - val_loss: 1.0874 - val_profit_accuracy_2: 0.3850\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0764 - profit_accuracy_2: 0.3907 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3593\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_2: 0.3882 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3383\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_2: 0.3917 - val_loss: 1.0869 - val_profit_accuracy_2: 0.3974\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3950 - val_loss: 1.0897 - val_profit_accuracy_2: 0.3552\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0761 - profit_accuracy_2: 0.3854 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3719\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_2: 0.3828 - val_loss: 1.0908 - val_profit_accuracy_2: 0.3345\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_2: 0.4021 - val_loss: 1.0869 - val_profit_accuracy_2: 0.3795\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_2: 0.3957 - val_loss: 1.0899 - val_profit_accuracy_2: 0.3394\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_2: 0.3993 - val_loss: 1.0890 - val_profit_accuracy_2: 0.3527\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_2: 0.3834 - val_loss: 1.0893 - val_profit_accuracy_2: 0.3347\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0753 - profit_accuracy_2: 0.3952 - val_loss: 1.0895 - val_profit_accuracy_2: 0.3182\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_2: 0.3828 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3831\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0764 - profit_accuracy_2: 0.3883 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3357\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0753 - profit_accuracy_2: 0.3913 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3416\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0759 - profit_accuracy_2: 0.3930 - val_loss: 1.0928 - val_profit_accuracy_2: 0.3364\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_2: 0.3969 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3734\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_2: 0.3963 - val_loss: 1.0896 - val_profit_accuracy_2: 0.3502\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_2: 0.4002 - val_loss: 1.0889 - val_profit_accuracy_2: 0.3556\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy_2: 0.3922 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3918\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0756 - profit_accuracy_2: 0.3988 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3835\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0751 - profit_accuracy_2: 0.4020 - val_loss: 1.0897 - val_profit_accuracy_2: 0.3574\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_2: 0.3913 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3846\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.4047 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3357\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_2: 0.3832 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3839\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_2: 0.3991 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3466\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_2: 0.3864 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3543\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_2: 0.3890 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3707\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3975 - val_loss: 1.0893 - val_profit_accuracy_2: 0.3387\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0756 - profit_accuracy_2: 0.3935 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3814\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0753 - profit_accuracy_2: 0.3896 - val_loss: 1.0874 - val_profit_accuracy_2: 0.3977\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_2: 0.3999 - val_loss: 1.0898 - val_profit_accuracy_2: 0.3294\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0751 - profit_accuracy_2: 0.3896 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3883\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0753 - profit_accuracy_2: 0.3901 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3829\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0752 - profit_accuracy_2: 0.3881 - val_loss: 1.0880 - val_profit_accuracy_2: 0.3600\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0754 - profit_accuracy_2: 0.3854 - val_loss: 1.0873 - val_profit_accuracy_2: 0.3909\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0751 - profit_accuracy_2: 0.3934 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3892\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_2: 0.3983 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3795\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3950 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3973 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3756\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3906 - val_loss: 1.0925 - val_profit_accuracy_2: 0.3464\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3755 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3670\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3972 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3774\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0746 - profit_accuracy_2: 0.3948 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3858\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0745 - profit_accuracy_2: 0.3990 - val_loss: 1.0921 - val_profit_accuracy_2: 0.3377\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_2: 0.3873 - val_loss: 1.0940 - val_profit_accuracy_2: 0.3409\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_2: 0.3869 - val_loss: 1.0931 - val_profit_accuracy_2: 0.3374\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3899 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3463\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_2: 0.3993 - val_loss: 1.0919 - val_profit_accuracy_2: 0.3441\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_2: 0.3867 - val_loss: 1.0910 - val_profit_accuracy_2: 0.3460\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_2: 0.3902 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3712\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_2: 0.3773 - val_loss: 1.0887 - val_profit_accuracy_2: 0.3455\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0761 - profit_accuracy_2: 0.3880 - val_loss: 1.0880 - val_profit_accuracy_2: 0.3857\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0752 - profit_accuracy_2: 0.3864 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3699\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_2: 0.3914 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3644\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3875 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3600\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0754 - profit_accuracy_2: 0.3924 - val_loss: 1.0891 - val_profit_accuracy_2: 0.3648\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0751 - profit_accuracy_2: 0.3839 - val_loss: 1.0945 - val_profit_accuracy_2: 0.3297\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_2: 0.3778 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3949\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3982 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3613\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_2: 0.3848 - val_loss: 1.0878 - val_profit_accuracy_2: 0.3938\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_2: 0.3916 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3964\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_2: 0.3929 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3702\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0746 - profit_accuracy_2: 0.4027 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3734\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0750 - profit_accuracy_2: 0.3762 - val_loss: 1.0887 - val_profit_accuracy_2: 0.3435\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0748 - profit_accuracy_2: 0.3933 - val_loss: 1.0891 - val_profit_accuracy_2: 0.3669\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0748 - profit_accuracy_2: 0.3970 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3776\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3836 - val_loss: 1.0904 - val_profit_accuracy_2: 0.3477\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3866 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3544\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_2: 0.3939 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3791\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_2: 0.3984 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3534\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0747 - profit_accuracy_2: 0.3898 - val_loss: 1.0898 - val_profit_accuracy_2: 0.3462\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_2: 0.3984 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3625\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0749 - profit_accuracy_2: 0.3968 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3896\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0745 - profit_accuracy_2: 0.3966 - val_loss: 1.0921 - val_profit_accuracy_2: 0.3388\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0743 - profit_accuracy_2: 0.3862 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3587\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0745 - profit_accuracy_2: 0.3917 - val_loss: 1.0913 - val_profit_accuracy_2: 0.3469\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0747 - profit_accuracy_2: 0.3854 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3828\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_2: 0.3935 - val_loss: 1.0903 - val_profit_accuracy_2: 0.3394\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0747 - profit_accuracy_2: 0.3833 - val_loss: 1.0901 - val_profit_accuracy_2: 0.3295\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0748 - profit_accuracy_2: 0.3941 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3597\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_2: 0.3912 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3454\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0746 - profit_accuracy_2: 0.3821 - val_loss: 1.0880 - val_profit_accuracy_2: 0.3814\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_2: 0.4039 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3733\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_2: 0.3989 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3750\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3855 - val_loss: 1.0910 - val_profit_accuracy_2: 0.3356\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0745 - profit_accuracy_2: 0.3933 - val_loss: 1.0892 - val_profit_accuracy_2: 0.3439\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0735 - profit_accuracy_2: 0.3937 - val_loss: 1.0874 - val_profit_accuracy_2: 0.4172\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_2: 0.4024 - val_loss: 1.0891 - val_profit_accuracy_2: 0.3605\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0739 - profit_accuracy_2: 0.3894 - val_loss: 1.0878 - val_profit_accuracy_2: 0.4351\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_2: 0.3969 - val_loss: 1.0889 - val_profit_accuracy_2: 0.3583\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_2: 0.4019 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3604\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0740 - profit_accuracy_2: 0.3947 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3901\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0735 - profit_accuracy_2: 0.3953 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3371\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0738 - profit_accuracy_2: 0.3992 - val_loss: 1.0910 - val_profit_accuracy_2: 0.3357\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_2: 0.3934 - val_loss: 1.0899 - val_profit_accuracy_2: 0.3320\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0740 - profit_accuracy_2: 0.3846 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3987\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0732 - profit_accuracy_2: 0.3969 - val_loss: 1.0917 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0731 - profit_accuracy_2: 0.3942 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3970\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0740 - profit_accuracy_2: 0.3886 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3522\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy_2: 0.4077 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3873\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0734 - profit_accuracy_2: 0.3945 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3548\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0739 - profit_accuracy_2: 0.3992 - val_loss: 1.0882 - val_profit_accuracy_2: 0.4052\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_2: 0.3952 - val_loss: 1.0919 - val_profit_accuracy_2: 0.3367\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_2: 0.4009 - val_loss: 1.0901 - val_profit_accuracy_2: 0.3373\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0732 - profit_accuracy_2: 0.3961 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3616\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_2: 0.3971 - val_loss: 1.0932 - val_profit_accuracy_2: 0.3605\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_2: 0.3868 - val_loss: 1.0914 - val_profit_accuracy_2: 0.3549\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0737 - profit_accuracy_2: 0.3931 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3898\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_2: 0.4040 - val_loss: 1.0892 - val_profit_accuracy_2: 0.3554\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0732 - profit_accuracy_2: 0.3922 - val_loss: 1.0893 - val_profit_accuracy_2: 0.3740\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0731 - profit_accuracy_2: 0.3950 - val_loss: 1.0897 - val_profit_accuracy_2: 0.3360\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy_2: 0.3988 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3581\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0728 - profit_accuracy_2: 0.3906 - val_loss: 1.0904 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0727 - profit_accuracy_2: 0.4004 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3450\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy_2: 0.3968 - val_loss: 1.0934 - val_profit_accuracy_2: 0.3292\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0738 - profit_accuracy_2: 0.3888 - val_loss: 1.0923 - val_profit_accuracy_2: 0.3378\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0728 - profit_accuracy_2: 0.3942 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3636\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0727 - profit_accuracy_2: 0.3948 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3581\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0722 - profit_accuracy_2: 0.3986 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3858\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0738 - profit_accuracy_2: 0.3833 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3762\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Profit_accuracy = 0.3761904835700989\n"
     ]
    }
   ],
   "source": [
    "y_tech = data_tech['target']\n",
    "X_tech = data_tech.drop(columns=['target'])\n",
    "\n",
    "X_train_normalized_tech, X_test_normalized_tech, y_train, y_test = data_normalized(X_tech, y_tech)\n",
    "y_pred, profit_accuracy = train_lstm_model(X_train_normalized_tech, X_test_normalized_tech, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions(me_pred_probs, ti_pred_probs):\n",
    "    combined_pred_probs = []\n",
    "\n",
    "    for me_probs, ti_probs in zip(me_pred_probs, ti_pred_probs):\n",
    "        # If one model's prediction is class_noact, set final decision as class_noact\n",
    "        if np.argmax(me_probs) == 0 or np.argmax(ti_probs) == 0:\n",
    "            combined_pred_probs.append([1, 0, 0])  # class_noact one-hot encoding\n",
    "        # If both models agree on labels, set final decision as this label\n",
    "        elif np.argmax(me_probs) == np.argmax(ti_probs):\n",
    "            combined_pred_probs.append(me_probs)  # Use either model's probabilities\n",
    "        # If predictions of the two models are different, choose the one with higher probability\n",
    "        else:\n",
    "            max_prob_index = np.argmax([np.max(me_probs), np.max(ti_probs)])\n",
    "            if max_prob_index == 0:\n",
    "                combined_pred_probs.append(me_probs)  # Use ME_LSTM's probabilities\n",
    "            else:\n",
    "                combined_pred_probs.append(ti_probs)  # Use TI_LSTM's probabilities\n",
    "\n",
    "    return np.array(combined_pred_probs)\n",
    "\n",
    "\n",
    "def train_lstm_model_combine(X_train_eco, X_test_eco, X_train_tech, X_test_tech, y_train, y_test, lstm_units=lstm_units, epochs=epochs, batch_size=batch_size):\n",
    "    # Train ME_LSTM model\n",
    "    me_pred_probs, _ = train_lstm_model(X_train_eco, X_test_eco, y_train, y_test, lstm_units, epochs, batch_size)\n",
    "\n",
    "    # Train TI_LSTM model\n",
    "    # ti_pred_probs, _ = train_lstm_model(X_train_tech, X_test_tech, y_train, y_test, lstm_units, epochs, batch_size)\n",
    "    ti_pred_probs, _ = train_lstm_model(X_train_tech, X_test_tech, y_train, y_test, lstm_units, epochs, batch_size)\n",
    "\n",
    "    # Combine predictions\n",
    "    combined_pred_probs = combine_predictions(me_pred_probs, ti_pred_probs)\n",
    "\n",
    "    # Convert y_test to one-hot encoding\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y_train)\n",
    "    encoded_y_test = encoder.transform(y_test)\n",
    "    y_test_onehot = to_categorical(encoded_y_test)\n",
    "\n",
    "    # Evaluate the combined model using ProfitAccuracy metric\n",
    "    profit_accuracy = ProfitAccuracy()(y_test_onehot, combined_pred_probs)\n",
    "    print(f\"Combine profit_accuracy = {profit_accuracy}\")\n",
    "\n",
    "    return combined_pred_probs, profit_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "59/59 [==============================] - 2s 13ms/step - loss: 1.0919 - profit_accuracy_4: 0.3625 - val_loss: 1.0821 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0836 - profit_accuracy_4: 0.3747 - val_loss: 1.0840 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0802 - profit_accuracy_4: 0.3920 - val_loss: 1.1129 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0791 - profit_accuracy_4: 0.3710 - val_loss: 1.1164 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0785 - profit_accuracy_4: 0.3838 - val_loss: 1.0975 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0779 - profit_accuracy_4: 0.3841 - val_loss: 1.1144 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0783 - profit_accuracy_4: 0.3821 - val_loss: 1.1054 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0776 - profit_accuracy_4: 0.3873 - val_loss: 1.1038 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0776 - profit_accuracy_4: 0.3826 - val_loss: 1.1051 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_4: 0.3905 - val_loss: 1.1187 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_4: 0.3857 - val_loss: 1.1216 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0761 - profit_accuracy_4: 0.3852 - val_loss: 1.1230 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_4: 0.3800 - val_loss: 1.1313 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_4: 0.3857 - val_loss: 1.1124 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0746 - profit_accuracy_4: 0.3929 - val_loss: 1.1110 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_4: 0.4000 - val_loss: 1.1256 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_4: 0.3914 - val_loss: 1.1598 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_4: 0.3995 - val_loss: 1.1614 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0735 - profit_accuracy_4: 0.3931 - val_loss: 1.1292 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0742 - profit_accuracy_4: 0.3953 - val_loss: 1.1422 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_4: 0.3900 - val_loss: 1.1213 - val_profit_accuracy_4: 0.3000\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy_4: 0.3913 - val_loss: 1.1683 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0728 - profit_accuracy_4: 0.3991 - val_loss: 1.1412 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0729 - profit_accuracy_4: 0.4011 - val_loss: 1.1160 - val_profit_accuracy_4: 0.3478\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0735 - profit_accuracy_4: 0.3914 - val_loss: 1.1778 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0729 - profit_accuracy_4: 0.3977 - val_loss: 1.1528 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0724 - profit_accuracy_4: 0.4008 - val_loss: 1.1205 - val_profit_accuracy_4: 0.3500\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0726 - profit_accuracy_4: 0.3878 - val_loss: 1.1820 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy_4: 0.3920 - val_loss: 1.1556 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0726 - profit_accuracy_4: 0.3988 - val_loss: 1.1861 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0731 - profit_accuracy_4: 0.4013 - val_loss: 1.1389 - val_profit_accuracy_4: 0.3548\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0728 - profit_accuracy_4: 0.3866 - val_loss: 1.1594 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0722 - profit_accuracy_4: 0.3928 - val_loss: 1.1499 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy_4: 0.3903 - val_loss: 1.1478 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0722 - profit_accuracy_4: 0.3933 - val_loss: 1.1332 - val_profit_accuracy_4: 0.4286\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0715 - profit_accuracy_4: 0.3883 - val_loss: 1.1664 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0723 - profit_accuracy_4: 0.3871 - val_loss: 1.1781 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy_4: 0.3965 - val_loss: 1.2010 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0723 - profit_accuracy_4: 0.3921 - val_loss: 1.1692 - val_profit_accuracy_4: 0.2941\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0712 - profit_accuracy_4: 0.3966 - val_loss: 1.1304 - val_profit_accuracy_4: 0.3786\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0721 - profit_accuracy_4: 0.3881 - val_loss: 1.2568 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0725 - profit_accuracy_4: 0.3978 - val_loss: 1.1458 - val_profit_accuracy_4: 0.3750\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0713 - profit_accuracy_4: 0.3864 - val_loss: 1.2260 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0721 - profit_accuracy_4: 0.3991 - val_loss: 1.1417 - val_profit_accuracy_4: 0.3878\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0727 - profit_accuracy_4: 0.3870 - val_loss: 1.1966 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0716 - profit_accuracy_4: 0.3887 - val_loss: 1.2485 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0718 - profit_accuracy_4: 0.3886 - val_loss: 1.1430 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0712 - profit_accuracy_4: 0.3948 - val_loss: 1.1653 - val_profit_accuracy_4: 0.3000\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0712 - profit_accuracy_4: 0.3951 - val_loss: 1.2002 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0711 - profit_accuracy_4: 0.3922 - val_loss: 1.2150 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0709 - profit_accuracy_4: 0.3968 - val_loss: 1.1771 - val_profit_accuracy_4: 0.2941\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0706 - profit_accuracy_4: 0.3972 - val_loss: 1.1532 - val_profit_accuracy_4: 0.3182\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0712 - profit_accuracy_4: 0.3933 - val_loss: 1.1977 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0708 - profit_accuracy_4: 0.3916 - val_loss: 1.1627 - val_profit_accuracy_4: 0.3600\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0713 - profit_accuracy_4: 0.3921 - val_loss: 1.1887 - val_profit_accuracy_4: 0.3077\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0704 - profit_accuracy_4: 0.4023 - val_loss: 1.1582 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0704 - profit_accuracy_4: 0.3918 - val_loss: 1.1964 - val_profit_accuracy_4: 0.3077\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0712 - profit_accuracy_4: 0.3955 - val_loss: 1.2040 - val_profit_accuracy_4: 0.4000\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0704 - profit_accuracy_4: 0.3886 - val_loss: 1.1956 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0703 - profit_accuracy_4: 0.3944 - val_loss: 1.2260 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0699 - profit_accuracy_4: 0.3971 - val_loss: 1.2477 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0709 - profit_accuracy_4: 0.3970 - val_loss: 1.2574 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0706 - profit_accuracy_4: 0.3950 - val_loss: 1.1739 - val_profit_accuracy_4: 0.4074\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0704 - profit_accuracy_4: 0.3938 - val_loss: 1.1634 - val_profit_accuracy_4: 0.3704\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy_4: 0.3990 - val_loss: 1.1777 - val_profit_accuracy_4: 0.3750\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy_4: 0.3975 - val_loss: 1.1976 - val_profit_accuracy_4: 0.3125\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0708 - profit_accuracy_4: 0.3907 - val_loss: 1.1790 - val_profit_accuracy_4: 0.3600\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0707 - profit_accuracy_4: 0.3899 - val_loss: 1.2344 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0704 - profit_accuracy_4: 0.4035 - val_loss: 1.1982 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0701 - profit_accuracy_4: 0.3929 - val_loss: 1.2306 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0704 - profit_accuracy_4: 0.4003 - val_loss: 1.1774 - val_profit_accuracy_4: 0.3448\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0701 - profit_accuracy_4: 0.3926 - val_loss: 1.2405 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0694 - profit_accuracy_4: 0.3840 - val_loss: 1.2638 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy_4: 0.3912 - val_loss: 1.1596 - val_profit_accuracy_4: 0.3906\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0705 - profit_accuracy_4: 0.3981 - val_loss: 1.2288 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy_4: 0.4017 - val_loss: 1.1644 - val_profit_accuracy_4: 0.2941\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy_4: 0.3934 - val_loss: 1.1728 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy_4: 0.3944 - val_loss: 1.2171 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0703 - profit_accuracy_4: 0.4003 - val_loss: 1.2741 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0706 - profit_accuracy_4: 0.3884 - val_loss: 1.2162 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy_4: 0.3926 - val_loss: 1.2483 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy_4: 0.4034 - val_loss: 1.1859 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0695 - profit_accuracy_4: 0.3932 - val_loss: 1.1662 - val_profit_accuracy_4: 0.3500\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0702 - profit_accuracy_4: 0.3967 - val_loss: 1.2743 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0706 - profit_accuracy_4: 0.3994 - val_loss: 1.2041 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy_4: 0.3992 - val_loss: 1.1972 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy_4: 0.4045 - val_loss: 1.2133 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0699 - profit_accuracy_4: 0.3978 - val_loss: 1.2330 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0690 - profit_accuracy_4: 0.3968 - val_loss: 1.2206 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0696 - profit_accuracy_4: 0.3985 - val_loss: 1.1781 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0703 - profit_accuracy_4: 0.4026 - val_loss: 1.2241 - val_profit_accuracy_4: 0.3125\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0692 - profit_accuracy_4: 0.4027 - val_loss: 1.1677 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy_4: 0.3983 - val_loss: 1.1535 - val_profit_accuracy_4: 0.3932\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0695 - profit_accuracy_4: 0.4020 - val_loss: 1.1757 - val_profit_accuracy_4: 0.2647\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0691 - profit_accuracy_4: 0.4029 - val_loss: 1.2490 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0688 - profit_accuracy_4: 0.3977 - val_loss: 1.1883 - val_profit_accuracy_4: 0.3462\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0690 - profit_accuracy_4: 0.4005 - val_loss: 1.2343 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0690 - profit_accuracy_4: 0.4031 - val_loss: 1.2090 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0690 - profit_accuracy_4: 0.3968 - val_loss: 1.2512 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0700 - profit_accuracy_4: 0.3949 - val_loss: 1.1982 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0687 - profit_accuracy_4: 0.3998 - val_loss: 1.2332 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0695 - profit_accuracy_4: 0.4061 - val_loss: 1.1975 - val_profit_accuracy_4: 0.3077\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0689 - profit_accuracy_4: 0.3963 - val_loss: 1.2148 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy_4: 0.3999 - val_loss: 1.2536 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0686 - profit_accuracy_4: 0.3966 - val_loss: 1.1906 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0691 - profit_accuracy_4: 0.3952 - val_loss: 1.1779 - val_profit_accuracy_4: 0.3871\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0691 - profit_accuracy_4: 0.3982 - val_loss: 1.2042 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0690 - profit_accuracy_4: 0.4030 - val_loss: 1.2023 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0692 - profit_accuracy_4: 0.3979 - val_loss: 1.2169 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0685 - profit_accuracy_4: 0.4041 - val_loss: 1.2164 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy_4: 0.4009 - val_loss: 1.2158 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0681 - profit_accuracy_4: 0.4004 - val_loss: 1.1563 - val_profit_accuracy_4: 0.3803\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0697 - profit_accuracy_4: 0.4035 - val_loss: 1.2176 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0698 - profit_accuracy_4: 0.4052 - val_loss: 1.2051 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0687 - profit_accuracy_4: 0.4022 - val_loss: 1.1531 - val_profit_accuracy_4: 0.2933\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0688 - profit_accuracy_4: 0.3923 - val_loss: 1.2403 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0693 - profit_accuracy_4: 0.4014 - val_loss: 1.2515 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.0681 - profit_accuracy_4: 0.4054 - val_loss: 1.1909 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 1.0683 - profit_accuracy_4: 0.4054 - val_loss: 1.2342 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 1.0686 - profit_accuracy_4: 0.4032 - val_loss: 1.2037 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 1.0690 - profit_accuracy_4: 0.3881 - val_loss: 1.2112 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0694 - profit_accuracy_4: 0.4009 - val_loss: 1.1630 - val_profit_accuracy_4: 0.3103\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0680 - profit_accuracy_4: 0.4026 - val_loss: 1.2323 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0687 - profit_accuracy_4: 0.3976 - val_loss: 1.2603 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0690 - profit_accuracy_4: 0.3979 - val_loss: 1.2139 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0686 - profit_accuracy_4: 0.3960 - val_loss: 1.1945 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0678 - profit_accuracy_4: 0.4116 - val_loss: 1.1735 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0685 - profit_accuracy_4: 0.4029 - val_loss: 1.1572 - val_profit_accuracy_4: 0.3866\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0688 - profit_accuracy_4: 0.4035 - val_loss: 1.2578 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0681 - profit_accuracy_4: 0.3999 - val_loss: 1.1820 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.0681 - profit_accuracy_4: 0.4026 - val_loss: 1.1795 - val_profit_accuracy_4: 0.4194\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.0682 - profit_accuracy_4: 0.4028 - val_loss: 1.2318 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.0682 - profit_accuracy_4: 0.4045 - val_loss: 1.2212 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.0686 - profit_accuracy_4: 0.4019 - val_loss: 1.2064 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0681 - profit_accuracy_4: 0.4031 - val_loss: 1.1810 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0682 - profit_accuracy_4: 0.3959 - val_loss: 1.1681 - val_profit_accuracy_4: 0.3906\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0689 - profit_accuracy_4: 0.3942 - val_loss: 1.1524 - val_profit_accuracy_4: 0.3718\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0687 - profit_accuracy_4: 0.3900 - val_loss: 1.2664 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0695 - profit_accuracy_4: 0.4058 - val_loss: 1.2065 - val_profit_accuracy_4: 0.4000\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy_4: 0.3948 - val_loss: 1.1920 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0684 - profit_accuracy_4: 0.4040 - val_loss: 1.1827 - val_profit_accuracy_4: 0.3478\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0682 - profit_accuracy_4: 0.4131 - val_loss: 1.1788 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0674 - profit_accuracy_4: 0.4110 - val_loss: 1.1792 - val_profit_accuracy_4: 0.5294\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0681 - profit_accuracy_4: 0.4043 - val_loss: 1.1902 - val_profit_accuracy_4: 0.3500\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0680 - profit_accuracy_4: 0.4025 - val_loss: 1.2357 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0678 - profit_accuracy_4: 0.4055 - val_loss: 1.1853 - val_profit_accuracy_4: 0.2941\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0680 - profit_accuracy_4: 0.4015 - val_loss: 1.2013 - val_profit_accuracy_4: 0.3125\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0683 - profit_accuracy_4: 0.4026 - val_loss: 1.1961 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0679 - profit_accuracy_4: 0.4019 - val_loss: 1.1992 - val_profit_accuracy_4: 0.3571\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy_4: 0.4093 - val_loss: 1.1871 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy_4: 0.4055 - val_loss: 1.1764 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0678 - profit_accuracy_4: 0.4112 - val_loss: 1.2227 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0677 - profit_accuracy_4: 0.4118 - val_loss: 1.2668 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0682 - profit_accuracy_4: 0.4056 - val_loss: 1.2359 - val_profit_accuracy_4: 0.4000\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0671 - profit_accuracy_4: 0.4057 - val_loss: 1.2025 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0676 - profit_accuracy_4: 0.4025 - val_loss: 1.1973 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy_4: 0.4045 - val_loss: 1.2278 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0677 - profit_accuracy_4: 0.4038 - val_loss: 1.2190 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0680 - profit_accuracy_4: 0.4032 - val_loss: 1.1983 - val_profit_accuracy_4: 0.4444\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy_4: 0.3951 - val_loss: 1.2132 - val_profit_accuracy_4: 0.3125\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0686 - profit_accuracy_4: 0.4076 - val_loss: 1.1629 - val_profit_accuracy_4: 0.5357\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0672 - profit_accuracy_4: 0.3988 - val_loss: 1.2089 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy_4: 0.4016 - val_loss: 1.1814 - val_profit_accuracy_4: 0.5500\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0676 - profit_accuracy_4: 0.4019 - val_loss: 1.2061 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0676 - profit_accuracy_4: 0.3976 - val_loss: 1.1711 - val_profit_accuracy_4: 0.4000\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0666 - profit_accuracy_4: 0.4085 - val_loss: 1.1346 - val_profit_accuracy_4: 0.3874\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0678 - profit_accuracy_4: 0.4088 - val_loss: 1.1660 - val_profit_accuracy_4: 0.3953\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0669 - profit_accuracy_4: 0.4032 - val_loss: 1.1836 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0683 - profit_accuracy_4: 0.4068 - val_loss: 1.1850 - val_profit_accuracy_4: 0.3929\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0674 - profit_accuracy_4: 0.4064 - val_loss: 1.1725 - val_profit_accuracy_4: 0.5312\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0670 - profit_accuracy_4: 0.4019 - val_loss: 1.1743 - val_profit_accuracy_4: 0.4800\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0668 - profit_accuracy_4: 0.4127 - val_loss: 1.1800 - val_profit_accuracy_4: 0.4545\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0672 - profit_accuracy_4: 0.4076 - val_loss: 1.1837 - val_profit_accuracy_4: 0.2917\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0663 - profit_accuracy_4: 0.4164 - val_loss: 1.1502 - val_profit_accuracy_4: 0.3871\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0669 - profit_accuracy_4: 0.4044 - val_loss: 1.1868 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0673 - profit_accuracy_4: 0.4099 - val_loss: 1.1717 - val_profit_accuracy_4: 0.3548\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy_4: 0.4067 - val_loss: 1.1559 - val_profit_accuracy_4: 0.4211\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0667 - profit_accuracy_4: 0.4099 - val_loss: 1.1420 - val_profit_accuracy_4: 0.4154\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0667 - profit_accuracy_4: 0.4026 - val_loss: 1.1935 - val_profit_accuracy_4: 0.4667\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0664 - profit_accuracy_4: 0.4036 - val_loss: 1.1714 - val_profit_accuracy_4: 0.3871\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0663 - profit_accuracy_4: 0.4124 - val_loss: 1.1540 - val_profit_accuracy_4: 0.3958\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0663 - profit_accuracy_4: 0.4060 - val_loss: 1.1517 - val_profit_accuracy_4: 0.4127\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0674 - profit_accuracy_4: 0.4098 - val_loss: 1.1547 - val_profit_accuracy_4: 0.3962\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0675 - profit_accuracy_4: 0.4009 - val_loss: 1.1686 - val_profit_accuracy_4: 0.3448\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0666 - profit_accuracy_4: 0.4047 - val_loss: 1.1949 - val_profit_accuracy_4: 0.6000\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0673 - profit_accuracy_4: 0.4124 - val_loss: 1.1549 - val_profit_accuracy_4: 0.5102\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0662 - profit_accuracy_4: 0.4155 - val_loss: 1.1844 - val_profit_accuracy_4: 0.4167\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0669 - profit_accuracy_4: 0.4091 - val_loss: 1.1833 - val_profit_accuracy_4: 0.3043\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0665 - profit_accuracy_4: 0.4083 - val_loss: 1.1831 - val_profit_accuracy_4: 0.4138\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0666 - profit_accuracy_4: 0.4083 - val_loss: 1.1971 - val_profit_accuracy_4: 0.3600\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy_4: 0.4039 - val_loss: 1.1486 - val_profit_accuracy_4: 0.4167\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0664 - profit_accuracy_4: 0.4038 - val_loss: 1.1625 - val_profit_accuracy_4: 0.4412\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0667 - profit_accuracy_4: 0.4093 - val_loss: 1.1730 - val_profit_accuracy_4: 0.3600\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0668 - profit_accuracy_4: 0.4084 - val_loss: 1.1473 - val_profit_accuracy_4: 0.4127\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0666 - profit_accuracy_4: 0.4127 - val_loss: 1.1605 - val_profit_accuracy_4: 0.4516\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0658 - profit_accuracy_4: 0.4271 - val_loss: 1.1453 - val_profit_accuracy_4: 0.4314\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0659 - profit_accuracy_4: 0.4100 - val_loss: 1.1654 - val_profit_accuracy_4: 0.4474\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0654 - profit_accuracy_4: 0.4140 - val_loss: 1.1636 - val_profit_accuracy_4: 0.4634\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0661 - profit_accuracy_4: 0.4060 - val_loss: 1.1712 - val_profit_accuracy_4: 0.3947\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0652 - profit_accuracy_4: 0.4132 - val_loss: 1.1496 - val_profit_accuracy_4: 0.4167\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Profit_accuracy = 0.4166666567325592\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 2s 13ms/step - loss: 1.0959 - profit_accuracy_6: 0.3464 - val_loss: 1.1034 - val_profit_accuracy_6: 0.2839\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0918 - profit_accuracy_6: 0.3579 - val_loss: 1.0933 - val_profit_accuracy_6: 0.3433\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0897 - profit_accuracy_6: 0.3551 - val_loss: 1.0927 - val_profit_accuracy_6: 0.3846\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0870 - profit_accuracy_6: 0.3704 - val_loss: 1.0899 - val_profit_accuracy_6: 0.2500\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0855 - profit_accuracy_6: 0.3606 - val_loss: 1.0899 - val_profit_accuracy_6: 0.2727\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0831 - profit_accuracy_6: 0.3754 - val_loss: 1.0881 - val_profit_accuracy_6: 0.2500\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0819 - profit_accuracy_6: 0.3845 - val_loss: 1.0884 - val_profit_accuracy_6: 0.2698\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0811 - profit_accuracy_6: 0.3702 - val_loss: 1.0891 - val_profit_accuracy_6: 0.2900\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0801 - profit_accuracy_6: 0.3858 - val_loss: 1.0858 - val_profit_accuracy_6: 0.2581\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0802 - profit_accuracy_6: 0.3970 - val_loss: 1.0876 - val_profit_accuracy_6: 0.2821\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0793 - profit_accuracy_6: 0.3889 - val_loss: 1.0859 - val_profit_accuracy_6: 0.3684\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0801 - profit_accuracy_6: 0.3952 - val_loss: 1.0874 - val_profit_accuracy_6: 0.2830\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0797 - profit_accuracy_6: 0.3765 - val_loss: 1.0875 - val_profit_accuracy_6: 0.3143\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0796 - profit_accuracy_6: 0.3876 - val_loss: 1.0915 - val_profit_accuracy_6: 0.3319\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0795 - profit_accuracy_6: 0.3841 - val_loss: 1.0865 - val_profit_accuracy_6: 0.3462\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_6: 0.3949 - val_loss: 1.0869 - val_profit_accuracy_6: 0.3070\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0791 - profit_accuracy_6: 0.3825 - val_loss: 1.0875 - val_profit_accuracy_6: 0.3274\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0786 - profit_accuracy_6: 0.3881 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3776\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0794 - profit_accuracy_6: 0.3812 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3359\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_6: 0.3924 - val_loss: 1.0865 - val_profit_accuracy_6: 0.3562\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0785 - profit_accuracy_6: 0.3913 - val_loss: 1.0866 - val_profit_accuracy_6: 0.3636\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0781 - profit_accuracy_6: 0.3914 - val_loss: 1.0863 - val_profit_accuracy_6: 0.3571\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0787 - profit_accuracy_6: 0.4069 - val_loss: 1.0869 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0782 - profit_accuracy_6: 0.3934 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3494\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0789 - profit_accuracy_6: 0.3802 - val_loss: 1.0900 - val_profit_accuracy_6: 0.3413\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0785 - profit_accuracy_6: 0.3931 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3394\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0780 - profit_accuracy_6: 0.3910 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3673\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0782 - profit_accuracy_6: 0.3928 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3370\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_6: 0.3907 - val_loss: 1.0867 - val_profit_accuracy_6: 0.3976\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0782 - profit_accuracy_6: 0.3883 - val_loss: 1.0878 - val_profit_accuracy_6: 0.3654\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0776 - profit_accuracy_6: 0.4051 - val_loss: 1.0861 - val_profit_accuracy_6: 0.3810\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0779 - profit_accuracy_6: 0.3927 - val_loss: 1.0860 - val_profit_accuracy_6: 0.3725\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0797 - profit_accuracy_6: 0.3942 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3459\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0777 - profit_accuracy_6: 0.4003 - val_loss: 1.0863 - val_profit_accuracy_6: 0.3556\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_6: 0.3884 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3545\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0791 - profit_accuracy_6: 0.3969 - val_loss: 1.0870 - val_profit_accuracy_6: 0.3567\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0781 - profit_accuracy_6: 0.3820 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3474\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0774 - profit_accuracy_6: 0.3965 - val_loss: 1.0872 - val_profit_accuracy_6: 0.3648\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0774 - profit_accuracy_6: 0.3915 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3533\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0783 - profit_accuracy_6: 0.3972 - val_loss: 1.0867 - val_profit_accuracy_6: 0.3869\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0775 - profit_accuracy_6: 0.3933 - val_loss: 1.0869 - val_profit_accuracy_6: 0.4085\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_6: 0.3889 - val_loss: 1.0863 - val_profit_accuracy_6: 0.4369\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0770 - profit_accuracy_6: 0.3938 - val_loss: 1.0869 - val_profit_accuracy_6: 0.3600\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_6: 0.3975 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3321\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0768 - profit_accuracy_6: 0.3826 - val_loss: 1.0868 - val_profit_accuracy_6: 0.3895\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0776 - profit_accuracy_6: 0.4028 - val_loss: 1.0863 - val_profit_accuracy_6: 0.4000\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_6: 0.3919 - val_loss: 1.0865 - val_profit_accuracy_6: 0.3963\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy_6: 0.3883 - val_loss: 1.0871 - val_profit_accuracy_6: 0.3714\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0777 - profit_accuracy_6: 0.3875 - val_loss: 1.0865 - val_profit_accuracy_6: 0.4365\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0769 - profit_accuracy_6: 0.3884 - val_loss: 1.0910 - val_profit_accuracy_6: 0.3447\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0789 - profit_accuracy_6: 0.3961 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3145\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0774 - profit_accuracy_6: 0.3842 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3825\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0769 - profit_accuracy_6: 0.3929 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3438\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0773 - profit_accuracy_6: 0.3963 - val_loss: 1.0867 - val_profit_accuracy_6: 0.4236\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy_6: 0.3860 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3925\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0758 - profit_accuracy_6: 0.3865 - val_loss: 1.0907 - val_profit_accuracy_6: 0.3151\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0770 - profit_accuracy_6: 0.3757 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3436\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_6: 0.3899 - val_loss: 1.0871 - val_profit_accuracy_6: 0.3913\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3809 - val_loss: 1.0868 - val_profit_accuracy_6: 0.3889\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0774 - profit_accuracy_6: 0.3921 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3186\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy_6: 0.3935 - val_loss: 1.0863 - val_profit_accuracy_6: 0.4370\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0772 - profit_accuracy_6: 0.3940 - val_loss: 1.0878 - val_profit_accuracy_6: 0.3575\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_6: 0.3795 - val_loss: 1.0867 - val_profit_accuracy_6: 0.4091\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_6: 0.3895 - val_loss: 1.0897 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy_6: 0.3838 - val_loss: 1.0900 - val_profit_accuracy_6: 0.3455\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3825 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3417\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3898 - val_loss: 1.0868 - val_profit_accuracy_6: 0.3791\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy_6: 0.3986 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3484\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0770 - profit_accuracy_6: 0.3843 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3380\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0760 - profit_accuracy_6: 0.3876 - val_loss: 1.0868 - val_profit_accuracy_6: 0.4434\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3960 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3657\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0769 - profit_accuracy_6: 0.3864 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3627\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_6: 0.3868 - val_loss: 1.0877 - val_profit_accuracy_6: 0.3744\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0759 - profit_accuracy_6: 0.3967 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3816\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0758 - profit_accuracy_6: 0.3872 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3381\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0761 - profit_accuracy_6: 0.3976 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3565\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_6: 0.3894 - val_loss: 1.0873 - val_profit_accuracy_6: 0.4124\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_6: 0.3875 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3636\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_6: 0.3765 - val_loss: 1.0926 - val_profit_accuracy_6: 0.3374\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_6: 0.3920 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3829\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3932 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3597\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0764 - profit_accuracy_6: 0.3939 - val_loss: 1.0894 - val_profit_accuracy_6: 0.3520\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3805 - val_loss: 1.0895 - val_profit_accuracy_6: 0.3321\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_6: 0.3925 - val_loss: 1.0941 - val_profit_accuracy_6: 0.3409\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3866 - val_loss: 1.0896 - val_profit_accuracy_6: 0.3577\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0760 - profit_accuracy_6: 0.3947 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3673\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0761 - profit_accuracy_6: 0.3933 - val_loss: 1.0895 - val_profit_accuracy_6: 0.3563\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3923 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3364\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0756 - profit_accuracy_6: 0.3957 - val_loss: 1.0874 - val_profit_accuracy_6: 0.3989\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0756 - profit_accuracy_6: 0.3941 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3394\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0766 - profit_accuracy_6: 0.3883 - val_loss: 1.0915 - val_profit_accuracy_6: 0.3344\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0767 - profit_accuracy_6: 0.3877 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3654\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3953 - val_loss: 1.0876 - val_profit_accuracy_6: 0.3756\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0757 - profit_accuracy_6: 0.3995 - val_loss: 1.0915 - val_profit_accuracy_6: 0.3432\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0759 - profit_accuracy_6: 0.3936 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3532\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0754 - profit_accuracy_6: 0.3937 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3559\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_6: 0.3869 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3432\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0758 - profit_accuracy_6: 0.3891 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3428\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_6: 0.3904 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3877\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0760 - profit_accuracy_6: 0.3923 - val_loss: 1.0875 - val_profit_accuracy_6: 0.3936\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0759 - profit_accuracy_6: 0.3908 - val_loss: 1.0873 - val_profit_accuracy_6: 0.4035\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3990 - val_loss: 1.0891 - val_profit_accuracy_6: 0.3534\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3837 - val_loss: 1.0890 - val_profit_accuracy_6: 0.3247\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_6: 0.3863 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3733\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3914 - val_loss: 1.0880 - val_profit_accuracy_6: 0.3869\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0753 - profit_accuracy_6: 0.3923 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3529\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_6: 0.3775 - val_loss: 1.0904 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3912 - val_loss: 1.0877 - val_profit_accuracy_6: 0.3807\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_6: 0.3871 - val_loss: 1.0875 - val_profit_accuracy_6: 0.3858\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0750 - profit_accuracy_6: 0.3890 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3805\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0759 - profit_accuracy_6: 0.3936 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3958\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0758 - profit_accuracy_6: 0.3911 - val_loss: 1.0884 - val_profit_accuracy_6: 0.3621\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0753 - profit_accuracy_6: 0.3934 - val_loss: 1.0900 - val_profit_accuracy_6: 0.3284\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_6: 0.3929 - val_loss: 1.0878 - val_profit_accuracy_6: 0.3465\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3894 - val_loss: 1.0927 - val_profit_accuracy_6: 0.3343\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_6: 0.3856 - val_loss: 1.0878 - val_profit_accuracy_6: 0.3786\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0753 - profit_accuracy_6: 0.3890 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3761\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_6: 0.3785 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3497\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_6: 0.3913 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3419\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_6: 0.3904 - val_loss: 1.0917 - val_profit_accuracy_6: 0.3378\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0750 - profit_accuracy_6: 0.3998 - val_loss: 1.0884 - val_profit_accuracy_6: 0.3649\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0756 - profit_accuracy_6: 0.3881 - val_loss: 1.0901 - val_profit_accuracy_6: 0.3320\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_6: 0.3939 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3502\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0753 - profit_accuracy_6: 0.3904 - val_loss: 1.0884 - val_profit_accuracy_6: 0.3750\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_6: 0.3961 - val_loss: 1.0874 - val_profit_accuracy_6: 0.3918\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0751 - profit_accuracy_6: 0.3893 - val_loss: 1.0880 - val_profit_accuracy_6: 0.3767\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3941 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3415\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_6: 0.3921 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3432\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0749 - profit_accuracy_6: 0.3942 - val_loss: 1.0887 - val_profit_accuracy_6: 0.3613\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3947 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3482\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_6: 0.3914 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3756\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3893 - val_loss: 1.0926 - val_profit_accuracy_6: 0.3354\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_6: 0.3894 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3799\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0748 - profit_accuracy_6: 0.3836 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3738\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3886 - val_loss: 1.0896 - val_profit_accuracy_6: 0.3597\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0753 - profit_accuracy_6: 0.3925 - val_loss: 1.0908 - val_profit_accuracy_6: 0.3483\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0751 - profit_accuracy_6: 0.3910 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3812\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_6: 0.3929 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3710\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0743 - profit_accuracy_6: 0.3924 - val_loss: 1.0902 - val_profit_accuracy_6: 0.3494\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_6: 0.3782 - val_loss: 1.0890 - val_profit_accuracy_6: 0.3777\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0746 - profit_accuracy_6: 0.3913 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3476\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3888 - val_loss: 1.0947 - val_profit_accuracy_6: 0.3187\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_6: 0.3888 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3460\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0745 - profit_accuracy_6: 0.3904 - val_loss: 1.0899 - val_profit_accuracy_6: 0.3386\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_6: 0.3963 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3765\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_6: 0.3886 - val_loss: 1.0884 - val_profit_accuracy_6: 0.3761\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_6: 0.3952 - val_loss: 1.0912 - val_profit_accuracy_6: 0.3471\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_6: 0.3977 - val_loss: 1.0880 - val_profit_accuracy_6: 0.3679\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0748 - profit_accuracy_6: 0.4002 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3857\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_6: 0.3912 - val_loss: 1.0897 - val_profit_accuracy_6: 0.3398\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0743 - profit_accuracy_6: 0.3850 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3455\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_6: 0.3941 - val_loss: 1.0880 - val_profit_accuracy_6: 0.4559\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0745 - profit_accuracy_6: 0.3948 - val_loss: 1.0893 - val_profit_accuracy_6: 0.3583\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0751 - profit_accuracy_6: 0.3779 - val_loss: 1.0880 - val_profit_accuracy_6: 0.3855\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_6: 0.3920 - val_loss: 1.0897 - val_profit_accuracy_6: 0.3425\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_6: 0.3966 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3296\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_6: 0.3936 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3816\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3893 - val_loss: 1.0893 - val_profit_accuracy_6: 0.3644\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0755 - profit_accuracy_6: 0.3832 - val_loss: 1.0925 - val_profit_accuracy_6: 0.3376\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0743 - profit_accuracy_6: 0.4004 - val_loss: 1.0913 - val_profit_accuracy_6: 0.3514\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0744 - profit_accuracy_6: 0.3952 - val_loss: 1.0896 - val_profit_accuracy_6: 0.3440\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_6: 0.3896 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3723\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_6: 0.3992 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3955\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0740 - profit_accuracy_6: 0.3959 - val_loss: 1.0912 - val_profit_accuracy_6: 0.3309\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0748 - profit_accuracy_6: 0.3916 - val_loss: 1.0909 - val_profit_accuracy_6: 0.3345\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0738 - profit_accuracy_6: 0.3914 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3886\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0745 - profit_accuracy_6: 0.3867 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3895\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0747 - profit_accuracy_6: 0.3983 - val_loss: 1.0879 - val_profit_accuracy_6: 0.4122\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0745 - profit_accuracy_6: 0.3873 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3934\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_6: 0.3842 - val_loss: 1.0891 - val_profit_accuracy_6: 0.3691\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0738 - profit_accuracy_6: 0.4025 - val_loss: 1.0927 - val_profit_accuracy_6: 0.3407\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0746 - profit_accuracy_6: 0.3882 - val_loss: 1.0886 - val_profit_accuracy_6: 0.3632\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0745 - profit_accuracy_6: 0.3920 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3923\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_6: 0.3973 - val_loss: 1.0900 - val_profit_accuracy_6: 0.3253\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0739 - profit_accuracy_6: 0.3917 - val_loss: 1.0909 - val_profit_accuracy_6: 0.3321\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0738 - profit_accuracy_6: 0.3940 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3886\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_6: 0.3914 - val_loss: 1.0891 - val_profit_accuracy_6: 0.3480\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0735 - profit_accuracy_6: 0.4016 - val_loss: 1.0924 - val_profit_accuracy_6: 0.3487\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0733 - profit_accuracy_6: 0.4038 - val_loss: 1.0908 - val_profit_accuracy_6: 0.3296\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_6: 0.3936 - val_loss: 1.0895 - val_profit_accuracy_6: 0.3648\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0735 - profit_accuracy_6: 0.3944 - val_loss: 1.0904 - val_profit_accuracy_6: 0.3545\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0743 - profit_accuracy_6: 0.3913 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3640\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0735 - profit_accuracy_6: 0.3916 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3915\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_6: 0.3973 - val_loss: 1.0896 - val_profit_accuracy_6: 0.3603\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0733 - profit_accuracy_6: 0.3979 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3627\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0733 - profit_accuracy_6: 0.3961 - val_loss: 1.0901 - val_profit_accuracy_6: 0.3320\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0733 - profit_accuracy_6: 0.4001 - val_loss: 1.0916 - val_profit_accuracy_6: 0.3392\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_6: 0.3990 - val_loss: 1.0887 - val_profit_accuracy_6: 0.3905\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0738 - profit_accuracy_6: 0.3930 - val_loss: 1.0886 - val_profit_accuracy_6: 0.3869\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy_6: 0.3950 - val_loss: 1.0887 - val_profit_accuracy_6: 0.4052\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0736 - profit_accuracy_6: 0.3881 - val_loss: 1.0899 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_6: 0.3916 - val_loss: 1.0887 - val_profit_accuracy_6: 0.3989\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0733 - profit_accuracy_6: 0.4018 - val_loss: 1.0911 - val_profit_accuracy_6: 0.3396\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0732 - profit_accuracy_6: 0.3945 - val_loss: 1.0909 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_6: 0.3928 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3361\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0726 - profit_accuracy_6: 0.4009 - val_loss: 1.0887 - val_profit_accuracy_6: 0.4128\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0737 - profit_accuracy_6: 0.4002 - val_loss: 1.0899 - val_profit_accuracy_6: 0.3489\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0727 - profit_accuracy_6: 0.3926 - val_loss: 1.0890 - val_profit_accuracy_6: 0.3800\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0728 - profit_accuracy_6: 0.3917 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3347\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy_6: 0.3983 - val_loss: 1.0899 - val_profit_accuracy_6: 0.3713\n",
      "30/30 [==============================] - 1s 3ms/step\n",
      "Profit_accuracy = 0.37130802869796753\n",
      "Combine profit_accuracy = 0.5263158082962036\n"
     ]
    }
   ],
   "source": [
    "combined_pred_probs, profit_accuracy = train_lstm_model_combine(X_train_normalized_eco, X_test_normalized_eco, X_train_normalized_tech, X_test_normalized_tech, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
