{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import tpqoa\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "day_ahead = 1\n",
    "epochs = 200\n",
    "lstm_units = 150\n",
    "batch_size = 64\n",
    "file_name = './getdata/ig/CS.D.EURUSD.MINI.IP_DAY_2006-01-01_2024-03-29_format.csv'\n",
    "# file_name = './data/EUR_USD_D_2006_2024_M.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_name, parse_dates = ['time'], usecols = ['time', 'c', 'h', 'l'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge macroeco data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eco = data.copy()\n",
    "data_eco.drop(['h', 'l'], axis=1, inplace=True)\n",
    "data_eu_interest = pd.read_csv('./data/Interest_rate_EUR.csv')\n",
    "data_ge_interest = pd.read_csv('./data/Interest_rate_Germany.csv')\n",
    "data_sp500 = pd.read_csv('./data/SP500_Historical_Data.csv', parse_dates = ['Date'])\n",
    "data_cpi = pd.read_csv('./data/CPI-U_Inflation_US.csv')\n",
    "data_dff = pd.read_csv('./data/DFF.csv')\n",
    "data_gdaxi = pd.read_csv('./data/GDAXI.csv')\n",
    "data_hcip = pd.read_csv('./data/HCIP_Inflation_EUR.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eco['year_month'] = data_eco['time'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_eu_interest\n",
    "data_eu_interest['DATE'] = pd.to_datetime(data_eu_interest['DATE'], format=\"%Y-%m-%d\").dt.strftime(\"%Y-%m\")\n",
    "data_eco = pd.merge(data_eco, data_eu_interest, left_on='year_month', right_on='DATE', how='left')\n",
    "data_eco.drop(['DATE', 'TIME PERIOD'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_ge_interest\n",
    "data_ge_interest['DATE'] = pd.to_datetime(data_ge_interest['DATE'], format=\"%Y-%m-%d\").dt.strftime(\"%Y-%m\")\n",
    "data_eco = pd.merge(data_eco, data_ge_interest, left_on='year_month', right_on='DATE', how='left')\n",
    "data_eco.drop(['DATE', 'TIME PERIOD'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_sp500\n",
    "data_eco = pd.merge(data_eco, data_sp500[['Date', 'Adj Close']], left_on='time', right_on='Date', how='left')\n",
    "data_eco.drop(['Date'], axis=1, inplace=True)\n",
    "data_eco['Adj Close'].interpolate(method='linear', inplace=True)\n",
    "data_eco['Adj Close'].bfill(inplace=True)\n",
    "data_eco.rename(columns= {'Adj Close' : 'sp500'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_cpi\n",
    "data_cpi = data_cpi[~data_cpi['Period'].isin(['S01', 'S02'])]\n",
    "data_cpi['year_month'] = data_cpi['Year'].astype(str) + '-' + pd.to_datetime(data_cpi['Period'], format=\"M%m\").dt.strftime('%m')\n",
    "data_eco = pd.merge(data_eco, data_cpi[['year_month', 'Value']], left_on='year_month', right_on='year_month', how='left')\n",
    "data_eco.rename(columns= {'Value' : 'cpi-u'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_dff\n",
    "data_dff['DATE'] = pd.to_datetime(data_dff['DATE'], format='%Y-%m-%d')\n",
    "data_eco = pd.merge(data_eco, data_dff[['DATE', 'DFF']], left_on='time', right_on='DATE', how='left')\n",
    "data_eco.rename(columns= {'Value' : 'cpi-u'}, inplace=True)\n",
    "data_eco.drop(['DATE'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data_gdaxi\n",
    "data_gdaxi['Date'] = pd.to_datetime(data_gdaxi['Date'], format='%Y-%m-%d')\n",
    "data_eco = pd.merge(data_eco, data_gdaxi[['Date', 'Adj Close']], left_on='time', right_on='Date', how='left')\n",
    "data_eco.rename(columns= {'Adj Close' : 'gdaxi'}, inplace=True)\n",
    "data_eco.drop(['Date'], axis=1, inplace=True)\n",
    "data_eco['gdaxi'].interpolate(method='linear', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>c</th>\n",
       "      <th>year_month</th>\n",
       "      <th>interest_rate_eu</th>\n",
       "      <th>interest_rate_ge</th>\n",
       "      <th>sp500</th>\n",
       "      <th>cpi-u</th>\n",
       "      <th>DFF</th>\n",
       "      <th>gdaxi</th>\n",
       "      <th>hcip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01 16:00:00</td>\n",
       "      <td>{'bid': 11822.0, 'ask': 11822.0, 'lastTraded':...</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-02 16:00:00</td>\n",
       "      <td>{'bid': 12012.0, 'ask': 12012.0, 'lastTraded':...</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-03 16:00:00</td>\n",
       "      <td>{'bid': 12122.0, 'ask': 12122.0, 'lastTraded':...</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-04 16:00:00</td>\n",
       "      <td>{'bid': 12106.0, 'ask': 12106.0, 'lastTraded':...</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-05 16:00:00</td>\n",
       "      <td>{'bid': 12146.0, 'ask': 12146.0, 'lastTraded':...</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>2024-03-25 16:00:00</td>\n",
       "      <td>{'bid': 10827.9, 'ask': 10828.5, 'lastTraded':...</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>2024-03-26 16:00:00</td>\n",
       "      <td>{'bid': 10820.0, 'ask': 10820.6, 'lastTraded':...</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>2024-03-27 16:00:00</td>\n",
       "      <td>{'bid': 10801.0, 'ask': 10801.6, 'lastTraded':...</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>2024-03-28 16:00:00</td>\n",
       "      <td>{'bid': 10791.4, 'ask': 10793.5, 'lastTraded':...</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>2024-03-29 16:00:00</td>\n",
       "      <td>{'bid': 10790.7, 'ask': 10796.7, 'lastTraded':...</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4977 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time                                                  c  \\\n",
       "0    2006-01-01 16:00:00  {'bid': 11822.0, 'ask': 11822.0, 'lastTraded':...   \n",
       "1    2006-01-02 16:00:00  {'bid': 12012.0, 'ask': 12012.0, 'lastTraded':...   \n",
       "2    2006-01-03 16:00:00  {'bid': 12122.0, 'ask': 12122.0, 'lastTraded':...   \n",
       "3    2006-01-04 16:00:00  {'bid': 12106.0, 'ask': 12106.0, 'lastTraded':...   \n",
       "4    2006-01-05 16:00:00  {'bid': 12146.0, 'ask': 12146.0, 'lastTraded':...   \n",
       "...                  ...                                                ...   \n",
       "4972 2024-03-25 16:00:00  {'bid': 10827.9, 'ask': 10828.5, 'lastTraded':...   \n",
       "4973 2024-03-26 16:00:00  {'bid': 10820.0, 'ask': 10820.6, 'lastTraded':...   \n",
       "4974 2024-03-27 16:00:00  {'bid': 10801.0, 'ask': 10801.6, 'lastTraded':...   \n",
       "4975 2024-03-28 16:00:00  {'bid': 10791.4, 'ask': 10793.5, 'lastTraded':...   \n",
       "4976 2024-03-29 16:00:00  {'bid': 10790.7, 'ask': 10796.7, 'lastTraded':...   \n",
       "\n",
       "     year_month  interest_rate_eu  interest_rate_ge  sp500  cpi-u  DFF  gdaxi  \\\n",
       "0       2006-01              3.38              3.32    NaN    2.1  NaN    NaN   \n",
       "1       2006-01              3.38              3.32    NaN    2.1  NaN    NaN   \n",
       "2       2006-01              3.38              3.32    NaN    2.1  NaN    NaN   \n",
       "3       2006-01              3.38              3.32    NaN    2.1  NaN    NaN   \n",
       "4       2006-01              3.38              3.32    NaN    2.1  NaN    NaN   \n",
       "...         ...               ...               ...    ...    ...  ...    ...   \n",
       "4972    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
       "4973    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
       "4974    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
       "4975    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
       "4976    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
       "\n",
       "      hcip  \n",
       "0      2.4  \n",
       "1      2.4  \n",
       "2      2.4  \n",
       "3      2.4  \n",
       "4      2.4  \n",
       "...    ...  \n",
       "4972   2.4  \n",
       "4973   2.4  \n",
       "4974   2.4  \n",
       "4975   2.4  \n",
       "4976   2.4  \n",
       "\n",
       "[4977 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with data_hcip\n",
    "data_hcip['DATE'] = pd.to_datetime(data_hcip['DATE'], format=\"%Y-%m-%d\").dt.strftime(\"%Y-%m\")\n",
    "data_eco = pd.merge(data_eco, data_hcip, left_on='year_month', right_on='DATE', how='left')\n",
    "data_eco.drop(['DATE', 'TIME PERIOD'], axis=1, inplace=True)\n",
    "data_eco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4951, 10)\n",
      "                    time                                                  c  \\\n",
      "26   2006-02-06 16:00:00  {'bid': 11977.0, 'ask': 11977.0, 'lastTraded':...   \n",
      "27   2006-02-07 16:00:00  {'bid': 11962.0, 'ask': 11962.0, 'lastTraded':...   \n",
      "28   2006-02-08 16:00:00  {'bid': 11979.0, 'ask': 11979.0, 'lastTraded':...   \n",
      "29   2006-02-09 16:00:00  {'bid': 11900.0, 'ask': 11900.0, 'lastTraded':...   \n",
      "30   2006-02-12 16:00:00  {'bid': 11899.0, 'ask': 11899.0, 'lastTraded':...   \n",
      "...                  ...                                                ...   \n",
      "4972 2024-03-25 16:00:00  {'bid': 10827.9, 'ask': 10828.5, 'lastTraded':...   \n",
      "4973 2024-03-26 16:00:00  {'bid': 10820.0, 'ask': 10820.6, 'lastTraded':...   \n",
      "4974 2024-03-27 16:00:00  {'bid': 10801.0, 'ask': 10801.6, 'lastTraded':...   \n",
      "4975 2024-03-28 16:00:00  {'bid': 10791.4, 'ask': 10793.5, 'lastTraded':...   \n",
      "4976 2024-03-29 16:00:00  {'bid': 10790.7, 'ask': 10796.7, 'lastTraded':...   \n",
      "\n",
      "     year_month  interest_rate_eu  interest_rate_ge  sp500  cpi-u  DFF  gdaxi  \\\n",
      "26      2006-02              3.53              3.47    NaN    2.1  NaN    NaN   \n",
      "27      2006-02              3.53              3.47    NaN    2.1  NaN    NaN   \n",
      "28      2006-02              3.53              3.47    NaN    2.1  NaN    NaN   \n",
      "29      2006-02              3.53              3.47    NaN    2.1  NaN    NaN   \n",
      "30      2006-02              3.53              3.47    NaN    2.1  NaN    NaN   \n",
      "...         ...               ...               ...    ...    ...  ...    ...   \n",
      "4972    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
      "4973    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
      "4974    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
      "4975    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
      "4976    2024-03              2.90              2.35    NaN    3.8  NaN    NaN   \n",
      "\n",
      "      hcip  \n",
      "26     2.4  \n",
      "27     2.4  \n",
      "28     2.4  \n",
      "29     2.4  \n",
      "30     2.4  \n",
      "...    ...  \n",
      "4972   2.4  \n",
      "4973   2.4  \n",
      "4974   2.4  \n",
      "4975   2.4  \n",
      "4976   2.4  \n",
      "\n",
      "[4951 rows x 10 columns]\n",
      "time                   0\n",
      "c                      0\n",
      "year_month             0\n",
      "interest_rate_eu       0\n",
      "interest_rate_ge       0\n",
      "sp500               4951\n",
      "cpi-u                  0\n",
      "DFF                 4951\n",
      "gdaxi               4951\n",
      "hcip                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop the first 26 rows to match with data_tech\n",
    "data_eco = data_eco.iloc[26:]\n",
    "print(data_eco.shape)\n",
    "print(data_eco)\n",
    "print(data_eco.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate price changes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m price_changes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_eco\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Perform histogram analysis\u001b[39;00m\n\u001b[1;32m      5\u001b[0m histogram, bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(price_changes, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/function_base.py:1452\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(a, n, axis, prepend, append)\u001b[0m\n\u001b[1;32m   1450\u001b[0m op \u001b[38;5;241m=\u001b[39m not_equal \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_ \u001b[38;5;28;01melse\u001b[39;00m subtract\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m-> 1452\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslice1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslice2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# Calculate price changes\n",
    "price_changes = np.diff(data_eco['c'])\n",
    "\n",
    "# Perform histogram analysis\n",
    "histogram, bins = np.histogram(price_changes, bins=10)\n",
    "\n",
    "# Plot histogram\n",
    "plt.bar(bins[:-1], histogram, width=np.diff(bins), align='edge')\n",
    "plt.xlabel('Price Change')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Price Changes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'price_changes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprice_changes\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'price_changes' is not defined"
     ]
    }
   ],
   "source": [
    "price_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper bound of the threshold value: 0.04116999999999993\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Determine number of bins\n",
    "number_of_bins = 10\n",
    "\n",
    "# Calculate histogram\n",
    "histogram, bins = np.histogram(price_changes, bins=number_of_bins, range=(0, price_changes.max()))\n",
    "\n",
    "# Sort histogram counts in descending order\n",
    "sorted_histogram = np.sort(histogram)[::-1]\n",
    "\n",
    "# Calculate cumulative sum of sorted histogram counts\n",
    "cumulative_sum = np.cumsum(sorted_histogram)\n",
    "\n",
    "# Find the index where cumulative sum exceeds 85% of the whole count\n",
    "index_85_percent = np.argmax(cumulative_sum >= len(price_changes) * 0.85)\n",
    "\n",
    "# Calculate the upper bound of the threshold value\n",
    "if index_85_percent == 0:\n",
    "    threshold_upper_bound = bins[-1]\n",
    "else:\n",
    "    threshold_upper_bound = bins[index_85_percent]\n",
    "\n",
    "print(\"Upper bound of the threshold value:\", threshold_upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  17   49  213 1022 2249  939  177   28   14    3]\n",
      "[-0.03304  -0.025619 -0.018198 -0.010777 -0.003356  0.004065  0.011486\n",
      "  0.018907  0.026328  0.033749  0.04117 ]\n",
      "[-0.029329500000000175, -0.021908500000000164, -0.014487500000000153, -0.007066500000000142, 0.0003544999999998688, 0.00777549999999988, 0.01519649999999989, 0.0226174999999999, 0.030038499999999912, 0.03745949999999992]\n"
     ]
    }
   ],
   "source": [
    "bin_counts, bin_edges = np.histogram(price_changes, bins=number_of_bins)\n",
    "print(bin_counts)\n",
    "print(bin_edges)\n",
    "bin_max_diff = [(bin_edges[i] + bin_edges[i+1]) / 2 for i in range(len(bin_counts))]\n",
    "print(bin_max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold upper bound: 0.00777549999999988\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def histogram_analysis(close_diff, number_of_bins):\n",
    "    # Perform histogram analysis\n",
    "    bin_counts, bin_edges = np.histogram(close_diff, bins=number_of_bins)\n",
    "    bin_max_diff = [(bin_edges[i] + bin_edges[i+1]) / 2 for i in range(len(bin_counts))]\n",
    "\n",
    "    # Sort bin_counts and bin_max_diff in descending order\n",
    "    sorted_indices = np.argsort(bin_counts)[::-1]\n",
    "    bin_counts = bin_counts[sorted_indices]\n",
    "    bin_max_diff = [bin_max_diff[i] for i in sorted_indices]\n",
    "\n",
    "    # Calculate sum of bin_counts\n",
    "    sum_bin_counts = np.sum(bin_counts)\n",
    "\n",
    "    # Find the threshold upper bound\n",
    "    temp_sum = 0\n",
    "    for i in range(number_of_bins):\n",
    "        temp_sum += bin_counts[i]\n",
    "        if temp_sum / sum_bin_counts > 0.85:\n",
    "            break\n",
    "\n",
    "    threshold_upper_bound = bin_max_diff[i]\n",
    "\n",
    "    return threshold_upper_bound\n",
    "\n",
    "# Example usage\n",
    "# close_diff = np.random.uniform(low=-0.01, high=0.01, size=1000)  # Example differences data\n",
    "number_of_bins = 10  # Example number of bins\n",
    "threshold_upper_bound = histogram_analysis(price_changes, number_of_bins)\n",
    "print(\"Threshold upper bound:\", threshold_upper_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final threshold: 0.0024400000000000055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_threshold(close_diff):\n",
    "    # Get the upper bound of the threshold value from histogram analysis\n",
    "    threshold_upper_bound = histogram_analysis(close_diff, number_of_bins)\n",
    "    \n",
    "    temp_threshold = 0\n",
    "    best_entropy = -float('inf')\n",
    "    threshold = None\n",
    "    \n",
    "    while temp_threshold < threshold_upper_bound:\n",
    "        labels = np.zeros(len(close_diff))  # Initialize labels with zeros\n",
    "        \n",
    "        # Assign labels based on threshold\n",
    "        indexes_incr = np.where(close_diff > temp_threshold)[0]\n",
    "        indexes_decr = np.where(-close_diff > temp_threshold)[0]\n",
    "        labels[indexes_incr] = 2\n",
    "        labels[indexes_decr] = 1\n",
    "        \n",
    "        # Calculate entropy\n",
    "        entropy = calculate_entropy(labels)\n",
    "        \n",
    "        # Update best_entropy and threshold if current entropy is better\n",
    "        if entropy > best_entropy:\n",
    "            best_entropy = entropy\n",
    "            threshold = temp_threshold\n",
    "        \n",
    "        # Increase temp_threshold for next iteration\n",
    "        temp_threshold += 0.00001\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(labels):\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = label_counts / len(labels)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "# Example usage\n",
    "threshold = calculate_threshold(price_changes)\n",
    "print(\"Final threshold:\", threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>MA_10</th>\n",
       "      <th>MACD_12_26</th>\n",
       "      <th>ROC_2</th>\n",
       "      <th>Momentum_4</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>BBL_20_2.0</th>\n",
       "      <th>BBM_20_2.0</th>\n",
       "      <th>BBU_20_2.0</th>\n",
       "      <th>BBB_20_2.0</th>\n",
       "      <th>BBP_20_2.0</th>\n",
       "      <th>CCI_20</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-02-07</th>\n",
       "      <td>1.19646</td>\n",
       "      <td>1.212396</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-1.045406</td>\n",
       "      <td>-0.01834</td>\n",
       "      <td>36.217972</td>\n",
       "      <td>1.196244</td>\n",
       "      <td>1.212436</td>\n",
       "      <td>1.228628</td>\n",
       "      <td>2.671004</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>-165.533230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-08</th>\n",
       "      <td>1.19816</td>\n",
       "      <td>1.209542</td>\n",
       "      <td>-0.000946</td>\n",
       "      <td>-0.485050</td>\n",
       "      <td>-0.00964</td>\n",
       "      <td>38.532998</td>\n",
       "      <td>1.194933</td>\n",
       "      <td>1.212059</td>\n",
       "      <td>1.229185</td>\n",
       "      <td>2.825944</td>\n",
       "      <td>0.094215</td>\n",
       "      <td>-133.416803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-09</th>\n",
       "      <td>1.19626</td>\n",
       "      <td>1.206658</td>\n",
       "      <td>-0.001769</td>\n",
       "      <td>-0.016716</td>\n",
       "      <td>-0.01284</td>\n",
       "      <td>36.871095</td>\n",
       "      <td>1.192758</td>\n",
       "      <td>1.211187</td>\n",
       "      <td>1.229616</td>\n",
       "      <td>3.043199</td>\n",
       "      <td>0.095022</td>\n",
       "      <td>-137.805786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-10</th>\n",
       "      <td>1.19840</td>\n",
       "      <td>1.204328</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>-0.00560</td>\n",
       "      <td>40.103967</td>\n",
       "      <td>1.191852</td>\n",
       "      <td>1.210892</td>\n",
       "      <td>1.229932</td>\n",
       "      <td>3.144742</td>\n",
       "      <td>0.171949</td>\n",
       "      <td>-105.776085</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-13</th>\n",
       "      <td>1.18960</td>\n",
       "      <td>1.202308</td>\n",
       "      <td>-0.003255</td>\n",
       "      <td>-0.556735</td>\n",
       "      <td>-0.00686</td>\n",
       "      <td>32.499577</td>\n",
       "      <td>1.188575</td>\n",
       "      <td>1.209562</td>\n",
       "      <td>1.230549</td>\n",
       "      <td>3.470244</td>\n",
       "      <td>0.024428</td>\n",
       "      <td>-167.999552</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-25</th>\n",
       "      <td>1.08030</td>\n",
       "      <td>1.089076</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>-1.178214</td>\n",
       "      <td>-0.00694</td>\n",
       "      <td>38.811259</td>\n",
       "      <td>1.078868</td>\n",
       "      <td>1.087952</td>\n",
       "      <td>1.097036</td>\n",
       "      <td>1.669874</td>\n",
       "      <td>0.078807</td>\n",
       "      <td>-128.014550</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-26</th>\n",
       "      <td>1.08385</td>\n",
       "      <td>1.088139</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>-0.253083</td>\n",
       "      <td>-0.00212</td>\n",
       "      <td>45.143745</td>\n",
       "      <td>1.078728</td>\n",
       "      <td>1.087897</td>\n",
       "      <td>1.097066</td>\n",
       "      <td>1.685578</td>\n",
       "      <td>0.279303</td>\n",
       "      <td>-70.215176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-27</th>\n",
       "      <td>1.08302</td>\n",
       "      <td>1.087145</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.251782</td>\n",
       "      <td>-0.01016</td>\n",
       "      <td>43.961831</td>\n",
       "      <td>1.078553</td>\n",
       "      <td>1.087835</td>\n",
       "      <td>1.097117</td>\n",
       "      <td>1.706560</td>\n",
       "      <td>0.240635</td>\n",
       "      <td>-80.347630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>1.08138</td>\n",
       "      <td>1.085791</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>-0.227891</td>\n",
       "      <td>-0.00522</td>\n",
       "      <td>41.572286</td>\n",
       "      <td>1.078171</td>\n",
       "      <td>1.087716</td>\n",
       "      <td>1.097261</td>\n",
       "      <td>1.755144</td>\n",
       "      <td>0.168116</td>\n",
       "      <td>-105.605063</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-29</th>\n",
       "      <td>1.07866</td>\n",
       "      <td>1.084887</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>-0.402578</td>\n",
       "      <td>-0.00164</td>\n",
       "      <td>37.787271</td>\n",
       "      <td>1.077720</td>\n",
       "      <td>1.087610</td>\n",
       "      <td>1.097501</td>\n",
       "      <td>1.818783</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>-140.927230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4712 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  c     MA_10  MACD_12_26     ROC_2  Momentum_4     RSI_10  \\\n",
       "time                                                                         \n",
       "2006-02-07  1.19646  1.212396   -0.000074 -1.045406    -0.01834  36.217972   \n",
       "2006-02-08  1.19816  1.209542   -0.000946 -0.485050    -0.00964  38.532998   \n",
       "2006-02-09  1.19626  1.206658   -0.001769 -0.016716    -0.01284  36.871095   \n",
       "2006-02-10  1.19840  1.204328   -0.002223  0.020031    -0.00560  40.103967   \n",
       "2006-02-13  1.18960  1.202308   -0.003255 -0.556735    -0.00686  32.499577   \n",
       "...             ...       ...         ...       ...         ...        ...   \n",
       "2024-03-25  1.08030  1.089076    0.000777 -1.178214    -0.00694  38.811259   \n",
       "2024-03-26  1.08385  1.088139    0.000427 -0.253083    -0.00212  45.143745   \n",
       "2024-03-27  1.08302  1.087145    0.000082  0.251782    -0.01016  43.961831   \n",
       "2024-03-28  1.08138  1.085791   -0.000320 -0.227891    -0.00522  41.572286   \n",
       "2024-03-29  1.07866  1.084887   -0.000848 -0.402578    -0.00164  37.787271   \n",
       "\n",
       "            BBL_20_2.0  BBM_20_2.0  BBU_20_2.0  BBB_20_2.0  BBP_20_2.0  \\\n",
       "time                                                                     \n",
       "2006-02-07    1.196244    1.212436    1.228628    2.671004    0.006673   \n",
       "2006-02-08    1.194933    1.212059    1.229185    2.825944    0.094215   \n",
       "2006-02-09    1.192758    1.211187    1.229616    3.043199    0.095022   \n",
       "2006-02-10    1.191852    1.210892    1.229932    3.144742    0.171949   \n",
       "2006-02-13    1.188575    1.209562    1.230549    3.470244    0.024428   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-03-25    1.078868    1.087952    1.097036    1.669874    0.078807   \n",
       "2024-03-26    1.078728    1.087897    1.097066    1.685578    0.279303   \n",
       "2024-03-27    1.078553    1.087835    1.097117    1.706560    0.240635   \n",
       "2024-03-28    1.078171    1.087716    1.097261    1.755144    0.168116   \n",
       "2024-03-29    1.077720    1.087610    1.097501    1.818783    0.047527   \n",
       "\n",
       "                CCI_20  target  \n",
       "time                            \n",
       "2006-02-07 -165.533230     0.0  \n",
       "2006-02-08 -133.416803     0.0  \n",
       "2006-02-09 -137.805786     0.0  \n",
       "2006-02-10 -105.776085     1.0  \n",
       "2006-02-13 -167.999552     0.0  \n",
       "...                ...     ...  \n",
       "2024-03-25 -128.014550     2.0  \n",
       "2024-03-26  -70.215176     0.0  \n",
       "2024-03-27  -80.347630     0.0  \n",
       "2024-03-28 -105.605063     1.0  \n",
       "2024-03-29 -140.927230     0.0  \n",
       "\n",
       "[4712 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tech = data.copy()\n",
    "data_tech['MA_10'] = ta.sma(data_tech['c'], length=10)\n",
    "data_tech['MACD_12_26'] = ta.macd(data_tech['c'], fast=12, slow=26).iloc[:, 0]\n",
    "data_tech['ROC_2'] = ta.roc(data_tech['c'], length=2)\n",
    "data_tech['Momentum_4'] = ta.mom(data_tech['c'], length=4)\n",
    "data_tech['RSI_10'] = ta.rsi(data_tech['c'], length=10)\n",
    "bb_data = ta.bbands(data_tech['c'], length=20)\n",
    "data_tech = pd.concat([data_tech, bb_data], axis=1)\n",
    "data_tech['CCI_20'] = ta.cci(data_tech['h'], data_tech['l'], data_tech['c'], length=20)\n",
    "data_tech = data_tech.iloc[26:]\n",
    "data_tech['price_diff'] = data_tech['c'].diff()\n",
    "data_tech['price_diff'] = data_tech['price_diff'].bfill()\n",
    "data_tech['target'] = 0\n",
    "data_tech.loc[data_tech['price_diff'] > threshold, 'target'] = 2\n",
    "data_tech.loc[data_tech['price_diff'] < -threshold, 'target'] = 1\n",
    "data_tech['target'] = data_tech['target'].shift(-day_ahead)\n",
    "data_tech['target'].fillna(0, inplace=True)\n",
    "data_tech.set_index('time', inplace=True)\n",
    "data_tech.drop(['h', 'l', 'price_diff'], axis=1, inplace=True)\n",
    "# print(data_tech.isna().sum())\n",
    "data_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_533055/2160447692.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['price_diff'] = data_eco['c'].diff()\n",
      "/tmp/ipykernel_533055/2160447692.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['price_diff'] = data_eco['price_diff'].bfill()\n",
      "/tmp/ipykernel_533055/2160447692.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['target'] = 0\n",
      "/tmp/ipykernel_533055/2160447692.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['target'] = data_eco['target'].shift(-day_ahead)\n",
      "/tmp/ipykernel_533055/2160447692.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco['target'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_533055/2160447692.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_eco.drop(['year_month', 'price_diff'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_eco['price_diff'] = data_eco['c'].diff()\n",
    "data_eco['price_diff'] = data_eco['price_diff'].bfill()\n",
    "data_eco['target'] = 0\n",
    "data_eco.loc[data_eco['price_diff'] > threshold, 'target'] = 2\n",
    "data_eco.loc[data_eco['price_diff'] < -threshold, 'target'] = 1\n",
    "data_eco['target'] = data_eco['target'].shift(-day_ahead)\n",
    "data_eco['target'].fillna(0, inplace=True)\n",
    "data_eco.set_index('time', inplace=True)\n",
    "data_eco.drop(['year_month', 'price_diff'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_normalized(X, y, test_size=0.2):\n",
    "    # Split the dataset into training and testing sets with no shuffling\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the scaler to the training data and transform it\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Transform the testing data using the scaler fitted on the training data\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_normalized, X_test_normalized, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 03:12:00.367247: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 03:12:00.391571: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-26 03:12:00.684836: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-26 03:12:00.684973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-26 03:12:00.720938: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 03:12:00.824350: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-26 03:12:00.827446: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 03:12:02.279908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import Metric\n",
    "import keras.backend as K\n",
    "\n",
    "class ProfitAccuracy(Metric):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ProfitAccuracy, self).__init__(**kwargs)\n",
    "        self.true_dec = self.add_weight(name='true_dec', initializer='zeros')\n",
    "        self.true_inc = self.add_weight(name='true_inc', initializer='zeros')\n",
    "        self.false_dec_noact = self.add_weight(name='false_dec_noact', initializer='zeros')\n",
    "        self.false_inc_noact = self.add_weight(name='false_inc_noact', initializer='zeros')\n",
    "        self.false_inc_dec = self.add_weight(name='false_inc_dec', initializer='zeros')\n",
    "        self.false_dec_inc = self.add_weight(name='false_dec_inc', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert y_true and y_pred to boolean arrays\n",
    "        y_true = K.argmax(y_true, axis=-1)\n",
    "        y_pred = K.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        true_dec = K.sum(K.cast(K.equal(y_true, 1) & K.equal(y_pred, 1), 'float32'))\n",
    "        true_inc = K.sum(K.cast(K.equal(y_true, 2) & K.equal(y_pred, 2), 'float32'))\n",
    "        false_dec_noact = K.sum(K.cast(K.equal(y_true, 0) & K.equal(y_pred, 1), 'float32'))\n",
    "        false_inc_noact = K.sum(K.cast(K.equal(y_true, 0) & K.equal(y_pred, 2), 'float32'))\n",
    "        false_inc_dec = K.sum(K.cast(K.equal(y_true, 1) & K.equal(y_pred, 2), 'float32'))\n",
    "        false_dec_inc = K.sum(K.cast(K.equal(y_true, 2) & K.equal(y_pred, 1), 'float32'))\n",
    "\n",
    "\n",
    "        self.true_dec.assign_add(true_dec)\n",
    "        self.true_inc.assign_add(true_inc)\n",
    "        self.false_dec_noact.assign_add(false_dec_noact)\n",
    "        self.false_inc_noact.assign_add(false_inc_noact)\n",
    "        self.false_inc_dec.assign_add(false_inc_dec)\n",
    "        self.false_dec_inc.assign_add(false_dec_inc)\n",
    "\n",
    "    def result(self):\n",
    "        numerator = self.true_dec + self.true_inc\n",
    "        denominator = (\n",
    "            self.false_dec_noact + self.false_inc_noact +\n",
    "            self.true_dec + self.false_inc_dec +\n",
    "            self.false_dec_inc + self.true_inc\n",
    "        )\n",
    "\n",
    "        # Check for division by zero\n",
    "        if denominator == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return numerator / denominator\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_dec.assign(0)\n",
    "        self.true_inc.assign(0)\n",
    "        self.false_dec_noact.assign(0)\n",
    "        self.false_inc_noact.assign(0)\n",
    "        self.false_inc_dec.assign(0)\n",
    "        self.false_dec_inc.assign(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2006-02-07    0.0\n",
       "2006-02-08    0.0\n",
       "2006-02-09    0.0\n",
       "2006-02-10    1.0\n",
       "2006-02-13    0.0\n",
       "             ... \n",
       "2020-08-05    2.0\n",
       "2020-08-06    0.0\n",
       "2020-08-07    1.0\n",
       "2020-08-10    1.0\n",
       "2020-08-11    0.0\n",
       "Name: target, Length: 3769, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eco = data_eco.drop(columns=['target'])\n",
    "y_eco = data_eco['target']\n",
    "\n",
    "X_train_normalized_eco, X_test_normalized_eco, y_train, y_test = data_normalized(X_eco, y_eco)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "# from keras.layers import Dropout\n",
    "\n",
    "def train_lstm_model(X_train, X_test, y_train, y_test, lstm_units=lstm_units, epochs=epochs, batch_size=batch_size):\n",
    "    # Convert features to float32\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y_train)\n",
    "    encoded_y_train = encoder.transform(y_train)\n",
    "    encoded_y_test = encoder.transform(y_test)\n",
    "    y_train_onehot = to_categorical(encoded_y_train)\n",
    "    y_test_onehot = to_categorical(encoded_y_test)\n",
    "\n",
    "    # Reshape input data for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[ProfitAccuracy()])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train_onehot, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test_onehot))\n",
    "    \n",
    "    # Evaluate the model on the test set using custom metric\n",
    "    y_pred = model.predict(X_test)\n",
    "    profit_accuracy = ProfitAccuracy()(y_test_onehot, y_pred)\n",
    "    print(f\"Profit_accuracy = {profit_accuracy}\")\n",
    "\n",
    "    return y_pred, profit_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "59/59 [==============================] - 3s 17ms/step - loss: 1.0922 - profit_accuracy: 0.3560 - val_loss: 1.0843 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0832 - profit_accuracy: 0.3716 - val_loss: 1.0850 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0802 - profit_accuracy: 0.3734 - val_loss: 1.1081 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0788 - profit_accuracy: 0.3722 - val_loss: 1.1051 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0784 - profit_accuracy: 0.3851 - val_loss: 1.1377 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0782 - profit_accuracy: 0.3835 - val_loss: 1.1234 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0783 - profit_accuracy: 0.3749 - val_loss: 1.1112 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0769 - profit_accuracy: 0.3873 - val_loss: 1.1120 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy: 0.3950 - val_loss: 1.1124 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy: 0.3940 - val_loss: 1.1205 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0765 - profit_accuracy: 0.3915 - val_loss: 1.1030 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy: 0.3698 - val_loss: 1.1078 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy: 0.3926 - val_loss: 1.1305 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy: 0.3883 - val_loss: 1.1449 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0749 - profit_accuracy: 0.4115 - val_loss: 1.1388 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy: 0.3768 - val_loss: 1.1173 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0750 - profit_accuracy: 0.3925 - val_loss: 1.1236 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0748 - profit_accuracy: 0.3977 - val_loss: 1.1312 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy: 0.3957 - val_loss: 1.1151 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy: 0.3921 - val_loss: 1.1551 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0739 - profit_accuracy: 0.3888 - val_loss: 1.1358 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy: 0.3886 - val_loss: 1.1248 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0738 - profit_accuracy: 0.3928 - val_loss: 1.1329 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0733 - profit_accuracy: 0.3857 - val_loss: 1.1293 - val_profit_accuracy: 0.3158\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0728 - profit_accuracy: 0.3911 - val_loss: 1.1784 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0728 - profit_accuracy: 0.3911 - val_loss: 1.1853 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0721 - profit_accuracy: 0.3981 - val_loss: 1.1291 - val_profit_accuracy: 0.3000\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy: 0.3838 - val_loss: 1.1873 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0724 - profit_accuracy: 0.4000 - val_loss: 1.1435 - val_profit_accuracy: 0.3158\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy: 0.3852 - val_loss: 1.1138 - val_profit_accuracy: 0.3611\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0728 - profit_accuracy: 0.3981 - val_loss: 1.1167 - val_profit_accuracy: 0.3600\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy: 0.3892 - val_loss: 1.1033 - val_profit_accuracy: 0.3786\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0740 - profit_accuracy: 0.3831 - val_loss: 1.1249 - val_profit_accuracy: 0.3000\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy: 0.3909 - val_loss: 1.1312 - val_profit_accuracy: 0.3793\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0717 - profit_accuracy: 0.3918 - val_loss: 1.1364 - val_profit_accuracy: 0.3704\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0720 - profit_accuracy: 0.3919 - val_loss: 1.1273 - val_profit_accuracy: 0.3333\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0717 - profit_accuracy: 0.3919 - val_loss: 1.1858 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0717 - profit_accuracy: 0.3908 - val_loss: 1.1477 - val_profit_accuracy: 0.2857\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0719 - profit_accuracy: 0.3964 - val_loss: 1.1616 - val_profit_accuracy: 0.3600\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0713 - profit_accuracy: 0.3939 - val_loss: 1.1612 - val_profit_accuracy: 0.3600\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0714 - profit_accuracy: 0.3931 - val_loss: 1.1462 - val_profit_accuracy: 0.3600\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0714 - profit_accuracy: 0.3910 - val_loss: 1.1699 - val_profit_accuracy: 0.2222\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0712 - profit_accuracy: 0.3876 - val_loss: 1.1575 - val_profit_accuracy: 0.4138\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy: 0.3951 - val_loss: 1.1871 - val_profit_accuracy: 0.3000\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0708 - profit_accuracy: 0.3908 - val_loss: 1.2074 - val_profit_accuracy: 0.2222\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0709 - profit_accuracy: 0.3914 - val_loss: 1.1375 - val_profit_accuracy: 0.3924\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0718 - profit_accuracy: 0.3870 - val_loss: 1.1462 - val_profit_accuracy: 0.3529\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy: 0.3887 - val_loss: 1.1807 - val_profit_accuracy: 0.3333\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0715 - profit_accuracy: 0.3963 - val_loss: 1.1632 - val_profit_accuracy: 0.3500\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0710 - profit_accuracy: 0.3920 - val_loss: 1.1839 - val_profit_accuracy: 0.3478\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0716 - profit_accuracy: 0.4013 - val_loss: 1.2440 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0723 - profit_accuracy: 0.3980 - val_loss: 1.1320 - val_profit_accuracy: 0.3875\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0711 - profit_accuracy: 0.3909 - val_loss: 1.1855 - val_profit_accuracy: 0.3158\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0711 - profit_accuracy: 0.3954 - val_loss: 1.2140 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0709 - profit_accuracy: 0.3985 - val_loss: 1.1779 - val_profit_accuracy: 0.3077\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy: 0.3965 - val_loss: 1.1904 - val_profit_accuracy: 0.2857\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0711 - profit_accuracy: 0.3970 - val_loss: 1.1979 - val_profit_accuracy: 0.3333\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0703 - profit_accuracy: 0.4005 - val_loss: 1.1552 - val_profit_accuracy: 0.3750\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0708 - profit_accuracy: 0.3913 - val_loss: 1.1654 - val_profit_accuracy: 0.3571\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0702 - profit_accuracy: 0.3956 - val_loss: 1.2352 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0707 - profit_accuracy: 0.3995 - val_loss: 1.1790 - val_profit_accuracy: 0.3636\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0705 - profit_accuracy: 0.3886 - val_loss: 1.1686 - val_profit_accuracy: 0.4000\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0708 - profit_accuracy: 0.3864 - val_loss: 1.1869 - val_profit_accuracy: 0.3125\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0701 - profit_accuracy: 0.4007 - val_loss: 1.1980 - val_profit_accuracy: 0.3077\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0704 - profit_accuracy: 0.3893 - val_loss: 1.1628 - val_profit_accuracy: 0.3750\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0710 - profit_accuracy: 0.3880 - val_loss: 1.1894 - val_profit_accuracy: 0.3125\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0702 - profit_accuracy: 0.3834 - val_loss: 1.2238 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0708 - profit_accuracy: 0.3962 - val_loss: 1.2085 - val_profit_accuracy: 0.2857\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0702 - profit_accuracy: 0.4000 - val_loss: 1.1850 - val_profit_accuracy: 0.3333\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy: 0.3906 - val_loss: 1.2225 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy: 0.3977 - val_loss: 1.1945 - val_profit_accuracy: 0.3077\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0703 - profit_accuracy: 0.3983 - val_loss: 1.1848 - val_profit_accuracy: 0.2727\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy: 0.3968 - val_loss: 1.1865 - val_profit_accuracy: 0.3636\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3986 - val_loss: 1.1239 - val_profit_accuracy: 0.3462\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0707 - profit_accuracy: 0.3925 - val_loss: 1.1575 - val_profit_accuracy: 0.3684\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy: 0.3958 - val_loss: 1.1696 - val_profit_accuracy: 0.3636\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy: 0.3974 - val_loss: 1.2057 - val_profit_accuracy: 0.3125\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0695 - profit_accuracy: 0.3954 - val_loss: 1.1965 - val_profit_accuracy: 0.3125\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0704 - profit_accuracy: 0.3943 - val_loss: 1.1766 - val_profit_accuracy: 0.3478\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy: 0.3941 - val_loss: 1.2039 - val_profit_accuracy: 0.3158\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy: 0.3981 - val_loss: 1.2733 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0699 - profit_accuracy: 0.3995 - val_loss: 1.2065 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0702 - profit_accuracy: 0.3943 - val_loss: 1.1777 - val_profit_accuracy: 0.3333\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy: 0.3978 - val_loss: 1.2209 - val_profit_accuracy: 0.2222\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0701 - profit_accuracy: 0.3908 - val_loss: 1.1834 - val_profit_accuracy: 0.3158\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0699 - profit_accuracy: 0.3949 - val_loss: 1.1959 - val_profit_accuracy: 0.3636\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0691 - profit_accuracy: 0.4020 - val_loss: 1.1826 - val_profit_accuracy: 0.3793\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy: 0.3960 - val_loss: 1.1584 - val_profit_accuracy: 0.3667\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy: 0.3986 - val_loss: 1.1863 - val_profit_accuracy: 0.3333\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy: 0.3984 - val_loss: 1.2142 - val_profit_accuracy: 0.2857\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0690 - profit_accuracy: 0.3967 - val_loss: 1.1886 - val_profit_accuracy: 0.3600\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0697 - profit_accuracy: 0.3958 - val_loss: 1.1979 - val_profit_accuracy: 0.2727\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0687 - profit_accuracy: 0.4057 - val_loss: 1.2348 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy: 0.4002 - val_loss: 1.1651 - val_profit_accuracy: 0.3256\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3950 - val_loss: 1.1988 - val_profit_accuracy: 0.2941\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0695 - profit_accuracy: 0.4001 - val_loss: 1.2280 - val_profit_accuracy: 0.2222\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.3970 - val_loss: 1.2502 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3978 - val_loss: 1.2192 - val_profit_accuracy: 0.2222\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3950 - val_loss: 1.2675 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0689 - profit_accuracy: 0.4024 - val_loss: 1.1819 - val_profit_accuracy: 0.2903\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0701 - profit_accuracy: 0.4029 - val_loss: 1.1492 - val_profit_accuracy: 0.3333\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0688 - profit_accuracy: 0.4016 - val_loss: 1.1476 - val_profit_accuracy: 0.3380\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy: 0.4072 - val_loss: 1.1976 - val_profit_accuracy: 0.3125\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0694 - profit_accuracy: 0.3970 - val_loss: 1.2256 - val_profit_accuracy: 0.2857\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.3936 - val_loss: 1.1940 - val_profit_accuracy: 0.3333\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0691 - profit_accuracy: 0.4037 - val_loss: 1.1806 - val_profit_accuracy: 0.3750\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0687 - profit_accuracy: 0.4050 - val_loss: 1.2395 - val_profit_accuracy: 0.2500\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy: 0.4007 - val_loss: 1.2011 - val_profit_accuracy: 0.3125\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.4037 - val_loss: 1.1791 - val_profit_accuracy: 0.3793\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0689 - profit_accuracy: 0.3973 - val_loss: 1.2009 - val_profit_accuracy: 0.3125\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0685 - profit_accuracy: 0.3976 - val_loss: 1.1958 - val_profit_accuracy: 0.3500\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3960 - val_loss: 1.2211 - val_profit_accuracy: 0.3636\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.4060 - val_loss: 1.1559 - val_profit_accuracy: 0.2969\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.3941 - val_loss: 1.2292 - val_profit_accuracy: 0.2857\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy: 0.4022 - val_loss: 1.1794 - val_profit_accuracy: 0.3226\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0685 - profit_accuracy: 0.4024 - val_loss: 1.2054 - val_profit_accuracy: 0.3125\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0691 - profit_accuracy: 0.3945 - val_loss: 1.2064 - val_profit_accuracy: 0.2941\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy: 0.4093 - val_loss: 1.2198 - val_profit_accuracy: 0.3636\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy: 0.3938 - val_loss: 1.1618 - val_profit_accuracy: 0.2931\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0692 - profit_accuracy: 0.3988 - val_loss: 1.2281 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0688 - profit_accuracy: 0.4027 - val_loss: 1.2207 - val_profit_accuracy: 0.3125\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0689 - profit_accuracy: 0.4055 - val_loss: 1.1962 - val_profit_accuracy: 0.3158\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0687 - profit_accuracy: 0.3994 - val_loss: 1.2302 - val_profit_accuracy: 0.4000\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy: 0.4056 - val_loss: 1.2168 - val_profit_accuracy: 0.2500\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0692 - profit_accuracy: 0.4020 - val_loss: 1.2291 - val_profit_accuracy: 0.3636\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0689 - profit_accuracy: 0.4011 - val_loss: 1.2310 - val_profit_accuracy: 0.3333\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy: 0.3954 - val_loss: 1.1888 - val_profit_accuracy: 0.3333\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0696 - profit_accuracy: 0.4062 - val_loss: 1.2172 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0682 - profit_accuracy: 0.3999 - val_loss: 1.2152 - val_profit_accuracy: 0.3333\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0691 - profit_accuracy: 0.4017 - val_loss: 1.1825 - val_profit_accuracy: 0.3333\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy: 0.4035 - val_loss: 1.1809 - val_profit_accuracy: 0.3333\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0683 - profit_accuracy: 0.4024 - val_loss: 1.2222 - val_profit_accuracy: 0.2857\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0684 - profit_accuracy: 0.4083 - val_loss: 1.2040 - val_profit_accuracy: 0.3125\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0689 - profit_accuracy: 0.4048 - val_loss: 1.1815 - val_profit_accuracy: 0.3913\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0682 - profit_accuracy: 0.4016 - val_loss: 1.2310 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0683 - profit_accuracy: 0.3973 - val_loss: 1.1908 - val_profit_accuracy: 0.3158\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0680 - profit_accuracy: 0.4079 - val_loss: 1.2131 - val_profit_accuracy: 0.2857\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0679 - profit_accuracy: 0.4026 - val_loss: 1.2315 - val_profit_accuracy: 0.4000\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0685 - profit_accuracy: 0.4050 - val_loss: 1.1982 - val_profit_accuracy: 0.4167\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.0682 - profit_accuracy: 0.4055 - val_loss: 1.2362 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0683 - profit_accuracy: 0.4044 - val_loss: 1.2515 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0683 - profit_accuracy: 0.4073 - val_loss: 1.1981 - val_profit_accuracy: 0.4286\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0688 - profit_accuracy: 0.4046 - val_loss: 1.2006 - val_profit_accuracy: 0.3333\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0686 - profit_accuracy: 0.3977 - val_loss: 1.2372 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0688 - profit_accuracy: 0.3972 - val_loss: 1.2316 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0677 - profit_accuracy: 0.3995 - val_loss: 1.1863 - val_profit_accuracy: 0.3333\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0684 - profit_accuracy: 0.4024 - val_loss: 1.2307 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0686 - profit_accuracy: 0.4068 - val_loss: 1.1979 - val_profit_accuracy: 0.3333\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0684 - profit_accuracy: 0.4012 - val_loss: 1.1933 - val_profit_accuracy: 0.2222\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy: 0.4063 - val_loss: 1.2178 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0673 - profit_accuracy: 0.4044 - val_loss: 1.2623 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0682 - profit_accuracy: 0.4043 - val_loss: 1.2315 - val_profit_accuracy: 0.2857\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0683 - profit_accuracy: 0.4041 - val_loss: 1.2000 - val_profit_accuracy: 0.3636\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0688 - profit_accuracy: 0.4023 - val_loss: 1.1901 - val_profit_accuracy: 0.3125\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0682 - profit_accuracy: 0.4022 - val_loss: 1.1522 - val_profit_accuracy: 0.3651\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0680 - profit_accuracy: 0.4089 - val_loss: 1.1926 - val_profit_accuracy: 0.3333\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0685 - profit_accuracy: 0.4074 - val_loss: 1.1718 - val_profit_accuracy: 0.3056\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0668 - profit_accuracy: 0.4027 - val_loss: 1.2615 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy: 0.4042 - val_loss: 1.1661 - val_profit_accuracy: 0.3455\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0680 - profit_accuracy: 0.4030 - val_loss: 1.1884 - val_profit_accuracy: 0.3125\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0676 - profit_accuracy: 0.4138 - val_loss: 1.1542 - val_profit_accuracy: 0.3333\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy: 0.3996 - val_loss: 1.2098 - val_profit_accuracy: 0.4000\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0676 - profit_accuracy: 0.4085 - val_loss: 1.1833 - val_profit_accuracy: 0.4000\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0676 - profit_accuracy: 0.4046 - val_loss: 1.2048 - val_profit_accuracy: 0.4000\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy: 0.4020 - val_loss: 1.1834 - val_profit_accuracy: 0.3529\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy: 0.4067 - val_loss: 1.1788 - val_profit_accuracy: 0.3600\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0671 - profit_accuracy: 0.4068 - val_loss: 1.2247 - val_profit_accuracy: 0.2500\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy: 0.4012 - val_loss: 1.2270 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0674 - profit_accuracy: 0.4062 - val_loss: 1.1837 - val_profit_accuracy: 0.3125\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0670 - profit_accuracy: 0.4002 - val_loss: 1.1889 - val_profit_accuracy: 0.4211\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0676 - profit_accuracy: 0.4111 - val_loss: 1.1835 - val_profit_accuracy: 0.5909\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0678 - profit_accuracy: 0.4053 - val_loss: 1.2277 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0664 - profit_accuracy: 0.4051 - val_loss: 1.1740 - val_profit_accuracy: 0.2963\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy: 0.4070 - val_loss: 1.1555 - val_profit_accuracy: 0.3729\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0679 - profit_accuracy: 0.4002 - val_loss: 1.2102 - val_profit_accuracy: 0.3333\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0678 - profit_accuracy: 0.4042 - val_loss: 1.2110 - val_profit_accuracy: 0.4000\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy: 0.4024 - val_loss: 1.1772 - val_profit_accuracy: 0.6111\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0671 - profit_accuracy: 0.4026 - val_loss: 1.1993 - val_profit_accuracy: 0.4000\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy: 0.4064 - val_loss: 1.1633 - val_profit_accuracy: 0.3333\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0668 - profit_accuracy: 0.4109 - val_loss: 1.2095 - val_profit_accuracy: 0.2857\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0681 - profit_accuracy: 0.3997 - val_loss: 1.1978 - val_profit_accuracy: 0.3636\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0667 - profit_accuracy: 0.4074 - val_loss: 1.2301 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0667 - profit_accuracy: 0.4146 - val_loss: 1.1977 - val_profit_accuracy: 0.3571\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0666 - profit_accuracy: 0.4053 - val_loss: 1.1808 - val_profit_accuracy: 0.3929\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0665 - profit_accuracy: 0.4013 - val_loss: 1.2122 - val_profit_accuracy: 0.2857\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0669 - profit_accuracy: 0.3957 - val_loss: 1.2183 - val_profit_accuracy: 0.3333\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0674 - profit_accuracy: 0.4004 - val_loss: 1.2122 - val_profit_accuracy: 0.3571\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0676 - profit_accuracy: 0.4107 - val_loss: 1.1913 - val_profit_accuracy: 0.3600\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0664 - profit_accuracy: 0.4047 - val_loss: 1.2102 - val_profit_accuracy: 0.3333\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy: 0.4140 - val_loss: 1.2212 - val_profit_accuracy: 0.2857\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0663 - profit_accuracy: 0.4050 - val_loss: 1.2253 - val_profit_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0667 - profit_accuracy: 0.4136 - val_loss: 1.1726 - val_profit_accuracy: 0.4333\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.0664 - profit_accuracy: 0.4201 - val_loss: 1.1640 - val_profit_accuracy: 0.4000\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0672 - profit_accuracy: 0.4048 - val_loss: 1.1782 - val_profit_accuracy: 0.4074\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0664 - profit_accuracy: 0.4042 - val_loss: 1.1863 - val_profit_accuracy: 0.3600\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0658 - profit_accuracy: 0.4175 - val_loss: 1.2201 - val_profit_accuracy: 0.4286\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0665 - profit_accuracy: 0.4132 - val_loss: 1.1730 - val_profit_accuracy: 0.4138\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.0664 - profit_accuracy: 0.4006 - val_loss: 1.2211 - val_profit_accuracy: 0.2857\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0663 - profit_accuracy: 0.4124 - val_loss: 1.1966 - val_profit_accuracy: 0.3600\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0655 - profit_accuracy: 0.4026 - val_loss: 1.2014 - val_profit_accuracy: 0.3333\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Profit_accuracy = 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "y_eco = data_eco['target']\n",
    "X_eco = data_eco.drop(columns=['target'])\n",
    "\n",
    "X_train_normalized_eco, X_test_normalized_eco, y_train, y_test = data_normalized(X_eco, y_eco)\n",
    "y_pred, profit_accuracy = train_lstm_model(X_train_normalized_eco, X_test_normalized_eco, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "59/59 [==============================] - 2s 13ms/step - loss: 1.0960 - profit_accuracy_2: 0.3407 - val_loss: 1.0967 - val_profit_accuracy_2: 0.2848\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0919 - profit_accuracy_2: 0.3541 - val_loss: 1.0981 - val_profit_accuracy_2: 0.2803\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0888 - profit_accuracy_2: 0.3575 - val_loss: 1.0901 - val_profit_accuracy_2: 1.0000\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0860 - profit_accuracy_2: 0.3681 - val_loss: 1.0910 - val_profit_accuracy_2: 0.3571\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0844 - profit_accuracy_2: 0.3635 - val_loss: 1.0897 - val_profit_accuracy_2: 0.2759\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0825 - profit_accuracy_2: 0.3704 - val_loss: 1.0938 - val_profit_accuracy_2: 0.3158\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0822 - profit_accuracy_2: 0.3774 - val_loss: 1.0919 - val_profit_accuracy_2: 0.3058\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0795 - profit_accuracy_2: 0.3869 - val_loss: 1.0871 - val_profit_accuracy_2: 0.4194\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0795 - profit_accuracy_2: 0.3904 - val_loss: 1.0911 - val_profit_accuracy_2: 0.3232\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0787 - profit_accuracy_2: 0.3935 - val_loss: 1.0868 - val_profit_accuracy_2: 0.3137\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0802 - profit_accuracy_2: 0.3769 - val_loss: 1.0904 - val_profit_accuracy_2: 0.3164\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0792 - profit_accuracy_2: 0.3918 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3077\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0789 - profit_accuracy_2: 0.3764 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3367\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0791 - profit_accuracy_2: 0.3902 - val_loss: 1.0866 - val_profit_accuracy_2: 0.3103\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0795 - profit_accuracy_2: 0.3808 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3256\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0788 - profit_accuracy_2: 0.4001 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3364\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0789 - profit_accuracy_2: 0.3855 - val_loss: 1.0890 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0787 - profit_accuracy_2: 0.3969 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3399\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0785 - profit_accuracy_2: 0.3905 - val_loss: 1.0878 - val_profit_accuracy_2: 0.3507\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_2: 0.3866 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3356\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_2: 0.3960 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3438\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0786 - profit_accuracy_2: 0.3914 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3562\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0792 - profit_accuracy_2: 0.3908 - val_loss: 1.0874 - val_profit_accuracy_2: 0.3259\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0779 - profit_accuracy_2: 0.3911 - val_loss: 1.0866 - val_profit_accuracy_2: 0.3393\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_2: 0.3923 - val_loss: 1.0873 - val_profit_accuracy_2: 0.3588\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0782 - profit_accuracy_2: 0.3937 - val_loss: 1.0940 - val_profit_accuracy_2: 0.3285\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0783 - profit_accuracy_2: 0.4040 - val_loss: 1.0870 - val_profit_accuracy_2: 0.3525\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0781 - profit_accuracy_2: 0.3984 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3630\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0783 - profit_accuracy_2: 0.3797 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0778 - profit_accuracy_2: 0.3958 - val_loss: 1.0926 - val_profit_accuracy_2: 0.3245\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0789 - profit_accuracy_2: 0.4025 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3448\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0786 - profit_accuracy_2: 0.3776 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3450\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0775 - profit_accuracy_2: 0.3917 - val_loss: 1.0869 - val_profit_accuracy_2: 0.3826\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_2: 0.3920 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3608\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0784 - profit_accuracy_2: 0.3925 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3901\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0777 - profit_accuracy_2: 0.3975 - val_loss: 1.0861 - val_profit_accuracy_2: 0.3878\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0774 - profit_accuracy_2: 0.3985 - val_loss: 1.0865 - val_profit_accuracy_2: 0.4028\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0776 - profit_accuracy_2: 0.3944 - val_loss: 1.0866 - val_profit_accuracy_2: 0.4123\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0779 - profit_accuracy_2: 0.3839 - val_loss: 1.0866 - val_profit_accuracy_2: 0.4242\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0784 - profit_accuracy_2: 0.3813 - val_loss: 1.0880 - val_profit_accuracy_2: 0.3403\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0778 - profit_accuracy_2: 0.3858 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3189\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0775 - profit_accuracy_2: 0.3925 - val_loss: 1.0870 - val_profit_accuracy_2: 0.3621\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_2: 0.3910 - val_loss: 1.0870 - val_profit_accuracy_2: 0.3596\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0770 - profit_accuracy_2: 0.3973 - val_loss: 1.0865 - val_profit_accuracy_2: 0.3618\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_2: 0.3959 - val_loss: 1.0871 - val_profit_accuracy_2: 0.3584\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0771 - profit_accuracy_2: 0.3914 - val_loss: 1.0868 - val_profit_accuracy_2: 0.3731\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0769 - profit_accuracy_2: 0.3931 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3480\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0777 - profit_accuracy_2: 0.3895 - val_loss: 1.0868 - val_profit_accuracy_2: 0.3742\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0765 - profit_accuracy_2: 0.3850 - val_loss: 1.0913 - val_profit_accuracy_2: 0.3266\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0778 - profit_accuracy_2: 0.3816 - val_loss: 1.0921 - val_profit_accuracy_2: 0.3283\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0774 - profit_accuracy_2: 0.3868 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3363\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0766 - profit_accuracy_2: 0.4005 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3651\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0768 - profit_accuracy_2: 0.3913 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3349\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_2: 0.4006 - val_loss: 1.0912 - val_profit_accuracy_2: 0.3140\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0777 - profit_accuracy_2: 0.3826 - val_loss: 1.0866 - val_profit_accuracy_2: 0.4375\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0772 - profit_accuracy_2: 0.3963 - val_loss: 1.0871 - val_profit_accuracy_2: 0.3925\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0766 - profit_accuracy_2: 0.3925 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3492\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3891 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3460\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0764 - profit_accuracy_2: 0.3866 - val_loss: 1.0890 - val_profit_accuracy_2: 0.3454\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0771 - profit_accuracy_2: 0.3885 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3349\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0769 - profit_accuracy_2: 0.3798 - val_loss: 1.0863 - val_profit_accuracy_2: 0.3720\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0764 - profit_accuracy_2: 0.3974 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3429\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3935 - val_loss: 1.0874 - val_profit_accuracy_2: 0.3448\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_2: 0.3923 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3468\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_2: 0.3879 - val_loss: 1.0873 - val_profit_accuracy_2: 0.3851\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0771 - profit_accuracy_2: 0.3798 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3521\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_2: 0.3964 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3535\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3929 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3468\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0764 - profit_accuracy_2: 0.3839 - val_loss: 1.0887 - val_profit_accuracy_2: 0.3362\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0769 - profit_accuracy_2: 0.3937 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3620\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_2: 0.3938 - val_loss: 1.0865 - val_profit_accuracy_2: 0.3812\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy_2: 0.3827 - val_loss: 1.0868 - val_profit_accuracy_2: 0.3855\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_2: 0.3767 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3598\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0770 - profit_accuracy_2: 0.3911 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3188\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0764 - profit_accuracy_2: 0.3764 - val_loss: 1.0874 - val_profit_accuracy_2: 0.4000\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_2: 0.3902 - val_loss: 1.0876 - val_profit_accuracy_2: 0.3581\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0770 - profit_accuracy_2: 0.3803 - val_loss: 1.0909 - val_profit_accuracy_2: 0.3171\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_2: 0.3936 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3613\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy_2: 0.3956 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3659\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0759 - profit_accuracy_2: 0.3895 - val_loss: 1.0874 - val_profit_accuracy_2: 0.3850\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0764 - profit_accuracy_2: 0.3907 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3593\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_2: 0.3882 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3383\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_2: 0.3917 - val_loss: 1.0869 - val_profit_accuracy_2: 0.3974\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3950 - val_loss: 1.0897 - val_profit_accuracy_2: 0.3552\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0761 - profit_accuracy_2: 0.3854 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3719\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_2: 0.3828 - val_loss: 1.0908 - val_profit_accuracy_2: 0.3345\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_2: 0.4021 - val_loss: 1.0869 - val_profit_accuracy_2: 0.3795\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_2: 0.3957 - val_loss: 1.0899 - val_profit_accuracy_2: 0.3394\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_2: 0.3993 - val_loss: 1.0890 - val_profit_accuracy_2: 0.3527\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_2: 0.3834 - val_loss: 1.0893 - val_profit_accuracy_2: 0.3347\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0753 - profit_accuracy_2: 0.3952 - val_loss: 1.0895 - val_profit_accuracy_2: 0.3182\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_2: 0.3828 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3831\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0764 - profit_accuracy_2: 0.3883 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3357\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0753 - profit_accuracy_2: 0.3913 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3416\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0759 - profit_accuracy_2: 0.3930 - val_loss: 1.0928 - val_profit_accuracy_2: 0.3364\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_2: 0.3969 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3734\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_2: 0.3963 - val_loss: 1.0896 - val_profit_accuracy_2: 0.3502\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_2: 0.4002 - val_loss: 1.0889 - val_profit_accuracy_2: 0.3556\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy_2: 0.3922 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3918\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0756 - profit_accuracy_2: 0.3988 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3835\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0751 - profit_accuracy_2: 0.4020 - val_loss: 1.0897 - val_profit_accuracy_2: 0.3574\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_2: 0.3913 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3846\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.4047 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3357\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_2: 0.3832 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3839\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_2: 0.3991 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3466\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_2: 0.3864 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3543\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_2: 0.3890 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3707\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3975 - val_loss: 1.0893 - val_profit_accuracy_2: 0.3387\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0756 - profit_accuracy_2: 0.3935 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3814\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0753 - profit_accuracy_2: 0.3896 - val_loss: 1.0874 - val_profit_accuracy_2: 0.3977\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_2: 0.3999 - val_loss: 1.0898 - val_profit_accuracy_2: 0.3294\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0751 - profit_accuracy_2: 0.3896 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3883\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0753 - profit_accuracy_2: 0.3901 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3829\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0752 - profit_accuracy_2: 0.3881 - val_loss: 1.0880 - val_profit_accuracy_2: 0.3600\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0754 - profit_accuracy_2: 0.3854 - val_loss: 1.0873 - val_profit_accuracy_2: 0.3909\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0751 - profit_accuracy_2: 0.3934 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3892\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_2: 0.3983 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3795\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3950 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3973 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3756\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3906 - val_loss: 1.0925 - val_profit_accuracy_2: 0.3464\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3755 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3670\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3972 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3774\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0746 - profit_accuracy_2: 0.3948 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3858\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0745 - profit_accuracy_2: 0.3990 - val_loss: 1.0921 - val_profit_accuracy_2: 0.3377\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_2: 0.3873 - val_loss: 1.0940 - val_profit_accuracy_2: 0.3409\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_2: 0.3869 - val_loss: 1.0931 - val_profit_accuracy_2: 0.3374\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_2: 0.3899 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3463\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_2: 0.3993 - val_loss: 1.0919 - val_profit_accuracy_2: 0.3441\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_2: 0.3867 - val_loss: 1.0910 - val_profit_accuracy_2: 0.3460\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_2: 0.3902 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3712\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_2: 0.3773 - val_loss: 1.0887 - val_profit_accuracy_2: 0.3455\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0761 - profit_accuracy_2: 0.3880 - val_loss: 1.0880 - val_profit_accuracy_2: 0.3857\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0752 - profit_accuracy_2: 0.3864 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3699\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_2: 0.3914 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3644\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_2: 0.3875 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3600\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0754 - profit_accuracy_2: 0.3924 - val_loss: 1.0891 - val_profit_accuracy_2: 0.3648\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0751 - profit_accuracy_2: 0.3839 - val_loss: 1.0945 - val_profit_accuracy_2: 0.3297\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_2: 0.3778 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3949\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3982 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3613\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_2: 0.3848 - val_loss: 1.0878 - val_profit_accuracy_2: 0.3938\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_2: 0.3916 - val_loss: 1.0872 - val_profit_accuracy_2: 0.3964\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_2: 0.3929 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3702\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0746 - profit_accuracy_2: 0.4027 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3734\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0750 - profit_accuracy_2: 0.3762 - val_loss: 1.0887 - val_profit_accuracy_2: 0.3435\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0748 - profit_accuracy_2: 0.3933 - val_loss: 1.0891 - val_profit_accuracy_2: 0.3669\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0748 - profit_accuracy_2: 0.3970 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3776\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3836 - val_loss: 1.0904 - val_profit_accuracy_2: 0.3477\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3866 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3544\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_2: 0.3939 - val_loss: 1.0875 - val_profit_accuracy_2: 0.3791\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_2: 0.3984 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3534\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0747 - profit_accuracy_2: 0.3898 - val_loss: 1.0898 - val_profit_accuracy_2: 0.3462\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_2: 0.3984 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3625\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0749 - profit_accuracy_2: 0.3968 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3896\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0745 - profit_accuracy_2: 0.3966 - val_loss: 1.0921 - val_profit_accuracy_2: 0.3388\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0743 - profit_accuracy_2: 0.3862 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3587\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0745 - profit_accuracy_2: 0.3917 - val_loss: 1.0913 - val_profit_accuracy_2: 0.3469\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0747 - profit_accuracy_2: 0.3854 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3828\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_2: 0.3935 - val_loss: 1.0903 - val_profit_accuracy_2: 0.3394\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0747 - profit_accuracy_2: 0.3833 - val_loss: 1.0901 - val_profit_accuracy_2: 0.3295\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0748 - profit_accuracy_2: 0.3941 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3597\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_2: 0.3912 - val_loss: 1.0894 - val_profit_accuracy_2: 0.3454\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0746 - profit_accuracy_2: 0.3821 - val_loss: 1.0880 - val_profit_accuracy_2: 0.3814\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_2: 0.4039 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3733\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_2: 0.3989 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3750\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_2: 0.3855 - val_loss: 1.0910 - val_profit_accuracy_2: 0.3356\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0745 - profit_accuracy_2: 0.3933 - val_loss: 1.0892 - val_profit_accuracy_2: 0.3439\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0735 - profit_accuracy_2: 0.3937 - val_loss: 1.0874 - val_profit_accuracy_2: 0.4172\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_2: 0.4024 - val_loss: 1.0891 - val_profit_accuracy_2: 0.3605\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0739 - profit_accuracy_2: 0.3894 - val_loss: 1.0878 - val_profit_accuracy_2: 0.4351\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_2: 0.3969 - val_loss: 1.0889 - val_profit_accuracy_2: 0.3583\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_2: 0.4019 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3604\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0740 - profit_accuracy_2: 0.3947 - val_loss: 1.0882 - val_profit_accuracy_2: 0.3901\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0735 - profit_accuracy_2: 0.3953 - val_loss: 1.0902 - val_profit_accuracy_2: 0.3371\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0738 - profit_accuracy_2: 0.3992 - val_loss: 1.0910 - val_profit_accuracy_2: 0.3357\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_2: 0.3934 - val_loss: 1.0899 - val_profit_accuracy_2: 0.3320\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0740 - profit_accuracy_2: 0.3846 - val_loss: 1.0883 - val_profit_accuracy_2: 0.3987\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0732 - profit_accuracy_2: 0.3969 - val_loss: 1.0917 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0731 - profit_accuracy_2: 0.3942 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3970\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0740 - profit_accuracy_2: 0.3886 - val_loss: 1.0886 - val_profit_accuracy_2: 0.3522\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy_2: 0.4077 - val_loss: 1.0879 - val_profit_accuracy_2: 0.3873\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0734 - profit_accuracy_2: 0.3945 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3548\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0739 - profit_accuracy_2: 0.3992 - val_loss: 1.0882 - val_profit_accuracy_2: 0.4052\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_2: 0.3952 - val_loss: 1.0919 - val_profit_accuracy_2: 0.3367\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_2: 0.4009 - val_loss: 1.0901 - val_profit_accuracy_2: 0.3373\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0732 - profit_accuracy_2: 0.3961 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3616\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_2: 0.3971 - val_loss: 1.0932 - val_profit_accuracy_2: 0.3605\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_2: 0.3868 - val_loss: 1.0914 - val_profit_accuracy_2: 0.3549\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0737 - profit_accuracy_2: 0.3931 - val_loss: 1.0877 - val_profit_accuracy_2: 0.3898\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_2: 0.4040 - val_loss: 1.0892 - val_profit_accuracy_2: 0.3554\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0732 - profit_accuracy_2: 0.3922 - val_loss: 1.0893 - val_profit_accuracy_2: 0.3740\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0731 - profit_accuracy_2: 0.3950 - val_loss: 1.0897 - val_profit_accuracy_2: 0.3360\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy_2: 0.3988 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3581\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0728 - profit_accuracy_2: 0.3906 - val_loss: 1.0904 - val_profit_accuracy_2: 0.3333\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0727 - profit_accuracy_2: 0.4004 - val_loss: 1.0905 - val_profit_accuracy_2: 0.3450\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy_2: 0.3968 - val_loss: 1.0934 - val_profit_accuracy_2: 0.3292\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0738 - profit_accuracy_2: 0.3888 - val_loss: 1.0923 - val_profit_accuracy_2: 0.3378\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0728 - profit_accuracy_2: 0.3942 - val_loss: 1.0885 - val_profit_accuracy_2: 0.3636\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0727 - profit_accuracy_2: 0.3948 - val_loss: 1.0888 - val_profit_accuracy_2: 0.3581\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0722 - profit_accuracy_2: 0.3986 - val_loss: 1.0881 - val_profit_accuracy_2: 0.3858\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0738 - profit_accuracy_2: 0.3833 - val_loss: 1.0884 - val_profit_accuracy_2: 0.3762\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Profit_accuracy = 0.3761904835700989\n"
     ]
    }
   ],
   "source": [
    "y_tech = data_tech['target']\n",
    "X_tech = data_tech.drop(columns=['target'])\n",
    "\n",
    "X_train_normalized_tech, X_test_normalized_tech, y_train, y_test = data_normalized(X_tech, y_tech)\n",
    "y_pred, profit_accuracy = train_lstm_model(X_train_normalized_tech, X_test_normalized_tech, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions(me_pred_probs, ti_pred_probs):\n",
    "    combined_pred_probs = []\n",
    "\n",
    "    for me_probs, ti_probs in zip(me_pred_probs, ti_pred_probs):\n",
    "        # If one model's prediction is class_noact, set final decision as class_noact\n",
    "        if np.argmax(me_probs) == 0 or np.argmax(ti_probs) == 0:\n",
    "            combined_pred_probs.append([1, 0, 0])  # class_noact one-hot encoding\n",
    "        # If both models agree on labels, set final decision as this label\n",
    "        elif np.argmax(me_probs) == np.argmax(ti_probs):\n",
    "            combined_pred_probs.append(me_probs)  # Use either model's probabilities\n",
    "        # If predictions of the two models are different, choose the one with higher probability\n",
    "        else:\n",
    "            max_prob_index = np.argmax([np.max(me_probs), np.max(ti_probs)])\n",
    "            if max_prob_index == 0:\n",
    "                combined_pred_probs.append(me_probs)  # Use ME_LSTM's probabilities\n",
    "            else:\n",
    "                combined_pred_probs.append(ti_probs)  # Use TI_LSTM's probabilities\n",
    "\n",
    "    return np.array(combined_pred_probs)\n",
    "\n",
    "\n",
    "def train_lstm_model_combine(X_train_eco, X_test_eco, X_train_tech, X_test_tech, y_train, y_test, lstm_units=lstm_units, epochs=epochs, batch_size=batch_size):\n",
    "    # Train ME_LSTM model\n",
    "    me_pred_probs, _ = train_lstm_model(X_train_eco, X_test_eco, y_train, y_test, lstm_units, epochs, batch_size)\n",
    "\n",
    "    # Train TI_LSTM model\n",
    "    # ti_pred_probs, _ = train_lstm_model(X_train_tech, X_test_tech, y_train, y_test, lstm_units, epochs, batch_size)\n",
    "    ti_pred_probs, _ = train_lstm_model(X_train_tech, X_test_tech, y_train, y_test, lstm_units, epochs, batch_size)\n",
    "\n",
    "    # Combine predictions\n",
    "    combined_pred_probs = combine_predictions(me_pred_probs, ti_pred_probs)\n",
    "\n",
    "    # Convert y_test to one-hot encoding\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y_train)\n",
    "    encoded_y_test = encoder.transform(y_test)\n",
    "    y_test_onehot = to_categorical(encoded_y_test)\n",
    "\n",
    "    # Evaluate the combined model using ProfitAccuracy metric\n",
    "    profit_accuracy = ProfitAccuracy()(y_test_onehot, combined_pred_probs)\n",
    "    print(f\"Combine profit_accuracy = {profit_accuracy}\")\n",
    "\n",
    "    return combined_pred_probs, profit_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "59/59 [==============================] - 2s 13ms/step - loss: 1.0919 - profit_accuracy_4: 0.3625 - val_loss: 1.0821 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0836 - profit_accuracy_4: 0.3747 - val_loss: 1.0840 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0802 - profit_accuracy_4: 0.3920 - val_loss: 1.1129 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0791 - profit_accuracy_4: 0.3710 - val_loss: 1.1164 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0785 - profit_accuracy_4: 0.3838 - val_loss: 1.0975 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0779 - profit_accuracy_4: 0.3841 - val_loss: 1.1144 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0783 - profit_accuracy_4: 0.3821 - val_loss: 1.1054 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0776 - profit_accuracy_4: 0.3873 - val_loss: 1.1038 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0776 - profit_accuracy_4: 0.3826 - val_loss: 1.1051 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_4: 0.3905 - val_loss: 1.1187 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_4: 0.3857 - val_loss: 1.1216 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0761 - profit_accuracy_4: 0.3852 - val_loss: 1.1230 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_4: 0.3800 - val_loss: 1.1313 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_4: 0.3857 - val_loss: 1.1124 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0746 - profit_accuracy_4: 0.3929 - val_loss: 1.1110 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_4: 0.4000 - val_loss: 1.1256 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_4: 0.3914 - val_loss: 1.1598 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_4: 0.3995 - val_loss: 1.1614 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0735 - profit_accuracy_4: 0.3931 - val_loss: 1.1292 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0742 - profit_accuracy_4: 0.3953 - val_loss: 1.1422 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_4: 0.3900 - val_loss: 1.1213 - val_profit_accuracy_4: 0.3000\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy_4: 0.3913 - val_loss: 1.1683 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0728 - profit_accuracy_4: 0.3991 - val_loss: 1.1412 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0729 - profit_accuracy_4: 0.4011 - val_loss: 1.1160 - val_profit_accuracy_4: 0.3478\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0735 - profit_accuracy_4: 0.3914 - val_loss: 1.1778 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0729 - profit_accuracy_4: 0.3977 - val_loss: 1.1528 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0724 - profit_accuracy_4: 0.4008 - val_loss: 1.1205 - val_profit_accuracy_4: 0.3500\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0726 - profit_accuracy_4: 0.3878 - val_loss: 1.1820 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy_4: 0.3920 - val_loss: 1.1556 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0726 - profit_accuracy_4: 0.3988 - val_loss: 1.1861 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0731 - profit_accuracy_4: 0.4013 - val_loss: 1.1389 - val_profit_accuracy_4: 0.3548\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0728 - profit_accuracy_4: 0.3866 - val_loss: 1.1594 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0722 - profit_accuracy_4: 0.3928 - val_loss: 1.1499 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy_4: 0.3903 - val_loss: 1.1478 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0722 - profit_accuracy_4: 0.3933 - val_loss: 1.1332 - val_profit_accuracy_4: 0.4286\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0715 - profit_accuracy_4: 0.3883 - val_loss: 1.1664 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0723 - profit_accuracy_4: 0.3871 - val_loss: 1.1781 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0715 - profit_accuracy_4: 0.3965 - val_loss: 1.2010 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0723 - profit_accuracy_4: 0.3921 - val_loss: 1.1692 - val_profit_accuracy_4: 0.2941\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0712 - profit_accuracy_4: 0.3966 - val_loss: 1.1304 - val_profit_accuracy_4: 0.3786\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0721 - profit_accuracy_4: 0.3881 - val_loss: 1.2568 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0725 - profit_accuracy_4: 0.3978 - val_loss: 1.1458 - val_profit_accuracy_4: 0.3750\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0713 - profit_accuracy_4: 0.3864 - val_loss: 1.2260 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0721 - profit_accuracy_4: 0.3991 - val_loss: 1.1417 - val_profit_accuracy_4: 0.3878\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0727 - profit_accuracy_4: 0.3870 - val_loss: 1.1966 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0716 - profit_accuracy_4: 0.3887 - val_loss: 1.2485 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0718 - profit_accuracy_4: 0.3886 - val_loss: 1.1430 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0712 - profit_accuracy_4: 0.3948 - val_loss: 1.1653 - val_profit_accuracy_4: 0.3000\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0712 - profit_accuracy_4: 0.3951 - val_loss: 1.2002 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0711 - profit_accuracy_4: 0.3922 - val_loss: 1.2150 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0709 - profit_accuracy_4: 0.3968 - val_loss: 1.1771 - val_profit_accuracy_4: 0.2941\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0706 - profit_accuracy_4: 0.3972 - val_loss: 1.1532 - val_profit_accuracy_4: 0.3182\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0712 - profit_accuracy_4: 0.3933 - val_loss: 1.1977 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0708 - profit_accuracy_4: 0.3916 - val_loss: 1.1627 - val_profit_accuracy_4: 0.3600\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0713 - profit_accuracy_4: 0.3921 - val_loss: 1.1887 - val_profit_accuracy_4: 0.3077\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0704 - profit_accuracy_4: 0.4023 - val_loss: 1.1582 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0704 - profit_accuracy_4: 0.3918 - val_loss: 1.1964 - val_profit_accuracy_4: 0.3077\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0712 - profit_accuracy_4: 0.3955 - val_loss: 1.2040 - val_profit_accuracy_4: 0.4000\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0704 - profit_accuracy_4: 0.3886 - val_loss: 1.1956 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0703 - profit_accuracy_4: 0.3944 - val_loss: 1.2260 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0699 - profit_accuracy_4: 0.3971 - val_loss: 1.2477 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0709 - profit_accuracy_4: 0.3970 - val_loss: 1.2574 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0706 - profit_accuracy_4: 0.3950 - val_loss: 1.1739 - val_profit_accuracy_4: 0.4074\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0704 - profit_accuracy_4: 0.3938 - val_loss: 1.1634 - val_profit_accuracy_4: 0.3704\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy_4: 0.3990 - val_loss: 1.1777 - val_profit_accuracy_4: 0.3750\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0698 - profit_accuracy_4: 0.3975 - val_loss: 1.1976 - val_profit_accuracy_4: 0.3125\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0708 - profit_accuracy_4: 0.3907 - val_loss: 1.1790 - val_profit_accuracy_4: 0.3600\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0707 - profit_accuracy_4: 0.3899 - val_loss: 1.2344 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0704 - profit_accuracy_4: 0.4035 - val_loss: 1.1982 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0701 - profit_accuracy_4: 0.3929 - val_loss: 1.2306 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0704 - profit_accuracy_4: 0.4003 - val_loss: 1.1774 - val_profit_accuracy_4: 0.3448\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0701 - profit_accuracy_4: 0.3926 - val_loss: 1.2405 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0694 - profit_accuracy_4: 0.3840 - val_loss: 1.2638 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy_4: 0.3912 - val_loss: 1.1596 - val_profit_accuracy_4: 0.3906\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0705 - profit_accuracy_4: 0.3981 - val_loss: 1.2288 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy_4: 0.4017 - val_loss: 1.1644 - val_profit_accuracy_4: 0.2941\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0700 - profit_accuracy_4: 0.3934 - val_loss: 1.1728 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0699 - profit_accuracy_4: 0.3944 - val_loss: 1.2171 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0703 - profit_accuracy_4: 0.4003 - val_loss: 1.2741 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0706 - profit_accuracy_4: 0.3884 - val_loss: 1.2162 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy_4: 0.3926 - val_loss: 1.2483 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy_4: 0.4034 - val_loss: 1.1859 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0695 - profit_accuracy_4: 0.3932 - val_loss: 1.1662 - val_profit_accuracy_4: 0.3500\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0702 - profit_accuracy_4: 0.3967 - val_loss: 1.2743 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0706 - profit_accuracy_4: 0.3994 - val_loss: 1.2041 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy_4: 0.3992 - val_loss: 1.1972 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy_4: 0.4045 - val_loss: 1.2133 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0699 - profit_accuracy_4: 0.3978 - val_loss: 1.2330 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0690 - profit_accuracy_4: 0.3968 - val_loss: 1.2206 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0696 - profit_accuracy_4: 0.3985 - val_loss: 1.1781 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0703 - profit_accuracy_4: 0.4026 - val_loss: 1.2241 - val_profit_accuracy_4: 0.3125\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0692 - profit_accuracy_4: 0.4027 - val_loss: 1.1677 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0693 - profit_accuracy_4: 0.3983 - val_loss: 1.1535 - val_profit_accuracy_4: 0.3932\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0695 - profit_accuracy_4: 0.4020 - val_loss: 1.1757 - val_profit_accuracy_4: 0.2647\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0691 - profit_accuracy_4: 0.4029 - val_loss: 1.2490 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0688 - profit_accuracy_4: 0.3977 - val_loss: 1.1883 - val_profit_accuracy_4: 0.3462\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0690 - profit_accuracy_4: 0.4005 - val_loss: 1.2343 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0690 - profit_accuracy_4: 0.4031 - val_loss: 1.2090 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0690 - profit_accuracy_4: 0.3968 - val_loss: 1.2512 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0700 - profit_accuracy_4: 0.3949 - val_loss: 1.1982 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0687 - profit_accuracy_4: 0.3998 - val_loss: 1.2332 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0695 - profit_accuracy_4: 0.4061 - val_loss: 1.1975 - val_profit_accuracy_4: 0.3077\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0689 - profit_accuracy_4: 0.3963 - val_loss: 1.2148 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0696 - profit_accuracy_4: 0.3999 - val_loss: 1.2536 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0686 - profit_accuracy_4: 0.3966 - val_loss: 1.1906 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0691 - profit_accuracy_4: 0.3952 - val_loss: 1.1779 - val_profit_accuracy_4: 0.3871\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0691 - profit_accuracy_4: 0.3982 - val_loss: 1.2042 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0690 - profit_accuracy_4: 0.4030 - val_loss: 1.2023 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0692 - profit_accuracy_4: 0.3979 - val_loss: 1.2169 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0685 - profit_accuracy_4: 0.4041 - val_loss: 1.2164 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0686 - profit_accuracy_4: 0.4009 - val_loss: 1.2158 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0681 - profit_accuracy_4: 0.4004 - val_loss: 1.1563 - val_profit_accuracy_4: 0.3803\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0697 - profit_accuracy_4: 0.4035 - val_loss: 1.2176 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0698 - profit_accuracy_4: 0.4052 - val_loss: 1.2051 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0687 - profit_accuracy_4: 0.4022 - val_loss: 1.1531 - val_profit_accuracy_4: 0.2933\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0688 - profit_accuracy_4: 0.3923 - val_loss: 1.2403 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0693 - profit_accuracy_4: 0.4014 - val_loss: 1.2515 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.0681 - profit_accuracy_4: 0.4054 - val_loss: 1.1909 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 1.0683 - profit_accuracy_4: 0.4054 - val_loss: 1.2342 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 1.0686 - profit_accuracy_4: 0.4032 - val_loss: 1.2037 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 1.0690 - profit_accuracy_4: 0.3881 - val_loss: 1.2112 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0694 - profit_accuracy_4: 0.4009 - val_loss: 1.1630 - val_profit_accuracy_4: 0.3103\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0680 - profit_accuracy_4: 0.4026 - val_loss: 1.2323 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0687 - profit_accuracy_4: 0.3976 - val_loss: 1.2603 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0690 - profit_accuracy_4: 0.3979 - val_loss: 1.2139 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0686 - profit_accuracy_4: 0.3960 - val_loss: 1.1945 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0678 - profit_accuracy_4: 0.4116 - val_loss: 1.1735 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0685 - profit_accuracy_4: 0.4029 - val_loss: 1.1572 - val_profit_accuracy_4: 0.3866\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0688 - profit_accuracy_4: 0.4035 - val_loss: 1.2578 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0681 - profit_accuracy_4: 0.3999 - val_loss: 1.1820 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.0681 - profit_accuracy_4: 0.4026 - val_loss: 1.1795 - val_profit_accuracy_4: 0.4194\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.0682 - profit_accuracy_4: 0.4028 - val_loss: 1.2318 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.0682 - profit_accuracy_4: 0.4045 - val_loss: 1.2212 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.0686 - profit_accuracy_4: 0.4019 - val_loss: 1.2064 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0681 - profit_accuracy_4: 0.4031 - val_loss: 1.1810 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0682 - profit_accuracy_4: 0.3959 - val_loss: 1.1681 - val_profit_accuracy_4: 0.3906\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0689 - profit_accuracy_4: 0.3942 - val_loss: 1.1524 - val_profit_accuracy_4: 0.3718\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0687 - profit_accuracy_4: 0.3900 - val_loss: 1.2664 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0695 - profit_accuracy_4: 0.4058 - val_loss: 1.2065 - val_profit_accuracy_4: 0.4000\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy_4: 0.3948 - val_loss: 1.1920 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0684 - profit_accuracy_4: 0.4040 - val_loss: 1.1827 - val_profit_accuracy_4: 0.3478\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0682 - profit_accuracy_4: 0.4131 - val_loss: 1.1788 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0674 - profit_accuracy_4: 0.4110 - val_loss: 1.1792 - val_profit_accuracy_4: 0.5294\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0681 - profit_accuracy_4: 0.4043 - val_loss: 1.1902 - val_profit_accuracy_4: 0.3500\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0680 - profit_accuracy_4: 0.4025 - val_loss: 1.2357 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0678 - profit_accuracy_4: 0.4055 - val_loss: 1.1853 - val_profit_accuracy_4: 0.2941\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0680 - profit_accuracy_4: 0.4015 - val_loss: 1.2013 - val_profit_accuracy_4: 0.3125\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0683 - profit_accuracy_4: 0.4026 - val_loss: 1.1961 - val_profit_accuracy_4: 0.2222\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0679 - profit_accuracy_4: 0.4019 - val_loss: 1.1992 - val_profit_accuracy_4: 0.3571\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy_4: 0.4093 - val_loss: 1.1871 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy_4: 0.4055 - val_loss: 1.1764 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0678 - profit_accuracy_4: 0.4112 - val_loss: 1.2227 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0677 - profit_accuracy_4: 0.4118 - val_loss: 1.2668 - val_profit_accuracy_4: 0.0000e+00\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0682 - profit_accuracy_4: 0.4056 - val_loss: 1.2359 - val_profit_accuracy_4: 0.4000\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0671 - profit_accuracy_4: 0.4057 - val_loss: 1.2025 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0676 - profit_accuracy_4: 0.4025 - val_loss: 1.1973 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy_4: 0.4045 - val_loss: 1.2278 - val_profit_accuracy_4: 0.2500\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0677 - profit_accuracy_4: 0.4038 - val_loss: 1.2190 - val_profit_accuracy_4: 0.2857\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0680 - profit_accuracy_4: 0.4032 - val_loss: 1.1983 - val_profit_accuracy_4: 0.4444\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy_4: 0.3951 - val_loss: 1.2132 - val_profit_accuracy_4: 0.3125\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0686 - profit_accuracy_4: 0.4076 - val_loss: 1.1629 - val_profit_accuracy_4: 0.5357\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0672 - profit_accuracy_4: 0.3988 - val_loss: 1.2089 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0678 - profit_accuracy_4: 0.4016 - val_loss: 1.1814 - val_profit_accuracy_4: 0.5500\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0676 - profit_accuracy_4: 0.4019 - val_loss: 1.2061 - val_profit_accuracy_4: 0.3636\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0676 - profit_accuracy_4: 0.3976 - val_loss: 1.1711 - val_profit_accuracy_4: 0.4000\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0666 - profit_accuracy_4: 0.4085 - val_loss: 1.1346 - val_profit_accuracy_4: 0.3874\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0678 - profit_accuracy_4: 0.4088 - val_loss: 1.1660 - val_profit_accuracy_4: 0.3953\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0669 - profit_accuracy_4: 0.4032 - val_loss: 1.1836 - val_profit_accuracy_4: 0.3333\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0683 - profit_accuracy_4: 0.4068 - val_loss: 1.1850 - val_profit_accuracy_4: 0.3929\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0674 - profit_accuracy_4: 0.4064 - val_loss: 1.1725 - val_profit_accuracy_4: 0.5312\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0670 - profit_accuracy_4: 0.4019 - val_loss: 1.1743 - val_profit_accuracy_4: 0.4800\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0668 - profit_accuracy_4: 0.4127 - val_loss: 1.1800 - val_profit_accuracy_4: 0.4545\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0672 - profit_accuracy_4: 0.4076 - val_loss: 1.1837 - val_profit_accuracy_4: 0.2917\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0663 - profit_accuracy_4: 0.4164 - val_loss: 1.1502 - val_profit_accuracy_4: 0.3871\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0669 - profit_accuracy_4: 0.4044 - val_loss: 1.1868 - val_profit_accuracy_4: 0.3158\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0673 - profit_accuracy_4: 0.4099 - val_loss: 1.1717 - val_profit_accuracy_4: 0.3548\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0677 - profit_accuracy_4: 0.4067 - val_loss: 1.1559 - val_profit_accuracy_4: 0.4211\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0667 - profit_accuracy_4: 0.4099 - val_loss: 1.1420 - val_profit_accuracy_4: 0.4154\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0667 - profit_accuracy_4: 0.4026 - val_loss: 1.1935 - val_profit_accuracy_4: 0.4667\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0664 - profit_accuracy_4: 0.4036 - val_loss: 1.1714 - val_profit_accuracy_4: 0.3871\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0663 - profit_accuracy_4: 0.4124 - val_loss: 1.1540 - val_profit_accuracy_4: 0.3958\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0663 - profit_accuracy_4: 0.4060 - val_loss: 1.1517 - val_profit_accuracy_4: 0.4127\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0674 - profit_accuracy_4: 0.4098 - val_loss: 1.1547 - val_profit_accuracy_4: 0.3962\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0675 - profit_accuracy_4: 0.4009 - val_loss: 1.1686 - val_profit_accuracy_4: 0.3448\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0666 - profit_accuracy_4: 0.4047 - val_loss: 1.1949 - val_profit_accuracy_4: 0.6000\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0673 - profit_accuracy_4: 0.4124 - val_loss: 1.1549 - val_profit_accuracy_4: 0.5102\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0662 - profit_accuracy_4: 0.4155 - val_loss: 1.1844 - val_profit_accuracy_4: 0.4167\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0669 - profit_accuracy_4: 0.4091 - val_loss: 1.1833 - val_profit_accuracy_4: 0.3043\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0665 - profit_accuracy_4: 0.4083 - val_loss: 1.1831 - val_profit_accuracy_4: 0.4138\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0666 - profit_accuracy_4: 0.4083 - val_loss: 1.1971 - val_profit_accuracy_4: 0.3600\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0675 - profit_accuracy_4: 0.4039 - val_loss: 1.1486 - val_profit_accuracy_4: 0.4167\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0664 - profit_accuracy_4: 0.4038 - val_loss: 1.1625 - val_profit_accuracy_4: 0.4412\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0667 - profit_accuracy_4: 0.4093 - val_loss: 1.1730 - val_profit_accuracy_4: 0.3600\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0668 - profit_accuracy_4: 0.4084 - val_loss: 1.1473 - val_profit_accuracy_4: 0.4127\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0666 - profit_accuracy_4: 0.4127 - val_loss: 1.1605 - val_profit_accuracy_4: 0.4516\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0658 - profit_accuracy_4: 0.4271 - val_loss: 1.1453 - val_profit_accuracy_4: 0.4314\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0659 - profit_accuracy_4: 0.4100 - val_loss: 1.1654 - val_profit_accuracy_4: 0.4474\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0654 - profit_accuracy_4: 0.4140 - val_loss: 1.1636 - val_profit_accuracy_4: 0.4634\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0661 - profit_accuracy_4: 0.4060 - val_loss: 1.1712 - val_profit_accuracy_4: 0.3947\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0652 - profit_accuracy_4: 0.4132 - val_loss: 1.1496 - val_profit_accuracy_4: 0.4167\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Profit_accuracy = 0.4166666567325592\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 2s 13ms/step - loss: 1.0959 - profit_accuracy_6: 0.3464 - val_loss: 1.1034 - val_profit_accuracy_6: 0.2839\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0918 - profit_accuracy_6: 0.3579 - val_loss: 1.0933 - val_profit_accuracy_6: 0.3433\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0897 - profit_accuracy_6: 0.3551 - val_loss: 1.0927 - val_profit_accuracy_6: 0.3846\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0870 - profit_accuracy_6: 0.3704 - val_loss: 1.0899 - val_profit_accuracy_6: 0.2500\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0855 - profit_accuracy_6: 0.3606 - val_loss: 1.0899 - val_profit_accuracy_6: 0.2727\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0831 - profit_accuracy_6: 0.3754 - val_loss: 1.0881 - val_profit_accuracy_6: 0.2500\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0819 - profit_accuracy_6: 0.3845 - val_loss: 1.0884 - val_profit_accuracy_6: 0.2698\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0811 - profit_accuracy_6: 0.3702 - val_loss: 1.0891 - val_profit_accuracy_6: 0.2900\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0801 - profit_accuracy_6: 0.3858 - val_loss: 1.0858 - val_profit_accuracy_6: 0.2581\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0802 - profit_accuracy_6: 0.3970 - val_loss: 1.0876 - val_profit_accuracy_6: 0.2821\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0793 - profit_accuracy_6: 0.3889 - val_loss: 1.0859 - val_profit_accuracy_6: 0.3684\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0801 - profit_accuracy_6: 0.3952 - val_loss: 1.0874 - val_profit_accuracy_6: 0.2830\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0797 - profit_accuracy_6: 0.3765 - val_loss: 1.0875 - val_profit_accuracy_6: 0.3143\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0796 - profit_accuracy_6: 0.3876 - val_loss: 1.0915 - val_profit_accuracy_6: 0.3319\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0795 - profit_accuracy_6: 0.3841 - val_loss: 1.0865 - val_profit_accuracy_6: 0.3462\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_6: 0.3949 - val_loss: 1.0869 - val_profit_accuracy_6: 0.3070\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0791 - profit_accuracy_6: 0.3825 - val_loss: 1.0875 - val_profit_accuracy_6: 0.3274\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0786 - profit_accuracy_6: 0.3881 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3776\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0794 - profit_accuracy_6: 0.3812 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3359\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_6: 0.3924 - val_loss: 1.0865 - val_profit_accuracy_6: 0.3562\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0785 - profit_accuracy_6: 0.3913 - val_loss: 1.0866 - val_profit_accuracy_6: 0.3636\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0781 - profit_accuracy_6: 0.3914 - val_loss: 1.0863 - val_profit_accuracy_6: 0.3571\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0787 - profit_accuracy_6: 0.4069 - val_loss: 1.0869 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0782 - profit_accuracy_6: 0.3934 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3494\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0789 - profit_accuracy_6: 0.3802 - val_loss: 1.0900 - val_profit_accuracy_6: 0.3413\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0785 - profit_accuracy_6: 0.3931 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3394\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0780 - profit_accuracy_6: 0.3910 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3673\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0782 - profit_accuracy_6: 0.3928 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3370\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_6: 0.3907 - val_loss: 1.0867 - val_profit_accuracy_6: 0.3976\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0782 - profit_accuracy_6: 0.3883 - val_loss: 1.0878 - val_profit_accuracy_6: 0.3654\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0776 - profit_accuracy_6: 0.4051 - val_loss: 1.0861 - val_profit_accuracy_6: 0.3810\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0779 - profit_accuracy_6: 0.3927 - val_loss: 1.0860 - val_profit_accuracy_6: 0.3725\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0797 - profit_accuracy_6: 0.3942 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3459\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0777 - profit_accuracy_6: 0.4003 - val_loss: 1.0863 - val_profit_accuracy_6: 0.3556\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0790 - profit_accuracy_6: 0.3884 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3545\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0791 - profit_accuracy_6: 0.3969 - val_loss: 1.0870 - val_profit_accuracy_6: 0.3567\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0781 - profit_accuracy_6: 0.3820 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3474\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0774 - profit_accuracy_6: 0.3965 - val_loss: 1.0872 - val_profit_accuracy_6: 0.3648\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0774 - profit_accuracy_6: 0.3915 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3533\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0783 - profit_accuracy_6: 0.3972 - val_loss: 1.0867 - val_profit_accuracy_6: 0.3869\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0775 - profit_accuracy_6: 0.3933 - val_loss: 1.0869 - val_profit_accuracy_6: 0.4085\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0784 - profit_accuracy_6: 0.3889 - val_loss: 1.0863 - val_profit_accuracy_6: 0.4369\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0770 - profit_accuracy_6: 0.3938 - val_loss: 1.0869 - val_profit_accuracy_6: 0.3600\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_6: 0.3975 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3321\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0768 - profit_accuracy_6: 0.3826 - val_loss: 1.0868 - val_profit_accuracy_6: 0.3895\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0776 - profit_accuracy_6: 0.4028 - val_loss: 1.0863 - val_profit_accuracy_6: 0.4000\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0772 - profit_accuracy_6: 0.3919 - val_loss: 1.0865 - val_profit_accuracy_6: 0.3963\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy_6: 0.3883 - val_loss: 1.0871 - val_profit_accuracy_6: 0.3714\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0777 - profit_accuracy_6: 0.3875 - val_loss: 1.0865 - val_profit_accuracy_6: 0.4365\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0769 - profit_accuracy_6: 0.3884 - val_loss: 1.0910 - val_profit_accuracy_6: 0.3447\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0789 - profit_accuracy_6: 0.3961 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3145\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0774 - profit_accuracy_6: 0.3842 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3825\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0769 - profit_accuracy_6: 0.3929 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3438\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0773 - profit_accuracy_6: 0.3963 - val_loss: 1.0867 - val_profit_accuracy_6: 0.4236\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy_6: 0.3860 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3925\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0758 - profit_accuracy_6: 0.3865 - val_loss: 1.0907 - val_profit_accuracy_6: 0.3151\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0770 - profit_accuracy_6: 0.3757 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3436\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_6: 0.3899 - val_loss: 1.0871 - val_profit_accuracy_6: 0.3913\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3809 - val_loss: 1.0868 - val_profit_accuracy_6: 0.3889\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0774 - profit_accuracy_6: 0.3921 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3186\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy_6: 0.3935 - val_loss: 1.0863 - val_profit_accuracy_6: 0.4370\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.0772 - profit_accuracy_6: 0.3940 - val_loss: 1.0878 - val_profit_accuracy_6: 0.3575\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_6: 0.3795 - val_loss: 1.0867 - val_profit_accuracy_6: 0.4091\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_6: 0.3895 - val_loss: 1.0897 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0765 - profit_accuracy_6: 0.3838 - val_loss: 1.0900 - val_profit_accuracy_6: 0.3455\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3825 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3417\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3898 - val_loss: 1.0868 - val_profit_accuracy_6: 0.3791\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0767 - profit_accuracy_6: 0.3986 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3484\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0770 - profit_accuracy_6: 0.3843 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3380\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0760 - profit_accuracy_6: 0.3876 - val_loss: 1.0868 - val_profit_accuracy_6: 0.4434\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3960 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3657\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0769 - profit_accuracy_6: 0.3864 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3627\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_6: 0.3868 - val_loss: 1.0877 - val_profit_accuracy_6: 0.3744\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0759 - profit_accuracy_6: 0.3967 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3816\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0758 - profit_accuracy_6: 0.3872 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3381\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0761 - profit_accuracy_6: 0.3976 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3565\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_6: 0.3894 - val_loss: 1.0873 - val_profit_accuracy_6: 0.4124\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_6: 0.3875 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3636\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0763 - profit_accuracy_6: 0.3765 - val_loss: 1.0926 - val_profit_accuracy_6: 0.3374\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_6: 0.3920 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3829\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3932 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3597\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0764 - profit_accuracy_6: 0.3939 - val_loss: 1.0894 - val_profit_accuracy_6: 0.3520\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0763 - profit_accuracy_6: 0.3805 - val_loss: 1.0895 - val_profit_accuracy_6: 0.3321\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_6: 0.3925 - val_loss: 1.0941 - val_profit_accuracy_6: 0.3409\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3866 - val_loss: 1.0896 - val_profit_accuracy_6: 0.3577\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0760 - profit_accuracy_6: 0.3947 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3673\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0761 - profit_accuracy_6: 0.3933 - val_loss: 1.0895 - val_profit_accuracy_6: 0.3563\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3923 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3364\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0756 - profit_accuracy_6: 0.3957 - val_loss: 1.0874 - val_profit_accuracy_6: 0.3989\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0756 - profit_accuracy_6: 0.3941 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3394\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0766 - profit_accuracy_6: 0.3883 - val_loss: 1.0915 - val_profit_accuracy_6: 0.3344\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0767 - profit_accuracy_6: 0.3877 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3654\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3953 - val_loss: 1.0876 - val_profit_accuracy_6: 0.3756\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0757 - profit_accuracy_6: 0.3995 - val_loss: 1.0915 - val_profit_accuracy_6: 0.3432\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0759 - profit_accuracy_6: 0.3936 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3532\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0754 - profit_accuracy_6: 0.3937 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3559\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_6: 0.3869 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3432\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0758 - profit_accuracy_6: 0.3891 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3428\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_6: 0.3904 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3877\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0760 - profit_accuracy_6: 0.3923 - val_loss: 1.0875 - val_profit_accuracy_6: 0.3936\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0759 - profit_accuracy_6: 0.3908 - val_loss: 1.0873 - val_profit_accuracy_6: 0.4035\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3990 - val_loss: 1.0891 - val_profit_accuracy_6: 0.3534\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3837 - val_loss: 1.0890 - val_profit_accuracy_6: 0.3247\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_6: 0.3863 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3733\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3914 - val_loss: 1.0880 - val_profit_accuracy_6: 0.3869\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0753 - profit_accuracy_6: 0.3923 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3529\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0762 - profit_accuracy_6: 0.3775 - val_loss: 1.0904 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3912 - val_loss: 1.0877 - val_profit_accuracy_6: 0.3807\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_6: 0.3871 - val_loss: 1.0875 - val_profit_accuracy_6: 0.3858\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0750 - profit_accuracy_6: 0.3890 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3805\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0759 - profit_accuracy_6: 0.3936 - val_loss: 1.0873 - val_profit_accuracy_6: 0.3958\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0758 - profit_accuracy_6: 0.3911 - val_loss: 1.0884 - val_profit_accuracy_6: 0.3621\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0753 - profit_accuracy_6: 0.3934 - val_loss: 1.0900 - val_profit_accuracy_6: 0.3284\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_6: 0.3929 - val_loss: 1.0878 - val_profit_accuracy_6: 0.3465\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0756 - profit_accuracy_6: 0.3894 - val_loss: 1.0927 - val_profit_accuracy_6: 0.3343\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0759 - profit_accuracy_6: 0.3856 - val_loss: 1.0878 - val_profit_accuracy_6: 0.3786\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0753 - profit_accuracy_6: 0.3890 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3761\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_6: 0.3785 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3497\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0754 - profit_accuracy_6: 0.3913 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3419\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0758 - profit_accuracy_6: 0.3904 - val_loss: 1.0917 - val_profit_accuracy_6: 0.3378\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0750 - profit_accuracy_6: 0.3998 - val_loss: 1.0884 - val_profit_accuracy_6: 0.3649\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0756 - profit_accuracy_6: 0.3881 - val_loss: 1.0901 - val_profit_accuracy_6: 0.3320\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_6: 0.3939 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3502\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0753 - profit_accuracy_6: 0.3904 - val_loss: 1.0884 - val_profit_accuracy_6: 0.3750\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0766 - profit_accuracy_6: 0.3961 - val_loss: 1.0874 - val_profit_accuracy_6: 0.3918\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0751 - profit_accuracy_6: 0.3893 - val_loss: 1.0880 - val_profit_accuracy_6: 0.3767\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3941 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3415\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0757 - profit_accuracy_6: 0.3921 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3432\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0749 - profit_accuracy_6: 0.3942 - val_loss: 1.0887 - val_profit_accuracy_6: 0.3613\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3947 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3482\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_6: 0.3914 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3756\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3893 - val_loss: 1.0926 - val_profit_accuracy_6: 0.3354\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_6: 0.3894 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3799\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0748 - profit_accuracy_6: 0.3836 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3738\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0760 - profit_accuracy_6: 0.3886 - val_loss: 1.0896 - val_profit_accuracy_6: 0.3597\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0753 - profit_accuracy_6: 0.3925 - val_loss: 1.0908 - val_profit_accuracy_6: 0.3483\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0751 - profit_accuracy_6: 0.3910 - val_loss: 1.0881 - val_profit_accuracy_6: 0.3812\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_6: 0.3929 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3710\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0743 - profit_accuracy_6: 0.3924 - val_loss: 1.0902 - val_profit_accuracy_6: 0.3494\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_6: 0.3782 - val_loss: 1.0890 - val_profit_accuracy_6: 0.3777\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0746 - profit_accuracy_6: 0.3913 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3476\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3888 - val_loss: 1.0947 - val_profit_accuracy_6: 0.3187\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0752 - profit_accuracy_6: 0.3888 - val_loss: 1.0892 - val_profit_accuracy_6: 0.3460\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0745 - profit_accuracy_6: 0.3904 - val_loss: 1.0899 - val_profit_accuracy_6: 0.3386\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_6: 0.3963 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3765\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0752 - profit_accuracy_6: 0.3886 - val_loss: 1.0884 - val_profit_accuracy_6: 0.3761\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0749 - profit_accuracy_6: 0.3952 - val_loss: 1.0912 - val_profit_accuracy_6: 0.3471\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_6: 0.3977 - val_loss: 1.0880 - val_profit_accuracy_6: 0.3679\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0748 - profit_accuracy_6: 0.4002 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3857\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0755 - profit_accuracy_6: 0.3912 - val_loss: 1.0897 - val_profit_accuracy_6: 0.3398\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0743 - profit_accuracy_6: 0.3850 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3455\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_6: 0.3941 - val_loss: 1.0880 - val_profit_accuracy_6: 0.4559\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0745 - profit_accuracy_6: 0.3948 - val_loss: 1.0893 - val_profit_accuracy_6: 0.3583\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0751 - profit_accuracy_6: 0.3779 - val_loss: 1.0880 - val_profit_accuracy_6: 0.3855\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_6: 0.3920 - val_loss: 1.0897 - val_profit_accuracy_6: 0.3425\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_6: 0.3966 - val_loss: 1.0903 - val_profit_accuracy_6: 0.3296\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_6: 0.3936 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3816\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0750 - profit_accuracy_6: 0.3893 - val_loss: 1.0893 - val_profit_accuracy_6: 0.3644\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0755 - profit_accuracy_6: 0.3832 - val_loss: 1.0925 - val_profit_accuracy_6: 0.3376\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0743 - profit_accuracy_6: 0.4004 - val_loss: 1.0913 - val_profit_accuracy_6: 0.3514\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0744 - profit_accuracy_6: 0.3952 - val_loss: 1.0896 - val_profit_accuracy_6: 0.3440\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_6: 0.3896 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3723\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0744 - profit_accuracy_6: 0.3992 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3955\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0740 - profit_accuracy_6: 0.3959 - val_loss: 1.0912 - val_profit_accuracy_6: 0.3309\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0748 - profit_accuracy_6: 0.3916 - val_loss: 1.0909 - val_profit_accuracy_6: 0.3345\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0738 - profit_accuracy_6: 0.3914 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3886\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0745 - profit_accuracy_6: 0.3867 - val_loss: 1.0883 - val_profit_accuracy_6: 0.3895\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0747 - profit_accuracy_6: 0.3983 - val_loss: 1.0879 - val_profit_accuracy_6: 0.4122\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0745 - profit_accuracy_6: 0.3873 - val_loss: 1.0882 - val_profit_accuracy_6: 0.3934\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_6: 0.3842 - val_loss: 1.0891 - val_profit_accuracy_6: 0.3691\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0738 - profit_accuracy_6: 0.4025 - val_loss: 1.0927 - val_profit_accuracy_6: 0.3407\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0746 - profit_accuracy_6: 0.3882 - val_loss: 1.0886 - val_profit_accuracy_6: 0.3632\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0745 - profit_accuracy_6: 0.3920 - val_loss: 1.0879 - val_profit_accuracy_6: 0.3923\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_6: 0.3973 - val_loss: 1.0900 - val_profit_accuracy_6: 0.3253\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0739 - profit_accuracy_6: 0.3917 - val_loss: 1.0909 - val_profit_accuracy_6: 0.3321\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0738 - profit_accuracy_6: 0.3940 - val_loss: 1.0888 - val_profit_accuracy_6: 0.3886\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0747 - profit_accuracy_6: 0.3914 - val_loss: 1.0891 - val_profit_accuracy_6: 0.3480\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0735 - profit_accuracy_6: 0.4016 - val_loss: 1.0924 - val_profit_accuracy_6: 0.3487\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0733 - profit_accuracy_6: 0.4038 - val_loss: 1.0908 - val_profit_accuracy_6: 0.3296\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0742 - profit_accuracy_6: 0.3936 - val_loss: 1.0895 - val_profit_accuracy_6: 0.3648\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0735 - profit_accuracy_6: 0.3944 - val_loss: 1.0904 - val_profit_accuracy_6: 0.3545\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0743 - profit_accuracy_6: 0.3913 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3640\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0735 - profit_accuracy_6: 0.3916 - val_loss: 1.0885 - val_profit_accuracy_6: 0.3915\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0736 - profit_accuracy_6: 0.3973 - val_loss: 1.0896 - val_profit_accuracy_6: 0.3603\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0733 - profit_accuracy_6: 0.3979 - val_loss: 1.0889 - val_profit_accuracy_6: 0.3627\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0733 - profit_accuracy_6: 0.3961 - val_loss: 1.0901 - val_profit_accuracy_6: 0.3320\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0733 - profit_accuracy_6: 0.4001 - val_loss: 1.0916 - val_profit_accuracy_6: 0.3392\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0741 - profit_accuracy_6: 0.3990 - val_loss: 1.0887 - val_profit_accuracy_6: 0.3905\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0738 - profit_accuracy_6: 0.3930 - val_loss: 1.0886 - val_profit_accuracy_6: 0.3869\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0734 - profit_accuracy_6: 0.3950 - val_loss: 1.0887 - val_profit_accuracy_6: 0.4052\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0736 - profit_accuracy_6: 0.3881 - val_loss: 1.0899 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_6: 0.3916 - val_loss: 1.0887 - val_profit_accuracy_6: 0.3989\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0733 - profit_accuracy_6: 0.4018 - val_loss: 1.0911 - val_profit_accuracy_6: 0.3396\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0732 - profit_accuracy_6: 0.3945 - val_loss: 1.0909 - val_profit_accuracy_6: 0.3333\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0736 - profit_accuracy_6: 0.3928 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3361\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0726 - profit_accuracy_6: 0.4009 - val_loss: 1.0887 - val_profit_accuracy_6: 0.4128\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0737 - profit_accuracy_6: 0.4002 - val_loss: 1.0899 - val_profit_accuracy_6: 0.3489\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0727 - profit_accuracy_6: 0.3926 - val_loss: 1.0890 - val_profit_accuracy_6: 0.3800\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0728 - profit_accuracy_6: 0.3917 - val_loss: 1.0906 - val_profit_accuracy_6: 0.3347\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0725 - profit_accuracy_6: 0.3983 - val_loss: 1.0899 - val_profit_accuracy_6: 0.3713\n",
      "30/30 [==============================] - 1s 3ms/step\n",
      "Profit_accuracy = 0.37130802869796753\n",
      "Combine profit_accuracy = 0.5263158082962036\n"
     ]
    }
   ],
   "source": [
    "combined_pred_probs, profit_accuracy = train_lstm_model_combine(X_train_normalized_eco, X_test_normalized_eco, X_train_normalized_tech, X_test_normalized_tech, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
